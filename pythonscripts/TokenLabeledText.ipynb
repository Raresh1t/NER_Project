{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ddcf42-5245-42c2-b7a7-4218b8f6cccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: transformers in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.46.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\magnu\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\magnu\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\magnu\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\magnu\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\magnu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "c:\\Users\\magnu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas transformers\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "with open('../labeled_data/gold_labels/reconstructed_gold_labels_2.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "texts = [item['text'] for item in data]\n",
    "entities = [item['entities'] for item in data]\n",
    "df = pd.DataFrame({'text': texts, 'entities': entities})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a163175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nl_positions(text):\n",
    "    nl_pos = []\n",
    "    current = 0\n",
    "    while text.find(\"\\n\", current) != -1:\n",
    "        nl_pos.append(text.find(\"\\n\", current))\n",
    "        current = text.find(\"\\n\", current) +1\n",
    "    return nl_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b42efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nl_positions'] = df['text'].apply(\n",
    "    lambda x: find_nl_positions(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bee9c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>nl_positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A new ransomware-as-a-service (RaaS) operation...</td>\n",
       "      <td>[{'start': 716, 'end': 732, 'type': 'ORG', 'te...</td>\n",
       "      <td>[162, 359, 532, 702, 869, 1140, 1238, 1434, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nThe popular Docker-OSX project has been remo...</td>\n",
       "      <td>[{'start': 14, 'end': 24, 'type': 'Software', ...</td>\n",
       "      <td>[0, 183, 411, 581, 702, 848, 1102, 1288, 1445,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nA former core infrastructure engineer at an ...</td>\n",
       "      <td>[{'start': 82, 'end': 97, 'type': 'LOC', 'text...</td>\n",
       "      <td>[0, 221, 524, 752, 1136, 1350, 1722, 2064, 226...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThreat actors target Middle Eastern organiza...</td>\n",
       "      <td>[{'start': 23, 'end': 37, 'type': 'LOC', 'text...</td>\n",
       "      <td>[0, 220, 520, 682, 871, 1013, 1164, 1369, 1494...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nSince surfacing in February 2024, RansomHub ...</td>\n",
       "      <td>[{'start': 37, 'end': 46, 'type': 'MAL-ORG', '...</td>\n",
       "      <td>[0, 156, 529, 915, 1041, 1299, 1547, 1983, 198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>\\nâ€‹Russian law enforcement detained almost 100...</td>\n",
       "      <td>[{'start': 2, 'end': 10, 'type': 'LOC', 'text'...</td>\n",
       "      <td>[0, 239, 464, 787, 1076, 1241, 1472, 1719, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>\\nThe Russian state-sponsored APT29 hacking gr...</td>\n",
       "      <td>[{'start': 5, 'end': 13, 'type': 'LOC', 'text'...</td>\n",
       "      <td>[0, 209, 389, 524, 735, 972, 1082, 1313, 1486,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>\\nThe South Korea-aligned cyberespionage group...</td>\n",
       "      <td>[{'start': 6, 'end': 25, 'type': 'LOC', 'text'...</td>\n",
       "      <td>[0, 207, 366, 571, 799, 974, 1178, 1332, 1517,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>\\nThe Federal Communications Commission (FCC) ...</td>\n",
       "      <td>[{'start': 6, 'end': 39, 'type': 'ORG', 'text'...</td>\n",
       "      <td>[0, 196, 436, 610, 831, 1056, 1225, 1450, 1869...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Nuclear waste processing facility Sellafield h...</td>\n",
       "      <td>[{'start': 34, 'end': 44, 'type': 'ORG', 'text...</td>\n",
       "      <td>[254, 483, 697, 936, 1183, 1322, 1574, 1709, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   A new ransomware-as-a-service (RaaS) operation...   \n",
       "1   \\nThe popular Docker-OSX project has been remo...   \n",
       "2   \\nA former core infrastructure engineer at an ...   \n",
       "3   \\nThreat actors target Middle Eastern organiza...   \n",
       "4   \\nSince surfacing in February 2024, RansomHub ...   \n",
       "..                                                ...   \n",
       "56  \\nâ€‹Russian law enforcement detained almost 100...   \n",
       "57  \\nThe Russian state-sponsored APT29 hacking gr...   \n",
       "58  \\nThe South Korea-aligned cyberespionage group...   \n",
       "59  \\nThe Federal Communications Commission (FCC) ...   \n",
       "60  Nuclear waste processing facility Sellafield h...   \n",
       "\n",
       "                                             entities  \\\n",
       "0   [{'start': 716, 'end': 732, 'type': 'ORG', 'te...   \n",
       "1   [{'start': 14, 'end': 24, 'type': 'Software', ...   \n",
       "2   [{'start': 82, 'end': 97, 'type': 'LOC', 'text...   \n",
       "3   [{'start': 23, 'end': 37, 'type': 'LOC', 'text...   \n",
       "4   [{'start': 37, 'end': 46, 'type': 'MAL-ORG', '...   \n",
       "..                                                ...   \n",
       "56  [{'start': 2, 'end': 10, 'type': 'LOC', 'text'...   \n",
       "57  [{'start': 5, 'end': 13, 'type': 'LOC', 'text'...   \n",
       "58  [{'start': 6, 'end': 25, 'type': 'LOC', 'text'...   \n",
       "59  [{'start': 6, 'end': 39, 'type': 'ORG', 'text'...   \n",
       "60  [{'start': 34, 'end': 44, 'type': 'ORG', 'text...   \n",
       "\n",
       "                                         nl_positions  \n",
       "0   [162, 359, 532, 702, 869, 1140, 1238, 1434, 14...  \n",
       "1   [0, 183, 411, 581, 702, 848, 1102, 1288, 1445,...  \n",
       "2   [0, 221, 524, 752, 1136, 1350, 1722, 2064, 226...  \n",
       "3   [0, 220, 520, 682, 871, 1013, 1164, 1369, 1494...  \n",
       "4   [0, 156, 529, 915, 1041, 1299, 1547, 1983, 198...  \n",
       "..                                                ...  \n",
       "56  [0, 239, 464, 787, 1076, 1241, 1472, 1719, 202...  \n",
       "57  [0, 209, 389, 524, 735, 972, 1082, 1313, 1486,...  \n",
       "58  [0, 207, 366, 571, 799, 974, 1178, 1332, 1517,...  \n",
       "59  [0, 196, 436, 610, 831, 1056, 1225, 1450, 1869...  \n",
       "60  [254, 483, 697, 936, 1183, 1322, 1574, 1709, 1...  \n",
       "\n",
       "[61 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5645404d-0e2d-41be-8f21-c3c4f210a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "df['tokenized'] = df['text'].apply(\n",
    "    lambda x: tokenizer(x, return_offsets_mapping=True, truncation=True, padding=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53b7e5fb-eae0-4526-9d69-037431c75f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_to_tokens(text, entities, tokenized, nl_positions):\n",
    "    offset_mapping = tokenized['offset_mapping']\n",
    "    labels = [\"O\"] * len(offset_mapping) # Initialize all tokens with \"O\"\n",
    "\n",
    "    for entity in entities:\n",
    "        start, end, label_type = entity['start'], entity['end'], entity['type']\n",
    "        nls_before_entity = 0\n",
    "        for nl_pos in nl_positions:\n",
    "            if nl_pos < start:\n",
    "                nls_before_entity +=1\n",
    "            else:\n",
    "                break\n",
    "        start -= nls_before_entity\n",
    "        end -= nls_before_entity\n",
    "        entity_started = False\n",
    "        #print(entity)\n",
    "\n",
    "        for idx, (token_start, token_end) in enumerate(offset_mapping):\n",
    "            #print(token_start, token_end)\n",
    "            if token_start is None or token_end is None:\n",
    "                continue\n",
    "            if token_start >= start and token_end <= end:\n",
    "                if entity_started:\n",
    "                    labels[idx] = f\"I-{label_type}\"\n",
    "                else:\n",
    "                    labels[idx] = f\"B-{label_type}\"\n",
    "                    entity_started = True\n",
    "            else:\n",
    "                entity_started = False\n",
    "\n",
    "    return labels\n",
    "\n",
    "df['labels'] = df.apply(lambda row: align_labels_to_tokens(row['text'], row['entities'], row['tokenized'], row['nl_positions']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad751a07-b0af-4036-9da7-d9eac01ed409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSON or CSV format\n",
    "output_data = []\n",
    "for _, row in df.iterrows():\n",
    "    tokens = tokenizer.convert_ids_to_tokens(row['tokenized']['input_ids'])\n",
    "    labels = row['labels']\n",
    "    output_data.append({'tokens': tokens, 'labels': labels})\n",
    "\n",
    "# Save the processed data\n",
    "with open('tokenized_ner_data_4.json', 'w') as f:\n",
    "    json.dump(output_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f946a71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "##ica\n",
      "##da\n",
      "##33\n",
      "##01\n",
      "##da\n",
      "##33\n",
      "##01\n",
      "Ra\n",
      "##ping\n",
      "##C\n",
      "##om\n",
      "##pute\n",
      "##r\n",
      "is\n",
      "##da\n",
      "##33\n",
      "##01\n",
      "double\n",
      "-\n",
      "ex\n",
      "##tor\n",
      "##tion\n",
      "tactics\n",
      "where\n",
      "they\n",
      "breach\n",
      "corporate\n",
      "networks\n",
      ",\n",
      "steal\n",
      "data\n",
      ",\n",
      "and\n",
      "then\n",
      "en\n",
      "##c\n",
      "##ry\n",
      "##pt\n",
      "devices\n",
      ".\n",
      "The\n",
      "##01\n",
      "and\n",
      "AL\n",
      "##C\n",
      ",\n",
      "core\n",
      "from\n",
      "one\n",
      "also\n",
      "ransom\n",
      "##net\n",
      "for\n",
      "##inet\n",
      "Pa\n",
      "##lo\n",
      "and\n",
      "down\n",
      "a\n",
      "R\n",
      "##ust\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(output_data[0]['labels']):\n",
    "    if label != \"O\":\n",
    "        print(output_data[0]['tokens'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc8be507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nl_positions(text):\n",
    "    nl_pos = []\n",
    "    current = 0\n",
    "    while text.find(\"\\n\", current) != -1:\n",
    "        nl_pos.append(text.find(\"\\n\", current))\n",
    "        current = text.find(\"\\n\", current) +1\n",
    "    return nl_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d731d754",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nl_pos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnl_pos\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nl_pos' is not defined"
     ]
    }
   ],
   "source": [
    "nl_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37e5b07c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m labels \u001b[38;5;241m=\u001b[39m align_labels_to_tokens(\u001b[43mtext\u001b[49m, df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentities\u001b[39m\u001b[38;5;124m'\u001b[39m], df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenized\u001b[39m\u001b[38;5;124m'\u001b[39m], nl_pos)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "labels = align_labels_to_tokens(text, df.iloc[0]['entities'], df.iloc[0]['tokenized'], nl_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ecfdb6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "##ica\n",
      "##da\n",
      "##33\n",
      "##01\n",
      "C\n",
      "##ica\n",
      "##da\n",
      "##33\n",
      "##01\n",
      "B\n",
      "##lee\n",
      "##ping\n",
      "##C\n",
      "##om\n",
      "##pute\n",
      "##r\n",
      "C\n",
      "##ica\n",
      "##da\n",
      "C\n",
      "##ica\n",
      "##da\n",
      "##33\n",
      "##01\n",
      "conducts\n",
      "double\n",
      "-\n",
      "ex\n",
      "##tor\n",
      "##tion\n",
      "tactics\n",
      "where\n",
      "they\n",
      "breach\n",
      "corporate\n",
      "networks\n",
      ",\n",
      "steal\n",
      "data\n",
      ",\n",
      "and\n",
      "then\n",
      "en\n",
      "##c\n",
      "##ry\n",
      "##pt\n",
      "devices\n",
      "True\n",
      "##se\n",
      "##c\n",
      "C\n",
      "##ica\n",
      "##da\n",
      "##33\n",
      "##01\n",
      "AL\n",
      "##P\n",
      "##H\n",
      "##V\n",
      "Black\n",
      "##C\n",
      "##at\n",
      "AL\n",
      "##P\n",
      "##H\n",
      "##V\n",
      "'\n",
      "s\n",
      "AL\n",
      "##P\n",
      "##H\n",
      "##V\n",
      "FBI\n",
      "Change\n",
      "Healthcare\n",
      "True\n",
      "##se\n",
      "##c\n",
      "C\n",
      "##ica\n",
      "##da\n",
      "##33\n",
      "##01\n",
      "B\n",
      "##ru\n",
      "##tus\n",
      "b\n",
      "##ot\n",
      "##net\n",
      "C\n",
      "##isco\n",
      "Fort\n",
      "##inet\n",
      "Pa\n",
      "##lo\n",
      "Alto\n",
      "Sonic\n",
      "##W\n",
      "##all\n",
      "B\n",
      "##ru\n",
      "##tus\n",
      "AL\n",
      "##P\n",
      "##H\n",
      "##V\n",
      "C\n",
      "##ica\n",
      "##da\n",
      "##33\n",
      "##01\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(labels):\n",
    "    if label != \"O\":\n",
    "        print(output_data[0]['tokens'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef3469b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


# Starting new run with hyperparams:
{
  "learning_rate": 2e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy

# Starting new run with hyperparams:
{
  "learning_rate": 2e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy

# Starting new run with hyperparams:
{
  "learning_rate": 2e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.417, 10, 3.4690, None, None, None, None, None
0.833, 20, 1.0617, None, None, None, None, None
1.000, 24, None, 0.5843, 0.0000, 0.0000, 0.0000, 0.8680
1.250, 30, 0.5352, None, None, None, None, None
1.667, 40, 0.3309, None, None, None, None, None
2.000, 48, None, 0.3331, 0.4960, 0.5367, 0.5155, 0.9181
2.083, 50, 0.3830, None, None, None, None, None
2.500, 60, 0.2612, None, None, None, None, None
2.917, 70, 0.2313, None, None, None, None, None
3.000, 72, None, 0.2583, 0.6951, 0.6696, 0.6821, 0.9338
3.333, 80, 0.2370, None, None, None, None, None
3.750, 90, 0.1763, None, None, None, None, None
4.000, 96, None, 0.2370, 0.7040, 0.7360, 0.7197, 0.9404
4.167, 100, 0.1262, None, None, None, None, None
4.583, 110, 0.1257, None, None, None, None, None
5.000, 120, 0.1272, None, None, None, None, None
5.000, 120, None, 0.2706, 0.7460, 0.7290, 0.7374, 0.9410
5.417, 130, 0.1157, None, None, None, None, None
5.833, 140, 0.0990, None, None, None, None, None
6.000, 144, None, 0.2464, 0.7119, 0.7605, 0.7354, 0.9442
6.250, 150, 0.0867, None, None, None, None, None
6.667, 160, 0.0558, None, None, None, None, None
7.000, 168, None, 0.2847, 0.7623, 0.7570, 0.7596, 0.9440
7.083, 170, 0.0947, None, None, None, None, None
7.500, 180, 0.0583, None, None, None, None, None
7.917, 190, 0.0661, None, None, None, None, None
8.000, 192, None, 0.2901, 0.7358, 0.7692, 0.7521, 0.9451
8.333, 200, 0.0546, None, None, None, None, None
8.750, 210, 0.0571, None, None, None, None, None
9.000, 216, None, 0.2671, 0.7350, 0.7710, 0.7526, 0.9462
9.167, 220, 0.0561, None, None, None, None, None
9.583, 230, 0.0487, None, None, None, None, None
10.000, 240, 0.0473, None, None, None, None, None
10.000, 240, None, 0.2900, 0.7547, 0.7745, 0.7645, 0.9469
10.000, 240, None, None, None, None, None, None
10.000, 240, None, 0.2370, 0.7040, 0.7360, 0.7197, 0.9404

# Starting new run with hyperparams:
{
  "learning_rate": 2e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 2,
  "warmup_ratio": 0.1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.833, 10, 3.5065, None, None, None, None, None
1.000, 12, None, 0.7846, 0.0000, 0.0000, 0.0000, 0.8680
1.667, 20, 0.6427, None, None, None, None, None
2.000, 24, None, 0.5284, 0.3452, 0.0507, 0.0884, 0.8724
2.500, 30, 0.5276, None, None, None, None, None
3.000, 36, None, 0.4276, 0.2482, 0.3094, 0.2755, 0.8937
3.333, 40, 0.4159, None, None, None, None, None
4.000, 48, None, 0.3627, 0.3850, 0.4301, 0.4063, 0.9094
4.167, 50, 0.3172, None, None, None, None, None
5.000, 60, 0.3023, None, None, None, None, None
5.000, 60, None, 0.3299, 0.5159, 0.5664, 0.5400, 0.9220
5.833, 70, 0.2423, None, None, None, None, None
6.000, 72, None, 0.2821, 0.5706, 0.6573, 0.6109, 0.9278
6.667, 80, 0.2111, None, None, None, None, None
7.000, 84, None, 0.2666, 0.6650, 0.7150, 0.6891, 0.9378
7.500, 90, 0.2110, None, None, None, None, None
8.000, 96, None, 0.2778, 0.7000, 0.7465, 0.7225, 0.9393
8.333, 100, 0.1696, None, None, None, None, None
9.000, 108, None, 0.2760, 0.7037, 0.7308, 0.7170, 0.9353
9.167, 110, 0.1602, None, None, None, None, None
10.000, 120, 0.1468, None, None, None, None, None
10.000, 120, None, 0.2767, 0.7145, 0.7395, 0.7268, 0.9379
10.000, 120, None, None, None, None, None, None
10.000, 120, None, 0.2666, 0.6650, 0.7150, 0.6891, 0.9378

# Starting new run with hyperparams:
{
  "learning_rate": 2e-05,
  "batch_size": 4,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.833, 10, 3.5052, None, None, None, None, None
1.000, 12, None, 0.7801, 0.0000, 0.0000, 0.0000, 0.8680
1.667, 20, 0.6337, None, None, None, None, None
2.000, 24, None, 0.5196, 0.3179, 0.0839, 0.1328, 0.8750
2.500, 30, 0.5190, None, None, None, None, None
3.000, 36, None, 0.4172, 0.2475, 0.3059, 0.2737, 0.8939
3.333, 40, 0.4062, None, None, None, None, None
4.000, 48, None, 0.3528, 0.4230, 0.4371, 0.4299, 0.9098
4.167, 50, 0.3111, None, None, None, None, None
5.000, 60, 0.2935, None, None, None, None, None
5.000, 60, None, 0.3275, 0.5477, 0.5717, 0.5595, 0.9232
5.833, 70, 0.2382, None, None, None, None, None
6.000, 72, None, 0.2765, 0.6369, 0.7115, 0.6722, 0.9346
6.667, 80, 0.2074, None, None, None, None, None
7.000, 84, None, 0.2622, 0.6840, 0.7378, 0.7098, 0.9388
7.500, 90, 0.2016, None, None, None, None, None
8.000, 96, None, 0.3093, 0.6960, 0.7325, 0.7138, 0.9400
8.333, 100, 0.1648, None, None, None, None, None
9.000, 108, None, 0.2757, 0.7083, 0.7343, 0.7210, 0.9393
9.167, 110, 0.1602, None, None, None, None, None
10.000, 120, 0.1488, None, None, None, None, None
10.000, 120, None, 0.2548, 0.6967, 0.7430, 0.7191, 0.9360
10.000, 120, None, None, None, None, None, None
10.000, 120, None, 0.2548, 0.6967, 0.7430, 0.7191, 0.9360

# Starting new run with hyperparams:
{
  "learning_rate": 2e-05,
  "batch_size": 4,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 2,
  "warmup_ratio": 0.1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
1.000, 6, None, 1.9137, 0.0140, 0.0210, 0.0168, 0.7640
1.667, 10, 2.7958, None, None, None, None, None
2.000, 12, None, 0.6799, 0.0000, 0.0000, 0.0000, 0.8680
3.000, 18, None, 0.5219, 0.4079, 0.0542, 0.0957, 0.8732
3.333, 20, 0.5999, None, None, None, None, None
4.000, 24, None, 0.4564, 0.3073, 0.2955, 0.3012, 0.8944
5.000, 30, 0.3999, None, None, None, None, None
5.000, 30, None, 0.4310, 0.2868, 0.3444, 0.3129, 0.8982
6.000, 36, None, 0.3874, 0.2866, 0.3357, 0.3092, 0.8984
6.667, 40, 0.3487, None, None, None, None, None
7.000, 42, None, 0.3699, 0.4444, 0.4336, 0.4389, 0.9116
8.000, 48, None, 0.3365, 0.4709, 0.5087, 0.4891, 0.9173
8.333, 50, 0.3083, None, None, None, None, None
9.000, 54, None, 0.3314, 0.4837, 0.5175, 0.5000, 0.9184
10.000, 60, 0.2693, None, None, None, None, None
10.000, 60, None, 0.3231, 0.5142, 0.5367, 0.5252, 0.9203
10.000, 60, None, None, None, None, None, None
10.000, 60, None, 0.3231, 0.5142, 0.5367, 0.5252, 0.9203

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.417, 10, 4.0913, None, None, None, None, None
0.833, 20, 1.2556, None, None, None, None, None
1.000, 24, None, 0.6394, 0.0000, 0.0000, 0.0000, 0.8680
1.250, 30, 0.5643, None, None, None, None, None
1.667, 40, 0.3533, None, None, None, None, None
2.000, 48, None, 0.3975, 0.3263, 0.3759, 0.3493, 0.9026
2.083, 50, 0.4396, None, None, None, None, None
2.500, 60, 0.3365, None, None, None, None, None
2.917, 70, 0.2493, None, None, None, None, None
3.000, 72, None, 0.2945, 0.5896, 0.6556, 0.6209, 0.9321
3.333, 80, 0.2735, None, None, None, None, None
3.750, 90, 0.2097, None, None, None, None, None
4.000, 96, None, 0.2592, 0.7126, 0.7413, 0.7266, 0.9428
4.167, 100, 0.1565, None, None, None, None, None
4.583, 110, 0.1732, None, None, None, None, None
5.000, 120, 0.1586, None, None, None, None, None
5.000, 120, None, 0.2873, 0.7414, 0.7517, 0.7465, 0.9437
5.417, 130, 0.1505, None, None, None, None, None
5.833, 140, 0.1212, None, None, None, None, None
6.000, 144, None, 0.2295, 0.7033, 0.7710, 0.7356, 0.9446
6.250, 150, 0.1073, None, None, None, None, None
6.667, 160, 0.0755, None, None, None, None, None
7.000, 168, None, 0.2889, 0.7491, 0.7517, 0.7504, 0.9424
7.083, 170, 0.1118, None, None, None, None, None
7.500, 180, 0.0814, None, None, None, None, None
7.917, 190, 0.0791, None, None, None, None, None
8.000, 192, None, 0.2827, 0.7277, 0.7710, 0.7487, 0.9451
8.333, 200, 0.0702, None, None, None, None, None
8.750, 210, 0.0725, None, None, None, None, None
9.000, 216, None, 0.2682, 0.7300, 0.7797, 0.7540, 0.9457
9.167, 220, 0.0670, None, None, None, None, None
9.583, 230, 0.0610, None, None, None, None, None
10.000, 240, 0.0570, None, None, None, None, None
10.000, 240, None, 0.2791, 0.7274, 0.7745, 0.7502, 0.9457
10.000, 240, None, None, None, None, None, None
10.000, 240, None, 0.2295, 0.7033, 0.7710, 0.7356, 0.9446

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 2,
  "warmup_ratio": 0.1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.833, 10, 3.5065, None, None, None, None, None
1.000, 12, None, 0.7847, 0.0000, 0.0000, 0.0000, 0.8680
1.667, 20, 0.6427, None, None, None, None, None
2.000, 24, None, 0.5286, 0.3494, 0.0507, 0.0885, 0.8725
2.500, 30, 0.5277, None, None, None, None, None
3.000, 36, None, 0.4275, 0.2490, 0.3112, 0.2766, 0.8939
3.333, 40, 0.4158, None, None, None, None, None
4.000, 48, None, 0.3625, 0.3850, 0.4301, 0.4063, 0.9094
4.167, 50, 0.3171, None, None, None, None, None
5.000, 60, 0.3021, None, None, None, None, None
5.000, 60, None, 0.3316, 0.5135, 0.5647, 0.5379, 0.9220
5.833, 70, 0.2421, None, None, None, None, None
6.000, 72, None, 0.2840, 0.5766, 0.6643, 0.6174, 0.9260
6.667, 80, 0.2120, None, None, None, None, None
7.000, 84, None, 0.2674, 0.6645, 0.7133, 0.6880, 0.9378
7.500, 90, 0.2104, None, None, None, None, None
8.000, 96, None, 0.2793, 0.6987, 0.7500, 0.7234, 0.9390
8.333, 100, 0.1693, None, None, None, None, None
9.000, 108, None, 0.2761, 0.7061, 0.7308, 0.7182, 0.9352
9.167, 110, 0.1603, None, None, None, None, None
10.000, 120, 0.1470, None, None, None, None, None
10.000, 120, None, 0.2771, 0.7145, 0.7395, 0.7268, 0.9382
10.000, 120, None, None, None, None, None, None
10.000, 120, None, 0.2674, 0.6645, 0.7133, 0.6880, 0.9378

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 4,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.833, 10, 3.5052, None, None, None, None, None
1.000, 12, None, 0.7801, 0.0000, 0.0000, 0.0000, 0.8680
1.667, 20, 0.6337, None, None, None, None, None
2.000, 24, None, 0.5196, 0.3179, 0.0839, 0.1328, 0.8750
2.500, 30, 0.5190, None, None, None, None, None
3.000, 36, None, 0.4172, 0.2475, 0.3059, 0.2737, 0.8939
3.333, 40, 0.4062, None, None, None, None, None
4.000, 48, None, 0.3528, 0.4230, 0.4371, 0.4299, 0.9098
4.167, 50, 0.3110, None, None, None, None, None
5.000, 60, 0.2935, None, None, None, None, None
5.000, 60, None, 0.3276, 0.5470, 0.5699, 0.5582, 0.9231
5.833, 70, 0.2381, None, None, None, None, None
6.000, 72, None, 0.2764, 0.6359, 0.7115, 0.6716, 0.9347
6.667, 80, 0.2074, None, None, None, None, None
7.000, 84, None, 0.2622, 0.6823, 0.7360, 0.7082, 0.9386
7.500, 90, 0.2017, None, None, None, None, None
8.000, 96, None, 0.3092, 0.6960, 0.7325, 0.7138, 0.9400
8.333, 100, 0.1649, None, None, None, None, None
9.000, 108, None, 0.2756, 0.7095, 0.7343, 0.7216, 0.9394
9.167, 110, 0.1602, None, None, None, None, None
10.000, 120, 0.1488, None, None, None, None, None
10.000, 120, None, 0.2548, 0.6967, 0.7430, 0.7191, 0.9360
10.000, 120, None, None, None, None, None, None
10.000, 120, None, 0.2548, 0.6967, 0.7430, 0.7191, 0.9360

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 4,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 2,
  "warmup_ratio": 0.1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
1.000, 6, None, 1.9137, 0.0140, 0.0210, 0.0168, 0.7639
1.667, 10, 2.7958, None, None, None, None, None
2.000, 12, None, 0.6799, 0.0000, 0.0000, 0.0000, 0.8680
3.000, 18, None, 0.5219, 0.4079, 0.0542, 0.0957, 0.8732
3.333, 20, 0.5999, None, None, None, None, None
4.000, 24, None, 0.4562, 0.3073, 0.2955, 0.3012, 0.8944
5.000, 30, 0.3999, None, None, None, None, None
5.000, 30, None, 0.4310, 0.2880, 0.3444, 0.3137, 0.8983
6.000, 36, None, 0.3874, 0.2876, 0.3374, 0.3105, 0.8986
6.667, 40, 0.3486, None, None, None, None, None
7.000, 42, None, 0.3699, 0.4444, 0.4336, 0.4389, 0.9116
8.000, 48, None, 0.3364, 0.4709, 0.5087, 0.4891, 0.9173
8.333, 50, 0.3083, None, None, None, None, None
9.000, 54, None, 0.3314, 0.4829, 0.5175, 0.4996, 0.9184
10.000, 60, 0.2694, None, None, None, None, None
10.000, 60, None, 0.3231, 0.5160, 0.5367, 0.5261, 0.9205
10.000, 60, None, None, None, None, None, None
10.000, 60, None, 0.3231, 0.5160, 0.5367, 0.5261, 0.9205

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.417, 10, 4.0913, None, None, None, None, None
0.833, 20, 1.2557, None, None, None, None, None
1.000, 24, None, 0.6393, 0.0000, 0.0000, 0.0000, 0.8680
1.250, 30, 0.5643, None, None, None, None, None
1.667, 40, 0.3533, None, None, None, None, None
2.000, 48, None, 0.3977, 0.3263, 0.3759, 0.3493, 0.9026
2.083, 50, 0.4398, None, None, None, None, None
2.500, 60, 0.3368, None, None, None, None, None
2.917, 70, 0.2501, None, None, None, None, None
3.000, 72, None, 0.2939, 0.5921, 0.6573, 0.6230, 0.9321
3.333, 80, 0.2741, None, None, None, None, None
3.750, 90, 0.2098, None, None, None, None, None
4.000, 96, None, 0.2590, 0.7081, 0.7378, 0.7226, 0.9426
4.167, 100, 0.1560, None, None, None, None, None
4.583, 110, 0.1738, None, None, None, None, None
5.000, 120, 0.1600, None, None, None, None, None
5.000, 120, None, 0.2934, 0.7375, 0.7465, 0.7420, 0.9433
5.417, 130, 0.1527, None, None, None, None, None
5.833, 140, 0.1173, None, None, None, None, None
6.000, 144, None, 0.2323, 0.7042, 0.7657, 0.7337, 0.9443
6.250, 150, 0.1077, None, None, None, None, None
6.667, 160, 0.0754, None, None, None, None, None
7.000, 168, None, 0.2852, 0.7470, 0.7535, 0.7502, 0.9428
7.083, 170, 0.1103, None, None, None, None, None
7.500, 180, 0.0805, None, None, None, None, None
7.917, 190, 0.0767, None, None, None, None, None
8.000, 192, None, 0.2869, 0.7341, 0.7675, 0.7504, 0.9450
8.333, 200, 0.0697, None, None, None, None, None
8.750, 210, 0.0733, None, None, None, None, None
9.000, 216, None, 0.2708, 0.7331, 0.7780, 0.7549, 0.9460
9.167, 220, 0.0656, None, None, None, None, None
9.583, 230, 0.0614, None, None, None, None, None
10.000, 240, 0.0575, None, None, None, None, None
10.000, 240, None, 0.2793, 0.7348, 0.7797, 0.7566, 0.9453
10.000, 240, None, None, None, None, None, None
10.000, 240, None, 0.2323, 0.7042, 0.7657, 0.7337, 0.9443

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 2,
  "warmup_ratio": 0.1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.833, 10, 3.5065, None, None, None, None, None
1.000, 12, None, 0.7846, 0.0000, 0.0000, 0.0000, 0.8680
1.667, 20, 0.6427, None, None, None, None, None
2.000, 24, None, 0.5288, 0.3671, 0.0507, 0.0891, 0.8725
2.500, 30, 0.5278, None, None, None, None, None
3.000, 36, None, 0.4274, 0.2486, 0.3112, 0.2764, 0.8939
3.333, 40, 0.4157, None, None, None, None, None
4.000, 48, None, 0.3622, 0.3844, 0.4301, 0.4059, 0.9095
4.167, 50, 0.3171, None, None, None, None, None
5.000, 60, 0.3019, None, None, None, None, None
5.000, 60, None, 0.3332, 0.5079, 0.5594, 0.5324, 0.9214
5.833, 70, 0.2419, None, None, None, None, None
6.000, 72, None, 0.2871, 0.5762, 0.6678, 0.6186, 0.9239
6.667, 80, 0.2137, None, None, None, None, None
7.000, 84, None, 0.2670, 0.6591, 0.7063, 0.6819, 0.9372
7.500, 90, 0.2099, None, None, None, None, None
8.000, 96, None, 0.2834, 0.7010, 0.7500, 0.7247, 0.9390
8.333, 100, 0.1691, None, None, None, None, None
9.000, 108, None, 0.2787, 0.7061, 0.7308, 0.7182, 0.9356
9.167, 110, 0.1601, None, None, None, None, None
10.000, 120, 0.1472, None, None, None, None, None
10.000, 120, None, 0.2769, 0.7109, 0.7395, 0.7249, 0.9375
10.000, 120, None, None, None, None, None, None
10.000, 120, None, 0.2670, 0.6591, 0.7063, 0.6819, 0.9372

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 4,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.833, 10, 3.5052, None, None, None, None, None
1.000, 12, None, 0.7801, 0.0000, 0.0000, 0.0000, 0.8680
1.667, 20, 0.6337, None, None, None, None, None
2.000, 24, None, 0.5196, 0.3179, 0.0839, 0.1328, 0.8750
2.500, 30, 0.5190, None, None, None, None, None
3.000, 36, None, 0.4172, 0.2475, 0.3059, 0.2737, 0.8939
3.333, 40, 0.4062, None, None, None, None, None
4.000, 48, None, 0.3528, 0.4230, 0.4371, 0.4299, 0.9098
4.167, 50, 0.3111, None, None, None, None, None
5.000, 60, 0.2934, None, None, None, None, None
5.000, 60, None, 0.3274, 0.5468, 0.5717, 0.5590, 0.9234
5.833, 70, 0.2382, None, None, None, None, None
6.000, 72, None, 0.2767, 0.6340, 0.7115, 0.6705, 0.9346
6.667, 80, 0.2074, None, None, None, None, None
7.000, 84, None, 0.2623, 0.6840, 0.7378, 0.7098, 0.9388
7.500, 90, 0.2017, None, None, None, None, None
8.000, 96, None, 0.3093, 0.6960, 0.7325, 0.7138, 0.9400
8.333, 100, 0.1648, None, None, None, None, None
9.000, 108, None, 0.2756, 0.7066, 0.7325, 0.7193, 0.9392
9.167, 110, 0.1602, None, None, None, None, None
10.000, 120, 0.1487, None, None, None, None, None
10.000, 120, None, 0.2549, 0.6967, 0.7430, 0.7191, 0.9358
10.000, 120, None, None, None, None, None, None
10.000, 120, None, 0.2549, 0.6967, 0.7430, 0.7191, 0.9358

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 4,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 2,
  "warmup_ratio": 0.1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
1.000, 6, None, 1.9137, 0.0140, 0.0210, 0.0168, 0.7640
1.667, 10, 2.7958, None, None, None, None, None
2.000, 12, None, 0.6799, 0.0000, 0.0000, 0.0000, 0.8680
3.000, 18, None, 0.5219, 0.4079, 0.0542, 0.0957, 0.8732
3.333, 20, 0.5998, None, None, None, None, None
4.000, 24, None, 0.4561, 0.3073, 0.2955, 0.3012, 0.8944
5.000, 30, 0.3998, None, None, None, None, None
5.000, 30, None, 0.4311, 0.2880, 0.3444, 0.3137, 0.8983
6.000, 36, None, 0.3874, 0.2866, 0.3357, 0.3092, 0.8984
6.667, 40, 0.3486, None, None, None, None, None
7.000, 42, None, 0.3698, 0.4444, 0.4336, 0.4389, 0.9116
8.000, 48, None, 0.3364, 0.4709, 0.5087, 0.4891, 0.9173
8.333, 50, 0.3083, None, None, None, None, None
9.000, 54, None, 0.3314, 0.4829, 0.5175, 0.4996, 0.9184
10.000, 60, 0.2693, None, None, None, None, None
10.000, 60, None, 0.3231, 0.5151, 0.5367, 0.5257, 0.9203
10.000, 60, None, None, None, None, None, None
10.000, 60, None, 0.3231, 0.5151, 0.5367, 0.5257, 0.9203

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.208, 10, 3.3172, None, None, None, None, None
0.417, 20, 3.0803, None, None, None, None, None
0.625, 30, 2.6705, None, None, None, None, None
0.833, 40, 2.6442, None, None, None, None, None
1.000, 48, None, 2.2141, 0.0727, 0.4515, 0.1253, 0.4094
1.042, 50, 2.1349, None, None, None, None, None
1.250, 60, 1.6130, None, None, None, None, None
1.458, 70, 1.4289, None, None, None, None, None
1.667, 80, 1.2851, None, None, None, None, None
1.875, 90, 1.0498, None, None, None, None, None
2.000, 96, None, 1.0649, 0.1889, 0.6772, 0.2954, 0.6954
2.083, 100, 0.9418, None, None, None, None, None
2.292, 110, 0.6864, None, None, None, None, None
2.500, 120, 0.6373, None, None, None, None, None
2.708, 130, 0.4713, None, None, None, None, None
2.917, 140, 0.4780, None, None, None, None, None
3.000, 144, None, 0.9067, 0.3815, 0.6847, 0.4900, 0.8491
3.125, 150, 0.3940, None, None, None, None, None
3.333, 160, 0.4796, None, None, None, None, None
3.542, 170, 0.3058, None, None, None, None, None
3.750, 180, 0.2943, None, None, None, None, None
3.958, 190, 0.2586, None, None, None, None, None
4.000, 192, None, 0.7553, 0.3960, 0.6642, 0.4962, 0.8675
4.167, 200, 0.1879, None, None, None, None, None
4.375, 210, 0.2775, None, None, None, None, None
4.583, 220, 0.1936, None, None, None, None, None
4.792, 230, 0.2319, None, None, None, None, None
5.000, 240, 0.1478, None, None, None, None, None
5.000, 240, None, 0.9146, 0.4449, 0.6250, 0.5198, 0.8953
5.208, 250, 0.1268, None, None, None, None, None
5.417, 260, 0.1619, None, None, None, None, None
5.625, 270, 0.1134, None, None, None, None, None
5.833, 280, 0.0748, None, None, None, None, None
6.000, 288, None, 1.0526, 0.5179, 0.6754, 0.5862, 0.9087
6.042, 290, 0.0908, None, None, None, None, None
6.250, 300, 0.0482, None, None, None, None, None
6.458, 310, 0.1243, None, None, None, None, None
6.667, 320, 0.0828, None, None, None, None, None
6.875, 330, 0.0907, None, None, None, None, None
7.000, 336, None, 1.0590, 0.4950, 0.6455, 0.5603, 0.9037
7.083, 340, 0.0788, None, None, None, None, None
7.292, 350, 0.0609, None, None, None, None, None
7.500, 360, 0.0437, None, None, None, None, None
7.708, 370, 0.0412, None, None, None, None, None
7.917, 380, 0.0357, None, None, None, None, None
8.000, 384, None, 1.2143, 0.5593, 0.6866, 0.6164, 0.9224
8.125, 390, 0.0402, None, None, None, None, None
8.333, 400, 0.0372, None, None, None, None, None
8.542, 410, 0.0569, None, None, None, None, None
8.750, 420, 0.0465, None, None, None, None, None
8.958, 430, 0.0398, None, None, None, None, None
9.000, 432, None, 1.2344, 0.5752, 0.6922, 0.6283, 0.9253
9.167, 440, 0.0460, None, None, None, None, None
9.375, 450, 0.0299, None, None, None, None, None
9.583, 460, 0.0381, None, None, None, None, None
9.792, 470, 0.0295, None, None, None, None, None
10.000, 480, 0.0396, None, None, None, None, None
10.000, 480, None, 1.2445, 0.5770, 0.6922, 0.6293, 0.9260
10.000, 480, None, None, None, None, None, None
10.000, 480, None, 1.2445, 0.5770, 0.6922, 0.6293, 0.9260

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2869, None, None, None, None, None
0.408, 20, 3.2307, None, None, None, None, None
0.612, 30, 2.7948, None, None, None, None, None
0.816, 40, 2.4717, None, None, None, None, None
1.000, 49, None, 2.1857, 0.0429, 0.4397, 0.0781, 0.1567
1.020, 50, 2.2007, None, None, None, None, None
1.224, 60, 1.7742, None, None, None, None, None
1.429, 70, 1.5438, None, None, None, None, None
1.633, 80, 1.4073, None, None, None, None, None
1.837, 90, 1.1307, None, None, None, None, None
2.000, 98, None, 1.1992, 0.1827, 0.6809, 0.2881, 0.7152
2.041, 100, 0.9903, None, None, None, None, None
2.245, 110, 0.6386, None, None, None, None, None
2.449, 120, 0.5683, None, None, None, None, None
2.653, 130, 0.6106, None, None, None, None, None
2.857, 140, 0.5790, None, None, None, None, None
3.000, 147, None, 1.1913, 0.1710, 0.6231, 0.2684, 0.5143
3.061, 150, 0.4393, None, None, None, None, None
3.265, 160, 0.3626, None, None, None, None, None
3.469, 170, 0.3707, None, None, None, None, None
3.673, 180, 0.3218, None, None, None, None, None
3.878, 190, 0.2597, None, None, None, None, None
4.000, 196, None, 1.0518, 0.2340, 0.6709, 0.3470, 0.6130
4.082, 200, 0.3233, None, None, None, None, None
4.286, 210, 0.1592, None, None, None, None, None
4.490, 220, 0.2037, None, None, None, None, None
4.694, 230, 0.2001, None, None, None, None, None
4.898, 240, 0.2661, None, None, None, None, None
5.000, 245, None, 1.1020, 0.2647, 0.5528, 0.3580, 0.7836
5.102, 250, 0.1937, None, None, None, None, None
5.306, 260, 0.1144, None, None, None, None, None
5.510, 270, 0.1235, None, None, None, None, None
5.714, 280, 0.1314, None, None, None, None, None
5.918, 290, 0.1691, None, None, None, None, None

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.208, 10, 3.2510, None, None, None, None, None
0.417, 20, 3.0316, None, None, None, None, None
0.625, 30, 2.6829, None, None, None, None, None
0.833, 40, 2.7480, None, None, None, None, None
1.000, 48, None, 2.1865, 0.0396, 0.2743, 0.0692, 0.4532
1.042, 50, 2.1811, None, None, None, None, None
1.250, 60, 1.6690, None, None, None, None, None
1.458, 70, 1.3369, None, None, None, None, None
1.667, 80, 1.3119, None, None, None, None, None
1.875, 90, 1.0384, None, None, None, None, None
2.000, 96, None, 1.0763, 0.1516, 0.6119, 0.2431, 0.5648
2.083, 100, 1.1093, None, None, None, None, None
2.292, 110, 0.7773, None, None, None, None, None
2.500, 120, 0.6044, None, None, None, None, None
2.708, 130, 0.4286, None, None, None, None, None
2.917, 140, 0.5719, None, None, None, None, None
3.000, 144, None, 0.9137, 0.2471, 0.6679, 0.3607, 0.6653
3.125, 150, 0.3827, None, None, None, None, None
3.333, 160, 0.4432, None, None, None, None, None
3.542, 170, 0.3364, None, None, None, None, None
3.750, 180, 0.3550, None, None, None, None, None
3.958, 190, 0.2916, None, None, None, None, None
4.000, 192, None, 0.8945, 0.3285, 0.6287, 0.4315, 0.8333
4.167, 200, 0.1965, None, None, None, None, None

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler_type": "linear"
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.208, 10, 3.1649, None, None, None, None, None
0.417, 20, 2.9965, None, None, None, None, None
0.625, 30, 2.7666, None, None, None, None, None
0.833, 40, 2.6435, None, None, None, None, None
1.000, 48, None, 1.9850, 0.0363, 0.3299, 0.0654, 0.1473
1.042, 50, 1.9939, None, None, None, None, None
1.250, 60, 1.5812, None, None, None, None, None
1.458, 70, 1.3973, None, None, None, None, None
1.667, 80, 1.3547, None, None, None, None, None
1.875, 90, 1.1271, None, None, None, None, None
2.000, 96, None, 0.9535, 0.1140, 0.6273, 0.1930, 0.4524
2.083, 100, 0.8690, None, None, None, None, None
2.292, 110, 0.6669, None, None, None, None, None
2.500, 120, 0.5268, None, None, None, None, None
2.708, 130, 0.5206, None, None, None, None, None
2.917, 140, 0.5547, None, None, None, None, None
3.000, 144, None, 0.8112, 0.1981, 0.6293, 0.3013, 0.5686
3.125, 150, 0.4809, None, None, None, None, None
3.333, 160, 0.3539, None, None, None, None, None
3.542, 170, 0.2624, None, None, None, None, None
3.750, 180, 0.3099, None, None, None, None, None
3.958, 190, 0.2703, None, None, None, None, None
4.000, 192, None, 0.9229, 0.3198, 0.6436, 0.4273, 0.8350
4.167, 200, 0.2586, None, None, None, None, None
4.375, 210, 0.1687, None, None, None, None, None
4.583, 220, 0.2673, None, None, None, None, None
4.792, 230, 0.1794, None, None, None, None, None
5.000, 240, 0.1787, None, None, None, None, None
5.000, 240, None, 0.8450, 0.3425, 0.6110, 0.4389, 0.8425
5.208, 250, 0.0856, None, None, None, None, None
5.417, 260, 0.0878, None, None, None, None, None
5.625, 270, 0.0931, None, None, None, None, None
5.833, 280, 0.2372, None, None, None, None, None
6.000, 288, None, 0.9460, 0.3753, 0.6497, 0.4758, 0.8706
6.042, 290, 0.1369, None, None, None, None, None
6.250, 300, 0.0770, None, None, None, None, None
6.458, 310, 0.1220, None, None, None, None, None
6.667, 320, 0.0704, None, None, None, None, None
6.875, 330, 0.0630, None, None, None, None, None
7.000, 336, None, 0.9387, 0.3862, 0.7189, 0.5025, 0.8452
7.083, 340, 0.1752, None, None, None, None, None
7.292, 350, 0.0351, None, None, None, None, None
7.500, 360, 0.0592, None, None, None, None, None
7.708, 370, 0.0915, None, None, None, None, None
7.917, 380, 0.0663, None, None, None, None, None
8.000, 384, None, 1.0343, 0.4950, 0.7047, 0.5815, 0.9118
8.125, 390, 0.1624, None, None, None, None, None
8.333, 400, 0.0261, None, None, None, None, None
8.542, 410, 0.0736, None, None, None, None, None
8.750, 420, 0.1056, None, None, None, None, None
8.958, 430, 0.0475, None, None, None, None, None
9.000, 432, None, 1.1350, 0.5302, 0.7332, 0.6154, 0.9164
9.167, 440, 0.0949, None, None, None, None, None
9.375, 450, 0.0981, None, None, None, None, None
9.583, 460, 0.0242, None, None, None, None, None
9.792, 470, 0.0688, None, None, None, None, None
10.000, 480, 0.0449, None, None, None, None, None
10.000, 480, None, 1.2074, 0.5532, 0.7413, 0.6336, 0.9230
10.000, 480, None, None, None, None, None, None
10.000, 480, None, 0.8112, 0.1981, 0.6293, 0.3013, 0.5686

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler_type": "linear"
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.208, 10, 3.2396, None, None, None, None, None
0.417, 20, 3.0580, None, None, None, None, None
0.625, 30, 2.8958, None, None, None, None, None
0.833, 40, 2.5674, None, None, None, None, None
1.000, 48, None, 2.1317, 0.0791, 0.3611, 0.1298, 0.1215
1.042, 50, 2.1555, None, None, None, None, None
1.250, 60, 1.5937, None, None, None, None, None
1.458, 70, 1.3445, None, None, None, None, None
1.667, 80, 1.2904, None, None, None, None, None
1.875, 90, 1.1026, None, None, None, None, None
2.000, 96, None, 1.0969, 0.1238, 0.7108, 0.2109, 0.3875
2.083, 100, 0.8122, None, None, None, None, None
2.292, 110, 0.6794, None, None, None, None, None
2.500, 120, 0.6400, None, None, None, None, None
2.708, 130, 0.4679, None, None, None, None, None
2.917, 140, 0.6960, None, None, None, None, None
3.000, 144, None, 1.1383, 0.2279, 0.5747, 0.3264, 0.8072
3.125, 150, 0.4022, None, None, None, None, None
3.333, 160, 0.5404, None, None, None, None, None
3.542, 170, 0.3859, None, None, None, None, None
3.750, 180, 0.2925, None, None, None, None, None
3.958, 190, 0.2901, None, None, None, None, None
4.000, 192, None, 1.0054, 0.3875, 0.6938, 0.4973, 0.8711
4.167, 200, 0.3197, None, None, None, None, None
4.375, 210, 0.2896, None, None, None, None, None
4.583, 220, 0.1428, None, None, None, None, None
4.792, 230, 0.1941, None, None, None, None, None
5.000, 240, 0.2839, None, None, None, None, None
5.000, 240, None, 0.7825, 0.2676, 0.6389, 0.3772, 0.7177
5.208, 250, 0.2111, None, None, None, None, None
5.417, 260, 0.1907, None, None, None, None, None
5.625, 270, 0.1568, None, None, None, None, None
5.833, 280, 0.1091, None, None, None, None, None
6.000, 288, None, 1.1600, 0.4947, 0.6994, 0.5795, 0.9082
6.042, 290, 0.0694, None, None, None, None, None
6.250, 300, 0.0795, None, None, None, None, None
6.458, 310, 0.1447, None, None, None, None, None
6.667, 320, 0.1032, None, None, None, None, None
6.875, 330, 0.1075, None, None, None, None, None
7.000, 336, None, 0.9979, 0.4466, 0.7032, 0.5463, 0.8865
7.083, 340, 0.1550, None, None, None, None, None
7.292, 350, 0.0674, None, None, None, None, None
7.500, 360, 0.1822, None, None, None, None, None
7.708, 370, 0.0962, None, None, None, None, None
7.917, 380, 0.0764, None, None, None, None, None
8.000, 384, None, 1.0609, 0.5512, 0.7637, 0.6403, 0.9097
8.125, 390, 0.0636, None, None, None, None, None
8.333, 400, 0.1126, None, None, None, None, None
8.542, 410, 0.1036, None, None, None, None, None
8.750, 420, 0.0647, None, None, None, None, None
8.958, 430, 0.0290, None, None, None, None, None
9.000, 432, None, 1.1929, 0.5806, 0.7561, 0.6568, 0.9188
9.167, 440, 0.1259, None, None, None, None, None
9.375, 450, 0.0994, None, None, None, None, None
9.583, 460, 0.0206, None, None, None, None, None
9.792, 470, 0.0402, None, None, None, None, None
10.000, 480, 0.0464, None, None, None, None, None
10.000, 480, None, 1.2397, 0.6188, 0.7732, 0.6874, 0.9249
10.000, 480, None, None, None, None, None, None
10.000, 480, None, 1.2397, 0.6188, 0.7732, 0.6874, 0.9249

# Starting new run with hyperparams:
{
  "learning_rate": 6e-05,
  "batch_size": 1,
  "epochs": 20,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler_type": "linear"
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.208, 10, 3.1403, None, None, None, None, None
0.417, 20, 3.0731, None, None, None, None, None
0.625, 30, 2.9486, None, None, None, None, None
0.833, 40, 2.7952, None, None, None, None, None
1.000, 48, None, 2.4230, 0.0339, 0.2928, 0.0607, 0.4393
1.042, 50, 2.4817, None, None, None, None, None
1.250, 60, 2.1574, None, None, None, None, None
1.458, 70, 1.8527, None, None, None, None, None
1.667, 80, 1.7446, None, None, None, None, None
1.875, 90, 1.4408, None, None, None, None, None
2.000, 96, None, 1.3620, 0.0586, 0.5000, 0.1050, 0.2792
2.083, 100, 1.3125, None, None, None, None, None
2.292, 110, 0.9751, None, None, None, None, None
2.500, 120, 0.9199, None, None, None, None, None
2.708, 130, 0.8469, None, None, None, None, None
2.917, 140, 0.7512, None, None, None, None, None
3.000, 144, None, 1.0917, 0.1635, 0.6464, 0.2610, 0.7192
3.125, 150, 0.5807, None, None, None, None, None
3.333, 160, 0.4722, None, None, None, None, None
3.542, 170, 0.3996, None, None, None, None, None
3.750, 180, 0.5793, None, None, None, None, None
3.958, 190, 0.4491, None, None, None, None, None
4.000, 192, None, 0.8883, 0.2383, 0.5946, 0.3402, 0.8068
4.167, 200, 0.3040, None, None, None, None, None
4.375, 210, 0.2322, None, None, None, None, None
4.583, 220, 0.2475, None, None, None, None, None
4.792, 230, 0.3188, None, None, None, None, None
5.000, 240, 0.2741, None, None, None, None, None
5.000, 240, None, 0.9452, 0.2647, 0.6081, 0.3689, 0.8091
5.208, 250, 0.1448, None, None, None, None, None
5.417, 260, 0.1489, None, None, None, None, None
5.625, 270, 0.0999, None, None, None, None, None
5.833, 280, 0.1809, None, None, None, None, None
6.000, 288, None, 1.0124, 0.2679, 0.5315, 0.3562, 0.7994
6.042, 290, 0.1934, None, None, None, None, None
6.250, 300, 0.1230, None, None, None, None, None
6.458, 310, 0.1334, None, None, None, None, None
6.667, 320, 0.1157, None, None, None, None, None
6.875, 330, 0.1145, None, None, None, None, None
7.000, 336, None, 1.2989, 0.4263, 0.6644, 0.5194, 0.9051
7.083, 340, 0.1453, None, None, None, None, None
7.292, 350, 0.1017, None, None, None, None, None
7.500, 360, 0.1070, None, None, None, None, None
7.708, 370, 0.0478, None, None, None, None, None
7.917, 380, 0.1047, None, None, None, None, None
8.000, 384, None, 1.2938, 0.4850, 0.6577, 0.5583, 0.9369
8.125, 390, 0.1457, None, None, None, None, None
8.333, 400, 0.0593, None, None, None, None, None
8.542, 410, 0.0747, None, None, None, None, None
8.750, 420, 0.1051, None, None, None, None, None
8.958, 430, 0.0485, None, None, None, None, None
9.000, 432, None, 1.5171, 0.4237, 0.5878, 0.4925, 0.9182
9.167, 440, 0.0393, None, None, None, None, None
9.375, 450, 0.0521, None, None, None, None, None
9.583, 460, 0.0929, None, None, None, None, None
9.792, 470, 0.0508, None, None, None, None, None
10.000, 480, 0.0725, None, None, None, None, None
10.000, 480, None, 1.5862, 0.4762, 0.6532, 0.5508, 0.9256
10.208, 490, 0.0587, None, None, None, None, None
10.417, 500, 0.0243, None, None, None, None, None
10.625, 510, 0.0243, None, None, None, None, None
10.833, 520, 0.0542, None, None, None, None, None
11.000, 528, None, 1.6634, 0.5416, 0.6892, 0.6065, 0.9376
11.042, 530, 0.0795, None, None, None, None, None
11.250, 540, 0.0326, None, None, None, None, None
11.458, 550, 0.0209, None, None, None, None, None
11.667, 560, 0.0237, None, None, None, None, None
11.875, 570, 0.0797, None, None, None, None, None
12.000, 576, None, 1.7690, 0.5541, 0.6802, 0.6107, 0.9372
12.083, 580, 0.0980, None, None, None, None, None
12.292, 590, 0.0223, None, None, None, None, None
12.500, 600, 0.0535, None, None, None, None, None
12.708, 610, 0.0205, None, None, None, None, None
12.917, 620, 0.0575, None, None, None, None, None
13.000, 624, None, 1.6566, 0.4833, 0.6194, 0.5429, 0.9268
13.125, 630, 0.0256, None, None, None, None, None
13.333, 640, 0.0069, None, None, None, None, None
13.542, 650, 0.0178, None, None, None, None, None
13.750, 660, 0.0385, None, None, None, None, None
13.958, 670, 0.0649, None, None, None, None, None
14.000, 672, None, 1.8075, 0.5590, 0.6824, 0.6146, 0.9398
14.167, 680, 0.0327, None, None, None, None, None
14.375, 690, 0.0197, None, None, None, None, None
14.583, 700, 0.0250, None, None, None, None, None
14.792, 710, 0.0205, None, None, None, None, None
15.000, 720, 0.0582, None, None, None, None, None
15.000, 720, None, 1.7314, 0.5468, 0.6712, 0.6026, 0.9369
15.208, 730, 0.0571, None, None, None, None, None
15.417, 740, 0.0060, None, None, None, None, None
15.625, 750, 0.0186, None, None, None, None, None
15.833, 760, 0.0216, None, None, None, None, None
16.000, 768, None, 1.8481, 0.5722, 0.6959, 0.6280, 0.9399
16.042, 770, 0.0510, None, None, None, None, None
16.250, 780, 0.0047, None, None, None, None, None
16.458, 790, 0.0264, None, None, None, None, None
16.667, 800, 0.0261, None, None, None, None, None
16.875, 810, 0.0329, None, None, None, None, None
17.000, 816, None, 1.8264, 0.5743, 0.6959, 0.6293, 0.9434
17.083, 820, 0.0705, None, None, None, None, None
17.292, 830, 0.0039, None, None, None, None, None
17.500, 840, 0.0209, None, None, None, None, None
17.708, 850, 0.0173, None, None, None, None, None
17.917, 860, 0.0430, None, None, None, None, None
18.000, 864, None, 1.9030, 0.5924, 0.7005, 0.6419, 0.9466
18.125, 870, 0.0392, None, None, None, None, None
18.333, 880, 0.0173, None, None, None, None, None
18.542, 890, 0.0181, None, None, None, None, None
18.750, 900, 0.0147, None, None, None, None, None
18.958, 910, 0.0196, None, None, None, None, None
19.000, 912, None, 1.9472, 0.5969, 0.7005, 0.6446, 0.9460
19.167, 920, 0.0424, None, None, None, None, None
19.375, 930, 0.0076, None, None, None, None, None
19.583, 940, 0.0368, None, None, None, None, None
19.792, 950, 0.0272, None, None, None, None, None
20.000, 960, 0.0169, None, None, None, None, None
20.000, 960, None, 1.9347, 0.5969, 0.7005, 0.6446, 0.9466
20.000, 960, None, None, None, None, None, None
20.000, 960, None, 1.9472, 0.5969, 0.7005, 0.6446, 0.9460

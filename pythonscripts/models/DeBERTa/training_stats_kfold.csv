
# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.208, 10, 3.2843, None, None, None, None, None
0.417, 20, 3.0462, None, None, None, None, None
0.625, 30, 2.6274, None, None, None, None, None
0.833, 40, 2.7529, None, None, None, None, None
1.000, 48, None, 2.2237, 0.0363, 0.3358, 0.0655, 0.1379
1.042, 50, 2.1762, None, None, None, None, None
1.250, 60, 1.6809, None, None, None, None, None
1.458, 70, 1.3975, None, None, None, None, None
1.667, 80, 1.2288, None, None, None, None, None
1.875, 90, 1.0655, None, None, None, None, None
2.000, 96, None, 1.1278, 0.1330, 0.6418, 0.2203, 0.5595
2.083, 100, 1.0587, None, None, None, None, None
2.292, 110, 0.6598, None, None, None, None, None
2.500, 120, 0.8392, None, None, None, None, None
2.708, 130, 0.4673, None, None, None, None, None
2.917, 140, 0.4250, None, None, None, None, None
3.000, 144, None, 0.8690, 0.2453, 0.6604, 0.3578, 0.7451
3.125, 150, 0.3670, None, None, None, None, None
3.333, 160, 0.4120, None, None, None, None, None
3.542, 170, 0.3319, None, None, None, None, None
3.750, 180, 0.3312, None, None, None, None, None
3.958, 190, 0.2376, None, None, None, None, None
4.000, 192, None, 0.7469, 0.3436, 0.6269, 0.4439, 0.8302
4.167, 200, 0.1755, None, None, None, None, None
4.375, 210, 0.2282, None, None, None, None, None
4.583, 220, 0.1448, None, None, None, None, None
4.792, 230, 0.2228, None, None, None, None, None
5.000, 240, 0.2115, None, None, None, None, None
5.000, 240, None, 1.0647, 0.4725, 0.6250, 0.5382, 0.9113
5.208, 250, 0.1251, None, None, None, None, None
5.417, 260, 0.1172, None, None, None, None, None
5.625, 270, 0.1371, None, None, None, None, None
5.833, 280, 0.0793, None, None, None, None, None
6.000, 288, None, 1.1234, 0.4433, 0.6343, 0.5219, 0.8896
6.042, 290, 0.0938, None, None, None, None, None
6.250, 300, 0.0493, None, None, None, None, None
6.458, 310, 0.1052, None, None, None, None, None
6.667, 320, 0.0710, None, None, None, None, None
6.875, 330, 0.0545, None, None, None, None, None
7.000, 336, None, 1.1336, 0.4886, 0.6399, 0.5541, 0.9011
7.083, 340, 0.0669, None, None, None, None, None
7.292, 350, 0.0448, None, None, None, None, None
7.500, 360, 0.0491, None, None, None, None, None
7.708, 370, 0.0412, None, None, None, None, None
7.917, 380, 0.0450, None, None, None, None, None
8.000, 384, None, 1.1825, 0.5142, 0.6418, 0.5710, 0.9133
8.125, 390, 0.0406, None, None, None, None, None
8.333, 400, 0.0457, None, None, None, None, None
8.542, 410, 0.0469, None, None, None, None, None
8.750, 420, 0.0494, None, None, None, None, None
8.958, 430, 0.0358, None, None, None, None, None
9.000, 432, None, 1.2304, 0.5251, 0.6437, 0.5784, 0.9164
9.167, 440, 0.0261, None, None, None, None, None
9.375, 450, 0.0283, None, None, None, None, None
9.583, 460, 0.0350, None, None, None, None, None
9.792, 470, 0.0372, None, None, None, None, None
10.000, 480, 0.0399, None, None, None, None, None
10.000, 480, None, 1.2654, 0.5361, 0.6511, 0.5880, 0.9180
10.000, 480, None, None, None, None, None, None
10.000, 480, None, 1.2654, 0.5361, 0.6511, 0.5880, 0.9180

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2870, None, None, None, None, None
0.408, 20, 3.2307, None, None, None, None, None
0.612, 30, 2.7948, None, None, None, None, None
0.816, 40, 2.4717, None, None, None, None, None
1.000, 49, None, 2.1859, 0.0428, 0.4397, 0.0780, 0.1566
1.020, 50, 2.2007, None, None, None, None, None
1.224, 60, 1.7742, None, None, None, None, None
1.429, 70, 1.5439, None, None, None, None, None
1.633, 80, 1.4071, None, None, None, None, None
1.837, 90, 1.1306, None, None, None, None, None
2.000, 98, None, 1.1991, 0.1824, 0.6784, 0.2875, 0.7157
2.041, 100, 0.9900, None, None, None, None, None
2.245, 110, 0.6394, None, None, None, None, None
2.449, 120, 0.5686, None, None, None, None, None
2.653, 130, 0.6109, None, None, None, None, None
2.857, 140, 0.5794, None, None, None, None, None
3.000, 147, None, 1.1897, 0.1710, 0.6231, 0.2684, 0.5152
3.061, 150, 0.4392, None, None, None, None, None
3.265, 160, 0.3631, None, None, None, None, None
3.469, 170, 0.3769, None, None, None, None, None
3.673, 180, 0.3274, None, None, None, None, None
3.878, 190, 0.2623, None, None, None, None, None
4.000, 196, None, 1.0534, 0.2452, 0.6759, 0.3599, 0.6339
4.082, 200, 0.3262, None, None, None, None, None
4.286, 210, 0.1616, None, None, None, None, None
4.490, 220, 0.2066, None, None, None, None, None
4.694, 230, 0.1872, None, None, None, None, None
4.898, 240, 0.2617, None, None, None, None, None
5.000, 245, None, 1.0991, 0.2787, 0.5729, 0.3750, 0.7774
5.102, 250, 0.2038, None, None, None, None, None
5.306, 260, 0.2213, None, None, None, None, None
5.510, 270, 0.1186, None, None, None, None, None
5.714, 280, 0.1272, None, None, None, None, None
5.918, 290, 0.1623, None, None, None, None, None
6.000, 294, None, 1.1234, 0.3488, 0.6784, 0.4608, 0.7997
6.122, 300, 0.1645, None, None, None, None, None
6.327, 310, 0.0743, None, None, None, None, None
6.531, 320, 0.0865, None, None, None, None, None
6.735, 330, 0.0971, None, None, None, None, None
6.939, 340, 0.1507, None, None, None, None, None
7.000, 343, None, 1.3772, 0.4927, 0.6784, 0.5708, 0.9057
7.143, 350, 0.0749, None, None, None, None, None
7.347, 360, 0.0791, None, None, None, None, None
7.551, 370, 0.0747, None, None, None, None, None
7.755, 380, 0.1178, None, None, None, None, None
7.959, 390, 0.0190, None, None, None, None, None
8.000, 392, None, 1.4772, 0.5346, 0.6985, 0.6057, 0.9106
8.163, 400, 0.0405, None, None, None, None, None
8.367, 410, 0.0483, None, None, None, None, None
8.571, 420, 0.0661, None, None, None, None, None
8.776, 430, 0.0684, None, None, None, None, None
8.980, 440, 0.0546, None, None, None, None, None
9.000, 441, None, 1.4579, 0.5055, 0.6884, 0.5830, 0.9013
9.184, 450, 0.0929, None, None, None, None, None
9.388, 460, 0.0224, None, None, None, None, None
9.592, 470, 0.0208, None, None, None, None, None
9.796, 480, 0.0432, None, None, None, None, None
10.000, 490, 0.0670, None, None, None, None, None
10.000, 490, None, 1.4861, 0.5200, 0.6859, 0.5915, 0.9102
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.4861, 0.5200, 0.6859, 0.5915, 0.9102

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3242, None, None, None, None, None
0.408, 20, 3.1309, None, None, None, None, None
0.612, 30, 2.7689, None, None, None, None, None
0.816, 40, 2.7049, None, None, None, None, None
1.000, 49, None, 1.9305, 0.0705, 0.5234, 0.1243, 0.1479
1.020, 50, 2.3554, None, None, None, None, None
1.224, 60, 1.8392, None, None, None, None, None
1.429, 70, 1.5890, None, None, None, None, None
1.633, 80, 1.4383, None, None, None, None, None
1.837, 90, 1.0943, None, None, None, None, None
2.000, 98, None, 1.0056, 0.1354, 0.6393, 0.2235, 0.1431
2.041, 100, 1.3156, None, None, None, None, None
2.245, 110, 0.7814, None, None, None, None, None
2.449, 120, 0.7045, None, None, None, None, None
2.653, 130, 0.6822, None, None, None, None, None
2.857, 140, 0.7314, None, None, None, None, None
3.000, 147, None, 0.5527, 0.2291, 0.6972, 0.3449, 0.6951
3.061, 150, 0.4409, None, None, None, None, None
3.265, 160, 0.4636, None, None, None, None, None
3.469, 170, 0.3890, None, None, None, None, None
3.673, 180, 0.3816, None, None, None, None, None
3.878, 190, 0.2771, None, None, None, None, None
4.000, 196, None, 0.4079, 0.1945, 0.6224, 0.2964, 0.6558
4.082, 200, 0.3581, None, None, None, None, None
4.286, 210, 0.2273, None, None, None, None, None
4.490, 220, 0.2517, None, None, None, None, None
4.694, 230, 0.1845, None, None, None, None, None
4.898, 240, 0.3537, None, None, None, None, None
5.000, 245, None, 0.4481, 0.2646, 0.6617, 0.3780, 0.6532
5.102, 250, 0.2975, None, None, None, None, None
5.306, 260, 0.1775, None, None, None, None, None
5.510, 270, 0.2096, None, None, None, None, None
5.714, 280, 0.1978, None, None, None, None, None
5.918, 290, 0.1181, None, None, None, None, None
6.000, 294, None, 0.4363, 0.4714, 0.7234, 0.5708, 0.8797
6.122, 300, 0.1036, None, None, None, None, None
6.327, 310, 0.1211, None, None, None, None, None
6.531, 320, 0.1632, None, None, None, None, None
6.735, 330, 0.1156, None, None, None, None, None
6.939, 340, 0.0605, None, None, None, None, None
7.000, 343, None, 0.5209, 0.5586, 0.7664, 0.6462, 0.9080
7.143, 350, 0.1061, None, None, None, None, None
7.347, 360, 0.0744, None, None, None, None, None
7.551, 370, 0.0566, None, None, None, None, None
7.755, 380, 0.0960, None, None, None, None, None
7.959, 390, 0.0282, None, None, None, None, None
8.000, 392, None, 0.5297, 0.5397, 0.7364, 0.6229, 0.9076
8.163, 400, 0.0887, None, None, None, None, None
8.367, 410, 0.0618, None, None, None, None, None
8.571, 420, 0.0559, None, None, None, None, None
8.776, 430, 0.1091, None, None, None, None, None
8.980, 440, 0.0726, None, None, None, None, None
9.000, 441, None, 0.5521, 0.5760, 0.7720, 0.6597, 0.9149
9.184, 450, 0.0976, None, None, None, None, None
9.388, 460, 0.0321, None, None, None, None, None
9.592, 470, 0.0277, None, None, None, None, None
9.796, 480, 0.0307, None, None, None, None, None
10.000, 490, 0.1056, None, None, None, None, None
10.000, 490, None, 0.5596, 0.5761, 0.7645, 0.6570, 0.9159
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 0.5596, 0.5761, 0.7645, 0.6570, 0.9159

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2728, None, None, None, None, None
0.408, 20, 3.0711, None, None, None, None, None
0.612, 30, 2.9175, None, None, None, None, None
0.816, 40, 2.5615, None, None, None, None, None
1.000, 49, None, 2.1547, 0.0480, 0.3543, 0.0845, 0.3961
1.020, 50, 2.2635, None, None, None, None, None
1.224, 60, 1.7294, None, None, None, None, None
1.429, 70, 1.6342, None, None, None, None, None
1.633, 80, 1.1587, None, None, None, None, None
1.837, 90, 1.4130, None, None, None, None, None
2.000, 98, None, 1.1916, 0.1503, 0.5739, 0.2382, 0.6518
2.041, 100, 0.8570, None, None, None, None, None
2.245, 110, 0.6955, None, None, None, None, None
2.449, 120, 0.5974, None, None, None, None, None
2.653, 130, 0.4256, None, None, None, None, None
2.857, 140, 0.5381, None, None, None, None, None
3.000, 147, None, 1.0783, 0.2525, 0.6130, 0.3576, 0.7072
3.061, 150, 0.4987, None, None, None, None, None
3.265, 160, 0.3244, None, None, None, None, None
3.469, 170, 0.2818, None, None, None, None, None
3.673, 180, 0.2395, None, None, None, None, None
3.878, 190, 0.3782, None, None, None, None, None
4.000, 196, None, 0.9302, 0.2922, 0.6478, 0.4027, 0.8491
4.082, 200, 0.3503, None, None, None, None, None
4.286, 210, 0.1360, None, None, None, None, None
4.490, 220, 0.2011, None, None, None, None, None
4.694, 230, 0.2191, None, None, None, None, None
4.898, 240, 0.2038, None, None, None, None, None
5.000, 245, None, 1.2395, 0.2948, 0.5870, 0.3924, 0.8236
5.102, 250, 0.1712, None, None, None, None, None
5.306, 260, 0.1212, None, None, None, None, None
5.510, 270, 0.1339, None, None, None, None, None
5.714, 280, 0.1737, None, None, None, None, None
5.918, 290, 0.1145, None, None, None, None, None
6.000, 294, None, 1.3507, 0.4256, 0.6283, 0.5075, 0.8742
6.122, 300, 0.0950, None, None, None, None, None
6.327, 310, 0.0388, None, None, None, None, None
6.531, 320, 0.0930, None, None, None, None, None
6.735, 330, 0.1195, None, None, None, None, None
6.939, 340, 0.1083, None, None, None, None, None
7.000, 343, None, 1.3651, 0.4448, 0.6391, 0.5245, 0.8992
7.143, 350, 0.0776, None, None, None, None, None
7.347, 360, 0.0694, None, None, None, None, None
7.551, 370, 0.0819, None, None, None, None, None
7.755, 380, 0.0837, None, None, None, None, None
7.959, 390, 0.0264, None, None, None, None, None
8.000, 392, None, 1.3165, 0.5532, 0.6783, 0.6094, 0.9387
8.163, 400, 0.0408, None, None, None, None, None
8.367, 410, 0.0733, None, None, None, None, None
8.571, 420, 0.0323, None, None, None, None, None
8.776, 430, 0.0896, None, None, None, None, None
8.980, 440, 0.0196, None, None, None, None, None
9.000, 441, None, 1.3486, 0.5358, 0.6826, 0.6004, 0.9314
9.184, 450, 0.0374, None, None, None, None, None
9.388, 460, 0.0270, None, None, None, None, None
9.592, 470, 0.0418, None, None, None, None, None
9.796, 480, 0.0358, None, None, None, None, None
10.000, 490, 0.0845, None, None, None, None, None
10.000, 490, None, 1.3800, 0.5709, 0.7000, 0.6289, 0.9403
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.3800, 0.5709, 0.7000, 0.6289, 0.9403

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3034, None, None, None, None, None
0.408, 20, 3.0937, None, None, None, None, None
0.612, 30, 2.9349, None, None, None, None, None
0.816, 40, 2.6327, None, None, None, None, None
1.000, 49, None, 2.0128, 0.0558, 0.5178, 0.1007, 0.2252
1.020, 50, 2.4058, None, None, None, None, None
1.224, 60, 1.9065, None, None, None, None, None
1.429, 70, 1.4063, None, None, None, None, None
1.633, 80, 1.3480, None, None, None, None, None
1.837, 90, 1.1309, None, None, None, None, None
2.000, 98, None, 1.0339, 0.1763, 0.6467, 0.2770, 0.7023
2.041, 100, 1.2468, None, None, None, None, None
2.245, 110, 0.7139, None, None, None, None, None
2.449, 120, 0.6023, None, None, None, None, None
2.653, 130, 0.7142, None, None, None, None, None
2.857, 140, 0.6920, None, None, None, None, None
3.000, 147, None, 0.7059, 0.2705, 0.7622, 0.3993, 0.7461
3.061, 150, 0.4796, None, None, None, None, None
3.265, 160, 0.4122, None, None, None, None, None
3.469, 170, 0.3771, None, None, None, None, None
3.673, 180, 0.3338, None, None, None, None, None
3.878, 190, 0.2976, None, None, None, None, None
4.000, 196, None, 0.7366, 0.2216, 0.6333, 0.3283, 0.6989
4.082, 200, 0.3116, None, None, None, None, None
4.286, 210, 0.1601, None, None, None, None, None
4.490, 220, 0.2776, None, None, None, None, None
4.694, 230, 0.1616, None, None, None, None, None
4.898, 240, 0.2771, None, None, None, None, None
5.000, 245, None, 0.7082, 0.3228, 0.6800, 0.4378, 0.8216
5.102, 250, 0.1790, None, None, None, None, None
5.306, 260, 0.1031, None, None, None, None, None
5.510, 270, 0.1365, None, None, None, None, None
5.714, 280, 0.2859, None, None, None, None, None
5.918, 290, 0.0848, None, None, None, None, None
6.000, 294, None, 0.9164, 0.5354, 0.7400, 0.6213, 0.9141
6.122, 300, 0.0927, None, None, None, None, None
6.327, 310, 0.0607, None, None, None, None, None
6.531, 320, 0.1172, None, None, None, None, None
6.735, 330, 0.1126, None, None, None, None, None
6.939, 340, 0.0899, None, None, None, None, None
7.000, 343, None, 0.9090, 0.5475, 0.7556, 0.6349, 0.9135
7.143, 350, 0.0975, None, None, None, None, None
7.347, 360, 0.0813, None, None, None, None, None
7.551, 370, 0.0555, None, None, None, None, None
7.755, 380, 0.0648, None, None, None, None, None
7.959, 390, 0.0325, None, None, None, None, None
8.000, 392, None, 0.9983, 0.5922, 0.7711, 0.6699, 0.9280
8.163, 400, 0.0310, None, None, None, None, None
8.367, 410, 0.0414, None, None, None, None, None
8.571, 420, 0.0545, None, None, None, None, None
8.776, 430, 0.0893, None, None, None, None, None
8.980, 440, 0.0437, None, None, None, None, None
9.000, 441, None, 0.9991, 0.5945, 0.7756, 0.6731, 0.9261
9.184, 450, 0.0597, None, None, None, None, None
9.388, 460, 0.0482, None, None, None, None, None
9.592, 470, 0.0215, None, None, None, None, None
9.796, 480, 0.0313, None, None, None, None, None
10.000, 490, 0.0713, None, None, None, None, None
10.000, 490, None, 1.0062, 0.5956, 0.7756, 0.6737, 0.9272
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.0062, 0.5956, 0.7756, 0.6737, 0.9272

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.208, 10, 3.3576, None, None, None, None, None
0.417, 20, 3.1316, None, None, None, None, None
0.625, 30, 2.7200, None, None, None, None, None
0.833, 40, 2.7117, None, None, None, None, None
1.000, 48, None, 2.3677, 0.0410, 0.3713, 0.0738, 0.0974
1.042, 50, 2.2645, None, None, None, None, None
1.250, 60, 1.7316, None, None, None, None, None
1.458, 70, 1.5697, None, None, None, None, None
1.667, 80, 1.3886, None, None, None, None, None
1.875, 90, 1.0964, None, None, None, None, None
2.000, 96, None, 1.1790, 0.1685, 0.7034, 0.2719, 0.6343
2.083, 100, 1.0302, None, None, None, None, None
2.292, 110, 0.7668, None, None, None, None, None
2.500, 120, 0.6426, None, None, None, None, None
2.708, 130, 0.5181, None, None, None, None, None
2.917, 140, 0.4987, None, None, None, None, None
3.000, 144, None, 0.9413, 0.2785, 0.7201, 0.4017, 0.8030
3.125, 150, 0.4176, None, None, None, None, None
3.333, 160, 0.4838, None, None, None, None, None
3.542, 170, 0.3287, None, None, None, None, None
3.750, 180, 0.3050, None, None, None, None, None
3.958, 190, 0.4192, None, None, None, None, None
4.000, 192, None, 0.7808, 0.2551, 0.6567, 0.3674, 0.7631
4.167, 200, 0.2456, None, None, None, None, None
4.375, 210, 0.3216, None, None, None, None, None
4.583, 220, 0.1906, None, None, None, None, None
4.792, 230, 0.2074, None, None, None, None, None
5.000, 240, 0.2456, None, None, None, None, None
5.000, 240, None, 0.9620, 0.3386, 0.6343, 0.4416, 0.8657
5.208, 250, 0.1624, None, None, None, None, None
5.417, 260, 0.1418, None, None, None, None, None
5.625, 270, 0.1436, None, None, None, None, None
5.833, 280, 0.0921, None, None, None, None, None
6.000, 288, None, 1.2293, 0.5648, 0.6996, 0.6250, 0.9239
6.042, 290, 0.1123, None, None, None, None, None
6.250, 300, 0.0657, None, None, None, None, None
6.458, 310, 0.1242, None, None, None, None, None
6.667, 320, 0.1107, None, None, None, None, None
6.875, 330, 0.1079, None, None, None, None, None
7.000, 336, None, 1.1761, 0.4146, 0.6026, 0.4913, 0.8820
7.083, 340, 0.0868, None, None, None, None, None
7.292, 350, 0.1014, None, None, None, None, None
7.500, 360, 0.0695, None, None, None, None, None
7.708, 370, 0.0610, None, None, None, None, None
7.917, 380, 0.0407, None, None, None, None, None
8.000, 384, None, 1.1757, 0.4932, 0.6735, 0.5694, 0.9002
8.125, 390, 0.0510, None, None, None, None, None
8.333, 400, 0.0464, None, None, None, None, None
8.542, 410, 0.0476, None, None, None, None, None
8.750, 420, 0.0558, None, None, None, None, None
8.958, 430, 0.0543, None, None, None, None, None
9.000, 432, None, 1.3003, 0.5174, 0.6642, 0.5817, 0.9159
9.167, 440, 0.0314, None, None, None, None, None
9.375, 450, 0.0312, None, None, None, None, None
9.583, 460, 0.0562, None, None, None, None, None
9.792, 470, 0.0220, None, None, None, None, None
10.000, 480, 0.0426, None, None, None, None, None
10.000, 480, None, 1.3111, 0.5383, 0.6810, 0.6013, 0.9181
10.000, 480, None, None, None, None, None, None
10.000, 480, None, 1.3111, 0.5383, 0.6810, 0.6013, 0.9181

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2870, None, None, None, None, None
0.408, 20, 3.2308, None, None, None, None, None
0.612, 30, 2.7949, None, None, None, None, None
0.816, 40, 2.4718, None, None, None, None, None
1.000, 49, None, 2.1857, 0.0428, 0.4397, 0.0781, 0.1569
1.020, 50, 2.2006, None, None, None, None, None
1.224, 60, 1.7751, None, None, None, None, None
1.429, 70, 1.5445, None, None, None, None, None
1.633, 80, 1.4069, None, None, None, None, None
1.837, 90, 1.1290, None, None, None, None, None
2.000, 98, None, 1.2049, 0.1887, 0.6859, 0.2959, 0.7233
2.041, 100, 0.9961, None, None, None, None, None
2.245, 110, 0.6310, None, None, None, None, None
2.449, 120, 0.5720, None, None, None, None, None
2.653, 130, 0.6195, None, None, None, None, None
2.857, 140, 0.5799, None, None, None, None, None
3.000, 147, None, 1.1415, 0.1695, 0.6206, 0.2663, 0.5439
3.061, 150, 0.4421, None, None, None, None, None
3.265, 160, 0.3793, None, None, None, None, None
3.469, 170, 0.4067, None, None, None, None, None
3.673, 180, 0.3515, None, None, None, None, None
3.878, 190, 0.2772, None, None, None, None, None
4.000, 196, None, 1.0501, 0.2396, 0.6935, 0.3561, 0.6357
4.082, 200, 0.3372, None, None, None, None, None
4.286, 210, 0.1630, None, None, None, None, None
4.490, 220, 0.2512, None, None, None, None, None
4.694, 230, 0.1802, None, None, None, None, None
4.898, 240, 0.2539, None, None, None, None, None
5.000, 245, None, 1.0515, 0.2827, 0.5804, 0.3802, 0.7752
5.102, 250, 0.1945, None, None, None, None, None
5.306, 260, 0.1458, None, None, None, None, None
5.510, 270, 0.1290, None, None, None, None, None
5.714, 280, 0.1277, None, None, None, None, None
5.918, 290, 0.1405, None, None, None, None, None
6.000, 294, None, 1.1511, 0.3752, 0.6834, 0.4844, 0.8267
6.122, 300, 0.1622, None, None, None, None, None
6.327, 310, 0.0696, None, None, None, None, None
6.531, 320, 0.0947, None, None, None, None, None
6.735, 330, 0.1034, None, None, None, None, None
6.939, 340, 0.1853, None, None, None, None, None
7.000, 343, None, 1.4294, 0.4863, 0.6683, 0.5630, 0.9031
7.143, 350, 0.0761, None, None, None, None, None
7.347, 360, 0.0927, None, None, None, None, None
7.551, 370, 0.0881, None, None, None, None, None
7.755, 380, 0.1318, None, None, None, None, None
7.959, 390, 0.0197, None, None, None, None, None
8.000, 392, None, 1.6561, 0.5556, 0.6784, 0.6109, 0.9238
8.163, 400, 0.0445, None, None, None, None, None
8.367, 410, 0.0494, None, None, None, None, None
8.571, 420, 0.0821, None, None, None, None, None
8.776, 430, 0.1027, None, None, None, None, None
8.980, 440, 0.0561, None, None, None, None, None
9.000, 441, None, 1.5435, 0.5400, 0.6784, 0.6013, 0.9115
9.184, 450, 0.0958, None, None, None, None, None
9.388, 460, 0.0232, None, None, None, None, None
9.592, 470, 0.0204, None, None, None, None, None
9.796, 480, 0.0419, None, None, None, None, None
10.000, 490, 0.0648, None, None, None, None, None
10.000, 490, None, 1.5846, 0.5592, 0.6884, 0.6171, 0.9155
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.5846, 0.5592, 0.6884, 0.6171, 0.9155

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3242, None, None, None, None, None
0.408, 20, 3.1308, None, None, None, None, None
0.612, 30, 2.7688, None, None, None, None, None
0.816, 40, 2.7048, None, None, None, None, None
1.000, 49, None, 1.9304, 0.0705, 0.5234, 0.1243, 0.1478
1.020, 50, 2.3554, None, None, None, None, None
1.224, 60, 1.8398, None, None, None, None, None
1.429, 70, 1.5922, None, None, None, None, None
1.633, 80, 1.4275, None, None, None, None, None
1.837, 90, 1.0974, None, None, None, None, None
2.000, 98, None, 0.9938, 0.1340, 0.6393, 0.2216, 0.1473
2.041, 100, 1.3049, None, None, None, None, None
2.245, 110, 0.7791, None, None, None, None, None
2.449, 120, 0.7053, None, None, None, None, None
2.653, 130, 0.6722, None, None, None, None, None
2.857, 140, 0.7332, None, None, None, None, None
3.000, 147, None, 0.5450, 0.2349, 0.7215, 0.3545, 0.7035
3.061, 150, 0.4403, None, None, None, None, None
3.265, 160, 0.4422, None, None, None, None, None
3.469, 170, 0.3966, None, None, None, None, None
3.673, 180, 0.3890, None, None, None, None, None
3.878, 190, 0.3060, None, None, None, None, None
4.000, 196, None, 0.4208, 0.2271, 0.6636, 0.3384, 0.7070
4.082, 200, 0.3603, None, None, None, None, None
4.286, 210, 0.2262, None, None, None, None, None
4.490, 220, 0.2862, None, None, None, None, None
4.694, 230, 0.1883, None, None, None, None, None
4.898, 240, 0.3574, None, None, None, None, None
5.000, 245, None, 0.4450, 0.2656, 0.6673, 0.3800, 0.6473
5.102, 250, 0.3240, None, None, None, None, None
5.306, 260, 0.1731, None, None, None, None, None
5.510, 270, 0.2238, None, None, None, None, None
5.714, 280, 0.1963, None, None, None, None, None
5.918, 290, 0.1227, None, None, None, None, None
6.000, 294, None, 0.4327, 0.4515, 0.7047, 0.5504, 0.8801
6.122, 300, 0.1076, None, None, None, None, None
6.327, 310, 0.1316, None, None, None, None, None
6.531, 320, 0.1477, None, None, None, None, None
6.735, 330, 0.1197, None, None, None, None, None
6.939, 340, 0.0638, None, None, None, None, None
7.000, 343, None, 0.5018, 0.5434, 0.7720, 0.6378, 0.9014
7.143, 350, 0.1451, None, None, None, None, None
7.347, 360, 0.0793, None, None, None, None, None
7.551, 370, 0.0636, None, None, None, None, None
7.755, 380, 0.0961, None, None, None, None, None
7.959, 390, 0.0331, None, None, None, None, None
8.000, 392, None, 0.5106, 0.5383, 0.7495, 0.6266, 0.9033
8.163, 400, 0.0728, None, None, None, None, None
8.367, 410, 0.0660, None, None, None, None, None
8.571, 420, 0.0833, None, None, None, None, None
8.776, 430, 0.0976, None, None, None, None, None
8.980, 440, 0.0712, None, None, None, None, None
9.000, 441, None, 0.5416, 0.5480, 0.7364, 0.6284, 0.9097
9.184, 450, 0.0937, None, None, None, None, None
9.388, 460, 0.0333, None, None, None, None, None
9.592, 470, 0.0210, None, None, None, None, None
9.796, 480, 0.0339, None, None, None, None, None
10.000, 490, 0.1009, None, None, None, None, None
10.000, 490, None, 0.5964, 0.6226, 0.7832, 0.6937, 0.9265
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 0.5964, 0.6226, 0.7832, 0.6937, 0.9265

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2728, None, None, None, None, None
0.408, 20, 3.0711, None, None, None, None, None
0.612, 30, 2.9176, None, None, None, None, None
0.816, 40, 2.5615, None, None, None, None, None
1.000, 49, None, 2.1547, 0.0480, 0.3543, 0.0845, 0.3959
1.020, 50, 2.2635, None, None, None, None, None
1.224, 60, 1.7302, None, None, None, None, None
1.429, 70, 1.6351, None, None, None, None, None
1.633, 80, 1.1656, None, None, None, None, None
1.837, 90, 1.4036, None, None, None, None, None
2.000, 98, None, 1.2006, 0.1501, 0.5761, 0.2382, 0.6400
2.041, 100, 0.8626, None, None, None, None, None
2.245, 110, 0.7071, None, None, None, None, None
2.449, 120, 0.5993, None, None, None, None, None
2.653, 130, 0.4290, None, None, None, None, None
2.857, 140, 0.5181, None, None, None, None, None
3.000, 147, None, 1.0640, 0.2527, 0.6087, 0.3571, 0.7084
3.061, 150, 0.4904, None, None, None, None, None
3.265, 160, 0.3282, None, None, None, None, None
3.469, 170, 0.2889, None, None, None, None, None
3.673, 180, 0.2278, None, None, None, None, None
3.878, 190, 0.3650, None, None, None, None, None
4.000, 196, None, 0.9354, 0.2998, 0.6543, 0.4112, 0.8494
4.082, 200, 0.3618, None, None, None, None, None
4.286, 210, 0.1425, None, None, None, None, None
4.490, 220, 0.2120, None, None, None, None, None
4.694, 230, 0.2206, None, None, None, None, None
4.898, 240, 0.1925, None, None, None, None, None
5.000, 245, None, 1.2116, 0.2997, 0.5674, 0.3922, 0.8290
5.102, 250, 0.1574, None, None, None, None, None
5.306, 260, 0.1217, None, None, None, None, None
5.510, 270, 0.1397, None, None, None, None, None
5.714, 280, 0.1855, None, None, None, None, None
5.918, 290, 0.1278, None, None, None, None, None
6.000, 294, None, 1.3936, 0.4331, 0.6543, 0.5212, 0.8819
6.122, 300, 0.1010, None, None, None, None, None
6.327, 310, 0.0521, None, None, None, None, None
6.531, 320, 0.0899, None, None, None, None, None
6.735, 330, 0.1320, None, None, None, None, None
6.939, 340, 0.1106, None, None, None, None, None
7.000, 343, None, 1.4211, 0.4020, 0.6239, 0.4889, 0.8780
7.143, 350, 0.0810, None, None, None, None, None
7.347, 360, 0.0859, None, None, None, None, None
7.551, 370, 0.0854, None, None, None, None, None
7.755, 380, 0.0810, None, None, None, None, None
7.959, 390, 0.0265, None, None, None, None, None
8.000, 392, None, 1.4585, 0.5017, 0.6609, 0.5704, 0.9056
8.163, 400, 0.0450, None, None, None, None, None
8.367, 410, 0.0684, None, None, None, None, None
8.571, 420, 0.0347, None, None, None, None, None
8.776, 430, 0.1772, None, None, None, None, None
8.980, 440, 0.0226, None, None, None, None, None
9.000, 441, None, 1.4241, 0.5315, 0.6783, 0.5960, 0.9314
9.184, 450, 0.0338, None, None, None, None, None
9.388, 460, 0.0257, None, None, None, None, None
9.592, 470, 0.0491, None, None, None, None, None
9.796, 480, 0.0376, None, None, None, None, None
10.000, 490, 0.0818, None, None, None, None, None
10.000, 490, None, 1.4855, 0.5453, 0.6804, 0.6054, 0.9379
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.4855, 0.5453, 0.6804, 0.6054, 0.9379

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3034, None, None, None, None, None
0.408, 20, 3.0937, None, None, None, None, None
0.612, 30, 2.9349, None, None, None, None, None
0.816, 40, 2.6328, None, None, None, None, None
1.000, 49, None, 2.0129, 0.0558, 0.5178, 0.1007, 0.2252
1.020, 50, 2.4060, None, None, None, None, None
1.224, 60, 1.9074, None, None, None, None, None
1.429, 70, 1.4097, None, None, None, None, None
1.633, 80, 1.3474, None, None, None, None, None
1.837, 90, 1.1354, None, None, None, None, None
2.000, 98, None, 1.0138, 0.1716, 0.6511, 0.2717, 0.6895
2.041, 100, 1.2432, None, None, None, None, None
2.245, 110, 0.7075, None, None, None, None, None
2.449, 120, 0.6165, None, None, None, None, None
2.653, 130, 0.7203, None, None, None, None, None
2.857, 140, 0.7000, None, None, None, None, None
3.000, 147, None, 0.7002, 0.2554, 0.7644, 0.3829, 0.7223
3.061, 150, 0.4685, None, None, None, None, None
3.265, 160, 0.3922, None, None, None, None, None
3.469, 170, 0.3831, None, None, None, None, None
3.673, 180, 0.3490, None, None, None, None, None
3.878, 190, 0.3007, None, None, None, None, None
4.000, 196, None, 0.7256, 0.2504, 0.6556, 0.3624, 0.7511
4.082, 200, 0.3172, None, None, None, None, None
4.286, 210, 0.1535, None, None, None, None, None
4.490, 220, 0.2609, None, None, None, None, None
4.694, 230, 0.1775, None, None, None, None, None
4.898, 240, 0.3033, None, None, None, None, None
5.000, 245, None, 0.6963, 0.3366, 0.6956, 0.4536, 0.8247
5.102, 250, 0.1839, None, None, None, None, None
5.306, 260, 0.0992, None, None, None, None, None
5.510, 270, 0.1743, None, None, None, None, None
5.714, 280, 0.2764, None, None, None, None, None
5.918, 290, 0.0889, None, None, None, None, None
6.000, 294, None, 0.8802, 0.5638, 0.7556, 0.6458, 0.9234
6.122, 300, 0.0848, None, None, None, None, None
6.327, 310, 0.0648, None, None, None, None, None
6.531, 320, 0.1297, None, None, None, None, None
6.735, 330, 0.1079, None, None, None, None, None
6.939, 340, 0.0929, None, None, None, None, None
7.000, 343, None, 0.9040, 0.5370, 0.7578, 0.6286, 0.9116
7.143, 350, 0.1043, None, None, None, None, None
7.347, 360, 0.0845, None, None, None, None, None
7.551, 370, 0.0603, None, None, None, None, None
7.755, 380, 0.0680, None, None, None, None, None
7.959, 390, 0.0312, None, None, None, None, None
8.000, 392, None, 1.0548, 0.6024, 0.7844, 0.6815, 0.9323
8.163, 400, 0.0382, None, None, None, None, None
8.367, 410, 0.0368, None, None, None, None, None
8.571, 420, 0.0634, None, None, None, None, None
8.776, 430, 0.1042, None, None, None, None, None
8.980, 440, 0.0498, None, None, None, None, None
9.000, 441, None, 1.0417, 0.5935, 0.7689, 0.6699, 0.9280
9.184, 450, 0.0545, None, None, None, None, None
9.388, 460, 0.0394, None, None, None, None, None
9.592, 470, 0.0298, None, None, None, None, None
9.796, 480, 0.0371, None, None, None, None, None
10.000, 490, 0.0681, None, None, None, None, None
10.000, 490, None, 1.0869, 0.6154, 0.7822, 0.6888, 0.9323
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.0869, 0.6154, 0.7822, 0.6888, 0.9323

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.208, 10, 3.3576, None, None, None, None, None
0.417, 20, 3.1316, None, None, None, None, None
0.625, 30, 2.7201, None, None, None, None, None
0.833, 40, 2.7118, None, None, None, None, None
1.000, 48, None, 2.3680, 0.0410, 0.3713, 0.0738, 0.0975
1.042, 50, 2.2647, None, None, None, None, None
1.250, 60, 1.7309, None, None, None, None, None
1.458, 70, 1.5699, None, None, None, None, None
1.667, 80, 1.3871, None, None, None, None, None
1.875, 90, 1.0964, None, None, None, None, None
2.000, 96, None, 1.1768, 0.1677, 0.7052, 0.2710, 0.6244
2.083, 100, 1.0327, None, None, None, None, None
2.292, 110, 0.7985, None, None, None, None, None
2.500, 120, 0.6528, None, None, None, None, None
2.708, 130, 0.5161, None, None, None, None, None
2.917, 140, 0.5092, None, None, None, None, None
3.000, 144, None, 0.9729, 0.2771, 0.6959, 0.3964, 0.8129
3.125, 150, 0.4249, None, None, None, None, None
3.333, 160, 0.4864, None, None, None, None, None
3.542, 170, 0.3240, None, None, None, None, None
3.750, 180, 0.3353, None, None, None, None, None
3.958, 190, 0.4678, None, None, None, None, None
4.000, 192, None, 0.8197, 0.2542, 0.6231, 0.3611, 0.7661
4.167, 200, 0.2381, None, None, None, None, None
4.375, 210, 0.3178, None, None, None, None, None
4.583, 220, 0.1830, None, None, None, None, None
4.792, 230, 0.1845, None, None, None, None, None
5.000, 240, 0.2256, None, None, None, None, None
5.000, 240, None, 0.9671, 0.3738, 0.6493, 0.4744, 0.8749
5.208, 250, 0.1501, None, None, None, None, None
5.417, 260, 0.1166, None, None, None, None, None
5.625, 270, 0.1172, None, None, None, None, None
5.833, 280, 0.0920, None, None, None, None, None
6.000, 288, None, 1.1817, 0.5192, 0.6810, 0.5892, 0.9085
6.042, 290, 0.1003, None, None, None, None, None
6.250, 300, 0.0586, None, None, None, None, None
6.458, 310, 0.1114, None, None, None, None, None
6.667, 320, 0.0823, None, None, None, None, None
6.875, 330, 0.0898, None, None, None, None, None
7.000, 336, None, 1.0854, 0.4431, 0.6325, 0.5211, 0.8893
7.083, 340, 0.0608, None, None, None, None, None
7.292, 350, 0.0730, None, None, None, None, None
7.500, 360, 0.0593, None, None, None, None, None
7.708, 370, 0.0561, None, None, None, None, None
7.917, 380, 0.0313, None, None, None, None, None
8.000, 384, None, 1.1711, 0.5114, 0.6698, 0.5800, 0.9116
8.125, 390, 0.0449, None, None, None, None, None
8.333, 400, 0.0438, None, None, None, None, None
8.542, 410, 0.0475, None, None, None, None, None
8.750, 420, 0.0465, None, None, None, None, None
8.958, 430, 0.0498, None, None, None, None, None
9.000, 432, None, 1.2385, 0.5301, 0.6735, 0.5933, 0.9170
9.167, 440, 0.0317, None, None, None, None, None
9.375, 450, 0.0363, None, None, None, None, None
9.583, 460, 0.0599, None, None, None, None, None
9.792, 470, 0.0219, None, None, None, None, None
10.000, 480, 0.0433, None, None, None, None, None
10.000, 480, None, 1.2420, 0.5365, 0.6847, 0.6016, 0.9180
10.000, 480, None, None, None, None, None, None
10.000, 480, None, 1.2420, 0.5365, 0.6847, 0.6016, 0.9180

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2870, None, None, None, None, None
0.408, 20, 3.2307, None, None, None, None, None
0.612, 30, 2.7948, None, None, None, None, None
0.816, 40, 2.4717, None, None, None, None, None
1.000, 49, None, 2.1857, 0.0431, 0.4422, 0.0785, 0.1571
1.020, 50, 2.2007, None, None, None, None, None
1.224, 60, 1.7742, None, None, None, None, None
1.429, 70, 1.5438, None, None, None, None, None
1.633, 80, 1.4071, None, None, None, None, None
1.837, 90, 1.1310, None, None, None, None, None
2.000, 98, None, 1.1991, 0.1822, 0.6784, 0.2872, 0.7150
2.041, 100, 0.9899, None, None, None, None, None
2.245, 110, 0.6402, None, None, None, None, None
2.449, 120, 0.5690, None, None, None, None, None
2.653, 130, 0.6111, None, None, None, None, None
2.857, 140, 0.5800, None, None, None, None, None
3.000, 147, None, 1.1890, 0.1712, 0.6231, 0.2685, 0.5134
3.061, 150, 0.4397, None, None, None, None, None
3.265, 160, 0.3637, None, None, None, None, None
3.469, 170, 0.3787, None, None, None, None, None
3.673, 180, 0.3281, None, None, None, None, None
3.878, 190, 0.2626, None, None, None, None, None
4.000, 196, None, 1.0550, 0.2468, 0.6759, 0.3616, 0.6344
4.082, 200, 0.3292, None, None, None, None, None
4.286, 210, 0.1616, None, None, None, None, None
4.490, 220, 0.2117, None, None, None, None, None
4.694, 230, 0.1929, None, None, None, None, None
4.898, 240, 0.2568, None, None, None, None, None
5.000, 245, None, 1.0936, 0.2767, 0.5603, 0.3704, 0.7779
5.102, 250, 0.2082, None, None, None, None, None
5.306, 260, 0.2000, None, None, None, None, None
5.510, 270, 0.1195, None, None, None, None, None
5.714, 280, 0.1255, None, None, None, None, None
5.918, 290, 0.1609, None, None, None, None, None
6.000, 294, None, 1.1225, 0.3536, 0.6734, 0.4637, 0.8093
6.122, 300, 0.1627, None, None, None, None, None
6.327, 310, 0.0742, None, None, None, None, None
6.531, 320, 0.0867, None, None, None, None, None
6.735, 330, 0.0937, None, None, None, None, None
6.939, 340, 0.1489, None, None, None, None, None
7.000, 343, None, 1.3780, 0.4954, 0.6759, 0.5717, 0.9048
7.143, 350, 0.0754, None, None, None, None, None
7.347, 360, 0.0814, None, None, None, None, None
7.551, 370, 0.0780, None, None, None, None, None
7.755, 380, 0.1138, None, None, None, None, None
7.959, 390, 0.0193, None, None, None, None, None
8.000, 392, None, 1.4712, 0.5355, 0.7010, 0.6072, 0.9109
8.163, 400, 0.0420, None, None, None, None, None
8.367, 410, 0.0498, None, None, None, None, None
8.571, 420, 0.0653, None, None, None, None, None
8.776, 430, 0.0685, None, None, None, None, None
8.980, 440, 0.0544, None, None, None, None, None
9.000, 441, None, 1.4498, 0.5093, 0.6884, 0.5855, 0.9015
9.184, 450, 0.0914, None, None, None, None, None
9.388, 460, 0.0225, None, None, None, None, None
9.592, 470, 0.0210, None, None, None, None, None
9.796, 480, 0.0435, None, None, None, None, None
10.000, 490, 0.0683, None, None, None, None, None
10.000, 490, None, 1.4772, 0.5249, 0.6884, 0.5957, 0.9082
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.4772, 0.5249, 0.6884, 0.5957, 0.9082

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3242, None, None, None, None, None
0.408, 20, 3.1309, None, None, None, None, None
0.612, 30, 2.7689, None, None, None, None, None
0.816, 40, 2.7048, None, None, None, None, None
1.000, 49, None, 1.9305, 0.0705, 0.5234, 0.1243, 0.1478
1.020, 50, 2.3554, None, None, None, None, None
1.224, 60, 1.8392, None, None, None, None, None
1.429, 70, 1.5889, None, None, None, None, None
1.633, 80, 1.4384, None, None, None, None, None
1.837, 90, 1.0942, None, None, None, None, None
2.000, 98, None, 1.0058, 0.1356, 0.6393, 0.2237, 0.1431
2.041, 100, 1.3154, None, None, None, None, None
2.245, 110, 0.7814, None, None, None, None, None
2.449, 120, 0.7046, None, None, None, None, None
2.653, 130, 0.6821, None, None, None, None, None
2.857, 140, 0.7310, None, None, None, None, None
3.000, 147, None, 0.5533, 0.2287, 0.6972, 0.3444, 0.6951
3.061, 150, 0.4408, None, None, None, None, None
3.265, 160, 0.4633, None, None, None, None, None
3.469, 170, 0.3886, None, None, None, None, None
3.673, 180, 0.3807, None, None, None, None, None
3.878, 190, 0.2773, None, None, None, None, None
4.000, 196, None, 0.4083, 0.1943, 0.6224, 0.2961, 0.6559
4.082, 200, 0.3595, None, None, None, None, None
4.286, 210, 0.2281, None, None, None, None, None
4.490, 220, 0.2508, None, None, None, None, None
4.694, 230, 0.1848, None, None, None, None, None
4.898, 240, 0.3550, None, None, None, None, None
5.000, 245, None, 0.4471, 0.2624, 0.6617, 0.3758, 0.6507
5.102, 250, 0.2988, None, None, None, None, None
5.306, 260, 0.1812, None, None, None, None, None
5.510, 270, 0.2083, None, None, None, None, None
5.714, 280, 0.2023, None, None, None, None, None
5.918, 290, 0.1183, None, None, None, None, None
6.000, 294, None, 0.4376, 0.4732, 0.7252, 0.5727, 0.8817
6.122, 300, 0.1033, None, None, None, None, None
6.327, 310, 0.1223, None, None, None, None, None
6.531, 320, 0.1544, None, None, None, None, None
6.735, 330, 0.1157, None, None, None, None, None
6.939, 340, 0.0596, None, None, None, None, None
7.000, 343, None, 0.5215, 0.5524, 0.7682, 0.6427, 0.9047
7.143, 350, 0.1076, None, None, None, None, None
7.347, 360, 0.0739, None, None, None, None, None
7.551, 370, 0.0567, None, None, None, None, None
7.755, 380, 0.0974, None, None, None, None, None
7.959, 390, 0.0286, None, None, None, None, None
8.000, 392, None, 0.5248, 0.5286, 0.7421, 0.6174, 0.9049
8.163, 400, 0.0871, None, None, None, None, None
8.367, 410, 0.0618, None, None, None, None, None
8.571, 420, 0.0586, None, None, None, None, None
8.776, 430, 0.1108, None, None, None, None, None
8.980, 440, 0.0727, None, None, None, None, None
9.000, 441, None, 0.5546, 0.5732, 0.7682, 0.6565, 0.9140
9.184, 450, 0.0997, None, None, None, None, None
9.388, 460, 0.0320, None, None, None, None, None
9.592, 470, 0.0288, None, None, None, None, None
9.796, 480, 0.0308, None, None, None, None, None
10.000, 490, 0.1045, None, None, None, None, None
10.000, 490, None, 0.5623, 0.5756, 0.7682, 0.6581, 0.9157
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 0.5623, 0.5756, 0.7682, 0.6581, 0.9157

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2728, None, None, None, None, None
0.408, 20, 3.0710, None, None, None, None, None
0.612, 30, 2.9176, None, None, None, None, None
0.816, 40, 2.5615, None, None, None, None, None
1.000, 49, None, 2.1547, 0.0480, 0.3543, 0.0845, 0.3958
1.020, 50, 2.2636, None, None, None, None, None
1.224, 60, 1.7295, None, None, None, None, None
1.429, 70, 1.6343, None, None, None, None, None
1.633, 80, 1.1589, None, None, None, None, None
1.837, 90, 1.4130, None, None, None, None, None
2.000, 98, None, 1.1914, 0.1504, 0.5739, 0.2384, 0.6525
2.041, 100, 0.8574, None, None, None, None, None
2.245, 110, 0.6958, None, None, None, None, None
2.449, 120, 0.5970, None, None, None, None, None
2.653, 130, 0.4260, None, None, None, None, None
2.857, 140, 0.5384, None, None, None, None, None
3.000, 147, None, 1.0770, 0.2565, 0.6217, 0.3632, 0.7075
3.061, 150, 0.4986, None, None, None, None, None
3.265, 160, 0.3243, None, None, None, None, None
3.469, 170, 0.2826, None, None, None, None, None
3.673, 180, 0.2372, None, None, None, None, None
3.878, 190, 0.3825, None, None, None, None, None
4.000, 196, None, 0.9295, 0.2917, 0.6457, 0.4019, 0.8477
4.082, 200, 0.3486, None, None, None, None, None
4.286, 210, 0.1349, None, None, None, None, None
4.490, 220, 0.2054, None, None, None, None, None
4.694, 230, 0.2138, None, None, None, None, None
4.898, 240, 0.2054, None, None, None, None, None
5.000, 245, None, 1.2304, 0.2980, 0.5870, 0.3953, 0.8259
5.102, 250, 0.1604, None, None, None, None, None
5.306, 260, 0.1221, None, None, None, None, None
5.510, 270, 0.1311, None, None, None, None, None
5.714, 280, 0.1743, None, None, None, None, None
5.918, 290, 0.1098, None, None, None, None, None
6.000, 294, None, 1.3281, 0.4305, 0.6326, 0.5123, 0.8802
6.122, 300, 0.0915, None, None, None, None, None
6.327, 310, 0.0370, None, None, None, None, None
6.531, 320, 0.0946, None, None, None, None, None
6.735, 330, 0.1149, None, None, None, None, None
6.939, 340, 0.1066, None, None, None, None, None
7.000, 343, None, 1.3807, 0.4387, 0.6304, 0.5174, 0.8927
7.143, 350, 0.0770, None, None, None, None, None
7.347, 360, 0.0649, None, None, None, None, None
7.551, 370, 0.0909, None, None, None, None, None
7.755, 380, 0.0846, None, None, None, None, None
7.959, 390, 0.0267, None, None, None, None, None
8.000, 392, None, 1.3557, 0.5550, 0.6804, 0.6113, 0.9424
8.163, 400, 0.0432, None, None, None, None, None
8.367, 410, 0.0728, None, None, None, None, None
8.571, 420, 0.0336, None, None, None, None, None
8.776, 430, 0.0891, None, None, None, None, None
8.980, 440, 0.0198, None, None, None, None, None
9.000, 441, None, 1.3649, 0.5273, 0.6717, 0.5908, 0.9311
9.184, 450, 0.0365, None, None, None, None, None
9.388, 460, 0.0268, None, None, None, None, None
9.592, 470, 0.0446, None, None, None, None, None
9.796, 480, 0.0369, None, None, None, None, None
10.000, 490, 0.0849, None, None, None, None, None
10.000, 490, None, 1.3958, 0.5628, 0.6913, 0.6205, 0.9395
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.3958, 0.5628, 0.6913, 0.6205, 0.9395

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3034, None, None, None, None, None
0.408, 20, 3.0937, None, None, None, None, None
0.612, 30, 2.9349, None, None, None, None, None
0.816, 40, 2.6328, None, None, None, None, None
1.000, 49, None, 2.0129, 0.0558, 0.5178, 0.1008, 0.2249
1.020, 50, 2.4059, None, None, None, None, None
1.224, 60, 1.9066, None, None, None, None, None
1.429, 70, 1.4063, None, None, None, None, None
1.633, 80, 1.3480, None, None, None, None, None
1.837, 90, 1.1311, None, None, None, None, None
2.000, 98, None, 1.0349, 0.1762, 0.6467, 0.2769, 0.7025
2.041, 100, 1.2472, None, None, None, None, None
2.245, 110, 0.7140, None, None, None, None, None
2.449, 120, 0.6030, None, None, None, None, None
2.653, 130, 0.7139, None, None, None, None, None
2.857, 140, 0.6924, None, None, None, None, None
3.000, 147, None, 0.7057, 0.2709, 0.7622, 0.3998, 0.7457
3.061, 150, 0.4797, None, None, None, None, None
3.265, 160, 0.4123, None, None, None, None, None
3.469, 170, 0.3792, None, None, None, None, None
3.673, 180, 0.3344, None, None, None, None, None
3.878, 190, 0.2974, None, None, None, None, None
4.000, 196, None, 0.7374, 0.2224, 0.6356, 0.3295, 0.6990
4.082, 200, 0.3124, None, None, None, None, None
4.286, 210, 0.1598, None, None, None, None, None
4.490, 220, 0.2764, None, None, None, None, None
4.694, 230, 0.1608, None, None, None, None, None
4.898, 240, 0.2773, None, None, None, None, None
5.000, 245, None, 0.7100, 0.3231, 0.6800, 0.4381, 0.8211
5.102, 250, 0.1747, None, None, None, None, None
5.306, 260, 0.1035, None, None, None, None, None
5.510, 270, 0.1360, None, None, None, None, None
5.714, 280, 0.2866, None, None, None, None, None
5.918, 290, 0.0846, None, None, None, None, None
6.000, 294, None, 0.9172, 0.5345, 0.7400, 0.6207, 0.9147
6.122, 300, 0.0922, None, None, None, None, None
6.327, 310, 0.0607, None, None, None, None, None
6.531, 320, 0.1181, None, None, None, None, None
6.735, 330, 0.1141, None, None, None, None, None
6.939, 340, 0.0895, None, None, None, None, None
7.000, 343, None, 0.9068, 0.5449, 0.7556, 0.6331, 0.9128
7.143, 350, 0.0959, None, None, None, None, None
7.347, 360, 0.0808, None, None, None, None, None
7.551, 370, 0.0562, None, None, None, None, None
7.755, 380, 0.0680, None, None, None, None, None
7.959, 390, 0.0322, None, None, None, None, None
8.000, 392, None, 0.9963, 0.5939, 0.7733, 0.6718, 0.9272
8.163, 400, 0.0348, None, None, None, None, None
8.367, 410, 0.0415, None, None, None, None, None
8.571, 420, 0.0541, None, None, None, None, None
8.776, 430, 0.0851, None, None, None, None, None
8.980, 440, 0.0436, None, None, None, None, None
9.000, 441, None, 0.9995, 0.5963, 0.7778, 0.6750, 0.9259
9.184, 450, 0.0596, None, None, None, None, None
9.388, 460, 0.0481, None, None, None, None, None
9.592, 470, 0.0216, None, None, None, None, None
9.796, 480, 0.0315, None, None, None, None, None
10.000, 490, 0.0712, None, None, None, None, None
10.000, 490, None, 1.0058, 0.5952, 0.7778, 0.6744, 0.9275
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.0058, 0.5952, 0.7778, 0.6744, 0.9275

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.208, 10, 3.3576, None, None, None, None, None
0.417, 20, 3.1316, None, None, None, None, None
0.625, 30, 2.7201, None, None, None, None, None
0.833, 40, 2.7117, None, None, None, None, None
1.000, 48, None, 2.3678, 0.0410, 0.3713, 0.0738, 0.0972
1.042, 50, 2.2646, None, None, None, None, None
1.250, 60, 1.7315, None, None, None, None, None
1.458, 70, 1.5696, None, None, None, None, None
1.667, 80, 1.3884, None, None, None, None, None
1.875, 90, 1.0963, None, None, None, None, None
2.000, 96, None, 1.1787, 0.1687, 0.7034, 0.2721, 0.6343
2.083, 100, 1.0299, None, None, None, None, None
2.292, 110, 0.7666, None, None, None, None, None
2.500, 120, 0.6429, None, None, None, None, None
2.708, 130, 0.5180, None, None, None, None, None
2.917, 140, 0.4990, None, None, None, None, None
3.000, 144, None, 0.9397, 0.2780, 0.7183, 0.4008, 0.8035
3.125, 150, 0.4180, None, None, None, None, None
3.333, 160, 0.4850, None, None, None, None, None
3.542, 170, 0.3293, None, None, None, None, None
3.750, 180, 0.3043, None, None, None, None, None
3.958, 190, 0.4177, None, None, None, None, None
4.000, 192, None, 0.7806, 0.2554, 0.6567, 0.3678, 0.7629
4.167, 200, 0.2464, None, None, None, None, None
4.375, 210, 0.3211, None, None, None, None, None
4.583, 220, 0.1893, None, None, None, None, None
4.792, 230, 0.2075, None, None, None, None, None
5.000, 240, 0.2439, None, None, None, None, None
5.000, 240, None, 0.9695, 0.3356, 0.6325, 0.4386, 0.8639
5.208, 250, 0.1630, None, None, None, None, None
5.417, 260, 0.1405, None, None, None, None, None
5.625, 270, 0.1441, None, None, None, None, None
5.833, 280, 0.0925, None, None, None, None, None
6.000, 288, None, 1.2198, 0.5675, 0.6978, 0.6259, 0.9242
6.042, 290, 0.1129, None, None, None, None, None
6.250, 300, 0.0662, None, None, None, None, None
6.458, 310, 0.1235, None, None, None, None, None
6.667, 320, 0.1130, None, None, None, None, None
6.875, 330, 0.1116, None, None, None, None, None
7.000, 336, None, 1.1728, 0.4031, 0.5896, 0.4788, 0.8806
7.083, 340, 0.0795, None, None, None, None, None
7.292, 350, 0.1027, None, None, None, None, None
7.500, 360, 0.0687, None, None, None, None, None
7.708, 370, 0.0639, None, None, None, None, None
7.917, 380, 0.0429, None, None, None, None, None
8.000, 384, None, 1.1688, 0.4952, 0.6791, 0.5728, 0.9000
8.125, 390, 0.0501, None, None, None, None, None
8.333, 400, 0.0478, None, None, None, None, None
8.542, 410, 0.0469, None, None, None, None, None
8.750, 420, 0.0570, None, None, None, None, None
8.958, 430, 0.0536, None, None, None, None, None
9.000, 432, None, 1.2682, 0.5256, 0.6698, 0.5890, 0.9165
9.167, 440, 0.0308, None, None, None, None, None
9.375, 450, 0.0310, None, None, None, None, None
9.583, 460, 0.0569, None, None, None, None, None
9.792, 470, 0.0223, None, None, None, None, None
10.000, 480, 0.0426, None, None, None, None, None
10.000, 480, None, 1.3290, 0.5446, 0.6828, 0.6060, 0.9197
10.000, 480, None, None, None, None, None, None
10.000, 480, None, 1.3290, 0.5446, 0.6828, 0.6060, 0.9197

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2870, None, None, None, None, None
0.408, 20, 3.2308, None, None, None, None, None
0.612, 30, 2.7948, None, None, None, None, None
0.816, 40, 2.4717, None, None, None, None, None
1.000, 49, None, 2.1858, 0.0429, 0.4397, 0.0781, 0.1569
1.020, 50, 2.2007, None, None, None, None, None
1.224, 60, 1.7750, None, None, None, None, None
1.429, 70, 1.5447, None, None, None, None, None
1.633, 80, 1.4066, None, None, None, None, None
1.837, 90, 1.1290, None, None, None, None, None
2.000, 98, None, 1.2046, 0.1888, 0.6859, 0.2961, 0.7235
2.041, 100, 0.9955, None, None, None, None, None
2.245, 110, 0.6317, None, None, None, None, None
2.449, 120, 0.5722, None, None, None, None, None
2.653, 130, 0.6195, None, None, None, None, None
2.857, 140, 0.5796, None, None, None, None, None
3.000, 147, None, 1.1414, 0.1699, 0.6206, 0.2667, 0.5432
3.061, 150, 0.4418, None, None, None, None, None
3.265, 160, 0.3802, None, None, None, None, None
3.469, 170, 0.4051, None, None, None, None, None
3.673, 180, 0.3510, None, None, None, None, None
3.878, 190, 0.2766, None, None, None, None, None
4.000, 196, None, 1.0543, 0.2390, 0.6960, 0.3558, 0.6292
4.082, 200, 0.3375, None, None, None, None, None
4.286, 210, 0.1638, None, None, None, None, None
4.490, 220, 0.2471, None, None, None, None, None
4.694, 230, 0.1844, None, None, None, None, None
4.898, 240, 0.2540, None, None, None, None, None
5.000, 245, None, 1.0477, 0.2845, 0.5854, 0.3829, 0.7754
5.102, 250, 0.1961, None, None, None, None, None
5.306, 260, 0.1375, None, None, None, None, None
5.510, 270, 0.1260, None, None, None, None, None
5.714, 280, 0.1237, None, None, None, None, None
5.918, 290, 0.1394, None, None, None, None, None
6.000, 294, None, 1.1367, 0.3618, 0.6709, 0.4701, 0.8213
6.122, 300, 0.1727, None, None, None, None, None
6.327, 310, 0.0839, None, None, None, None, None
6.531, 320, 0.0951, None, None, None, None, None
6.735, 330, 0.0967, None, None, None, None, None
6.939, 340, 0.1607, None, None, None, None, None
7.000, 343, None, 1.3965, 0.4673, 0.6633, 0.5483, 0.9000
7.143, 350, 0.0831, None, None, None, None, None
7.347, 360, 0.0909, None, None, None, None, None
7.551, 370, 0.0899, None, None, None, None, None
7.755, 380, 0.1659, None, None, None, None, None
7.959, 390, 0.0204, None, None, None, None, None
8.000, 392, None, 1.5646, 0.5621, 0.6935, 0.6209, 0.9251
8.163, 400, 0.0444, None, None, None, None, None
8.367, 410, 0.0557, None, None, None, None, None
8.571, 420, 0.0768, None, None, None, None, None
8.776, 430, 0.0904, None, None, None, None, None
8.980, 440, 0.0588, None, None, None, None, None
9.000, 441, None, 1.4886, 0.5430, 0.6985, 0.6110, 0.9129
9.184, 450, 0.0984, None, None, None, None, None
9.388, 460, 0.0211, None, None, None, None, None
9.592, 470, 0.0178, None, None, None, None, None
9.796, 480, 0.0401, None, None, None, None, None
10.000, 490, 0.0697, None, None, None, None, None
10.000, 490, None, 1.5315, 0.5663, 0.7085, 0.6295, 0.9169
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.5315, 0.5663, 0.7085, 0.6295, 0.9169

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3242, None, None, None, None, None
0.408, 20, 3.1309, None, None, None, None, None
0.612, 30, 2.7689, None, None, None, None, None
0.816, 40, 2.7048, None, None, None, None, None
1.000, 49, None, 1.9305, 0.0705, 0.5234, 0.1243, 0.1478
1.020, 50, 2.3553, None, None, None, None, None
1.224, 60, 1.8397, None, None, None, None, None
1.429, 70, 1.5920, None, None, None, None, None
1.633, 80, 1.4273, None, None, None, None, None
1.837, 90, 1.0974, None, None, None, None, None
2.000, 98, None, 0.9940, 0.1341, 0.6393, 0.2216, 0.1473
2.041, 100, 1.3048, None, None, None, None, None
2.245, 110, 0.7790, None, None, None, None, None
2.449, 120, 0.7053, None, None, None, None, None
2.653, 130, 0.6722, None, None, None, None, None
2.857, 140, 0.7330, None, None, None, None, None
3.000, 147, None, 0.5447, 0.2348, 0.7215, 0.3543, 0.7034
3.061, 150, 0.4407, None, None, None, None, None
3.265, 160, 0.4424, None, None, None, None, None
3.469, 170, 0.3965, None, None, None, None, None
3.673, 180, 0.3888, None, None, None, None, None
3.878, 190, 0.3066, None, None, None, None, None
4.000, 196, None, 0.4210, 0.2269, 0.6654, 0.3384, 0.7053
4.082, 200, 0.3612, None, None, None, None, None
4.286, 210, 0.2260, None, None, None, None, None
4.490, 220, 0.2874, None, None, None, None, None
4.694, 230, 0.1882, None, None, None, None, None
4.898, 240, 0.3579, None, None, None, None, None
5.000, 245, None, 0.4446, 0.2641, 0.6654, 0.3781, 0.6467
5.102, 250, 0.3215, None, None, None, None, None
5.306, 260, 0.1727, None, None, None, None, None
5.510, 270, 0.2230, None, None, None, None, None
5.714, 280, 0.1967, None, None, None, None, None
5.918, 290, 0.1225, None, None, None, None, None
6.000, 294, None, 0.4340, 0.4518, 0.7009, 0.5495, 0.8803
6.122, 300, 0.1070, None, None, None, None, None
6.327, 310, 0.1305, None, None, None, None, None
6.531, 320, 0.1465, None, None, None, None, None
6.735, 330, 0.1210, None, None, None, None, None
6.939, 340, 0.0635, None, None, None, None, None
7.000, 343, None, 0.5041, 0.5428, 0.7701, 0.6368, 0.9010
7.143, 350, 0.1426, None, None, None, None, None
7.347, 360, 0.0791, None, None, None, None, None
7.551, 370, 0.0627, None, None, None, None, None
7.755, 380, 0.0954, None, None, None, None, None
7.959, 390, 0.0329, None, None, None, None, None
8.000, 392, None, 0.5116, 0.5376, 0.7477, 0.6255, 0.9033
8.163, 400, 0.0731, None, None, None, None, None
8.367, 410, 0.0665, None, None, None, None, None
8.571, 420, 0.0809, None, None, None, None, None
8.776, 430, 0.0987, None, None, None, None, None
8.980, 440, 0.0705, None, None, None, None, None
9.000, 441, None, 0.5404, 0.5458, 0.7346, 0.6263, 0.9096
9.184, 450, 0.0912, None, None, None, None, None
9.388, 460, 0.0335, None, None, None, None, None
9.592, 470, 0.0206, None, None, None, None, None
9.796, 480, 0.0338, None, None, None, None, None
10.000, 490, 0.1031, None, None, None, None, None
10.000, 490, None, 0.5977, 0.6272, 0.7832, 0.6966, 0.9262
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 0.5977, 0.6272, 0.7832, 0.6966, 0.9262

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2727, None, None, None, None, None
0.408, 20, 3.0711, None, None, None, None, None
0.612, 30, 2.9175, None, None, None, None, None
0.816, 40, 2.5615, None, None, None, None, None
1.000, 49, None, 2.1547, 0.0480, 0.3543, 0.0845, 0.3959
1.020, 50, 2.2636, None, None, None, None, None
1.224, 60, 1.7303, None, None, None, None, None
1.429, 70, 1.6351, None, None, None, None, None
1.633, 80, 1.1655, None, None, None, None, None
1.837, 90, 1.4035, None, None, None, None, None
2.000, 98, None, 1.2002, 0.1502, 0.5761, 0.2383, 0.6401
2.041, 100, 0.8624, None, None, None, None, None
2.245, 110, 0.7072, None, None, None, None, None
2.449, 120, 0.5995, None, None, None, None, None
2.653, 130, 0.4286, None, None, None, None, None
2.857, 140, 0.5186, None, None, None, None, None
3.000, 147, None, 1.0635, 0.2529, 0.6087, 0.3574, 0.7090
3.061, 150, 0.4906, None, None, None, None, None
3.265, 160, 0.3280, None, None, None, None, None
3.469, 170, 0.2891, None, None, None, None, None
3.673, 180, 0.2283, None, None, None, None, None
3.878, 190, 0.3639, None, None, None, None, None
4.000, 196, None, 0.9370, 0.2989, 0.6543, 0.4104, 0.8497
4.082, 200, 0.3616, None, None, None, None, None
4.286, 210, 0.1432, None, None, None, None, None
4.490, 220, 0.2104, None, None, None, None, None
4.694, 230, 0.2193, None, None, None, None, None
4.898, 240, 0.1928, None, None, None, None, None
5.000, 245, None, 1.2110, 0.2951, 0.5652, 0.3878, 0.8265
5.102, 250, 0.1604, None, None, None, None, None
5.306, 260, 0.1240, None, None, None, None, None
5.510, 270, 0.1415, None, None, None, None, None
5.714, 280, 0.1851, None, None, None, None, None
5.918, 290, 0.1292, None, None, None, None, None
6.000, 294, None, 1.4027, 0.4362, 0.6543, 0.5235, 0.8847
6.122, 300, 0.1019, None, None, None, None, None
6.327, 310, 0.0514, None, None, None, None, None
6.531, 320, 0.0916, None, None, None, None, None
6.735, 330, 0.1326, None, None, None, None, None
6.939, 340, 0.1082, None, None, None, None, None
7.000, 343, None, 1.4026, 0.4065, 0.6239, 0.4923, 0.8819
7.143, 350, 0.0808, None, None, None, None, None
7.347, 360, 0.0830, None, None, None, None, None
7.551, 370, 0.0848, None, None, None, None, None
7.755, 380, 0.0801, None, None, None, None, None
7.959, 390, 0.0280, None, None, None, None, None
8.000, 392, None, 1.4715, 0.4959, 0.6652, 0.5682, 0.8949
8.163, 400, 0.0442, None, None, None, None, None
8.367, 410, 0.0697, None, None, None, None, None
8.571, 420, 0.0347, None, None, None, None, None
8.776, 430, 0.1830, None, None, None, None, None
8.980, 440, 0.0228, None, None, None, None, None
9.000, 441, None, 1.4008, 0.5254, 0.6739, 0.5905, 0.9325
9.184, 450, 0.0340, None, None, None, None, None
9.388, 460, 0.0259, None, None, None, None, None
9.592, 470, 0.0496, None, None, None, None, None
9.796, 480, 0.0364, None, None, None, None, None
10.000, 490, 0.0818, None, None, None, None, None
10.000, 490, None, 1.4647, 0.5390, 0.6761, 0.5998, 0.9386
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.4647, 0.5390, 0.6761, 0.5998, 0.9386

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3034, None, None, None, None, None
0.408, 20, 3.0937, None, None, None, None, None
0.612, 30, 2.9349, None, None, None, None, None
0.816, 40, 2.6328, None, None, None, None, None
1.000, 49, None, 2.0128, 0.0558, 0.5178, 0.1008, 0.2252
1.020, 50, 2.4059, None, None, None, None, None
1.224, 60, 1.9073, None, None, None, None, None
1.429, 70, 1.4098, None, None, None, None, None
1.633, 80, 1.3474, None, None, None, None, None
1.837, 90, 1.1355, None, None, None, None, None
2.000, 98, None, 1.0143, 0.1714, 0.6511, 0.2714, 0.6888
2.041, 100, 1.2435, None, None, None, None, None
2.245, 110, 0.7075, None, None, None, None, None
2.449, 120, 0.6170, None, None, None, None, None
2.653, 130, 0.7195, None, None, None, None, None
2.857, 140, 0.7003, None, None, None, None, None
3.000, 147, None, 0.7000, 0.2567, 0.7667, 0.3846, 0.7226
3.061, 150, 0.4685, None, None, None, None, None
3.265, 160, 0.3927, None, None, None, None, None
3.469, 170, 0.3832, None, None, None, None, None
3.673, 180, 0.3490, None, None, None, None, None
3.878, 190, 0.3003, None, None, None, None, None
4.000, 196, None, 0.7285, 0.2494, 0.6533, 0.3610, 0.7502
4.082, 200, 0.3183, None, None, None, None, None
4.286, 210, 0.1530, None, None, None, None, None
4.490, 220, 0.2592, None, None, None, None, None
4.694, 230, 0.1776, None, None, None, None, None
4.898, 240, 0.3031, None, None, None, None, None
5.000, 245, None, 0.6983, 0.3362, 0.6978, 0.4538, 0.8238
5.102, 250, 0.1830, None, None, None, None, None
5.306, 260, 0.0999, None, None, None, None, None
5.510, 270, 0.1734, None, None, None, None, None
5.714, 280, 0.2775, None, None, None, None, None
5.918, 290, 0.0903, None, None, None, None, None
6.000, 294, None, 0.8767, 0.5618, 0.7578, 0.6452, 0.9244
6.122, 300, 0.0859, None, None, None, None, None
6.327, 310, 0.0659, None, None, None, None, None
6.531, 320, 0.1322, None, None, None, None, None
6.735, 330, 0.1058, None, None, None, None, None
6.939, 340, 0.0952, None, None, None, None, None
7.000, 343, None, 0.8988, 0.5339, 0.7533, 0.6249, 0.9083
7.143, 350, 0.1076, None, None, None, None, None
7.347, 360, 0.0817, None, None, None, None, None
7.551, 370, 0.0569, None, None, None, None, None
7.755, 380, 0.0694, None, None, None, None, None
7.959, 390, 0.0314, None, None, None, None, None
8.000, 392, None, 1.0608, 0.6062, 0.7867, 0.6847, 0.9336
8.163, 400, 0.0398, None, None, None, None, None
8.367, 410, 0.0363, None, None, None, None, None
8.571, 420, 0.0681, None, None, None, None, None
8.776, 430, 0.1007, None, None, None, None, None
8.980, 440, 0.0476, None, None, None, None, None
9.000, 441, None, 1.0306, 0.5894, 0.7689, 0.6673, 0.9273
9.184, 450, 0.0559, None, None, None, None, None
9.388, 460, 0.0399, None, None, None, None, None
9.592, 470, 0.0294, None, None, None, None, None
9.796, 480, 0.0360, None, None, None, None, None
10.000, 490, 0.0667, None, None, None, None, None
10.000, 490, None, 1.0747, 0.6094, 0.7800, 0.6842, 0.9319
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.0747, 0.6094, 0.7800, 0.6842, 0.9319

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.417, 10, 3.2617, None, None, None, None, None
0.833, 20, 2.9183, None, None, None, None, None
1.000, 24, None, 2.5389, 0.0222, 0.2481, 0.0408, 0.0522
1.250, 30, 2.3139, None, None, None, None, None
1.667, 40, 1.9380, None, None, None, None, None
2.000, 48, None, 1.4723, 0.1314, 0.6474, 0.2185, 0.5987
2.083, 50, 1.4168, None, None, None, None, None
2.500, 60, 0.9764, None, None, None, None, None
2.917, 70, 0.7634, None, None, None, None, None
3.000, 72, None, 1.0520, 0.1451, 0.6847, 0.2394, 0.3501
3.333, 80, 0.5578, None, None, None, None, None
3.750, 90, 0.4831, None, None, None, None, None
4.000, 96, None, 0.9856, 0.1782, 0.6250, 0.2773, 0.6518
4.167, 100, 0.3926, None, None, None, None, None
4.583, 110, 0.3537, None, None, None, None, None
5.000, 120, 0.3119, None, None, None, None, None
5.000, 120, None, 0.8855, 0.2774, 0.6325, 0.3857, 0.7800
5.417, 130, 0.2217, None, None, None, None, None
5.833, 140, 0.1913, None, None, None, None, None
6.000, 144, None, 0.8390, 0.3013, 0.6437, 0.4105, 0.7877
6.250, 150, 0.1419, None, None, None, None, None
6.667, 160, 0.1445, None, None, None, None, None
7.000, 168, None, 1.0595, 0.3894, 0.6306, 0.4815, 0.8724
7.083, 170, 0.1297, None, None, None, None, None
7.500, 180, 0.0984, None, None, None, None, None
7.917, 190, 0.0909, None, None, None, None, None
8.000, 192, None, 0.9959, 0.3801, 0.6269, 0.4732, 0.8724
8.333, 200, 0.0796, None, None, None, None, None
8.750, 210, 0.0953, None, None, None, None, None
9.000, 216, None, 1.0102, 0.4184, 0.6455, 0.5077, 0.8839
9.167, 220, 0.0730, None, None, None, None, None
9.583, 230, 0.0843, None, None, None, None, None
10.000, 240, 0.0626, None, None, None, None, None
10.000, 240, None, 1.0362, 0.4265, 0.6437, 0.5130, 0.8875
10.000, 240, None, None, None, None, None, None
10.000, 240, None, 1.0362, 0.4265, 0.6437, 0.5130, 0.8875

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2865, None, None, None, None, None
0.800, 20, 2.8067, None, None, None, None, None
1.000, 25, None, 2.4964, 0.0216, 0.2588, 0.0398, 0.0463
1.200, 30, 2.4436, None, None, None, None, None
1.600, 40, 1.9337, None, None, None, None, None
2.000, 50, 1.5553, None, None, None, None, None
2.000, 50, None, 1.5598, 0.0921, 0.6055, 0.1599, 0.4287
2.400, 60, 1.0528, None, None, None, None, None
2.800, 70, 0.8283, None, None, None, None, None
3.000, 75, None, 1.3053, 0.1408, 0.5578, 0.2248, 0.5450
3.200, 80, 0.6521, None, None, None, None, None
3.600, 90, 0.5828, None, None, None, None, None
4.000, 100, 0.5249, None, None, None, None, None
4.000, 100, None, 1.0755, 0.2029, 0.6784, 0.3123, 0.6341
4.400, 110, 0.3069, None, None, None, None, None
4.800, 120, 0.3773, None, None, None, None, None
5.000, 125, None, 0.9912, 0.2345, 0.6181, 0.3400, 0.7533
5.200, 130, 0.2860, None, None, None, None, None
5.600, 140, 0.2208, None, None, None, None, None
6.000, 150, 0.2222, None, None, None, None, None
6.000, 150, None, 1.0187, 0.2644, 0.6457, 0.3752, 0.7716
6.400, 160, 0.1595, None, None, None, None, None
6.800, 170, 0.1599, None, None, None, None, None
7.000, 175, None, 1.0968, 0.3602, 0.6508, 0.4637, 0.8527
7.200, 180, 0.1497, None, None, None, None, None
7.600, 190, 0.1205, None, None, None, None, None
8.000, 200, 0.1091, None, None, None, None, None
8.000, 200, None, 1.1003, 0.3795, 0.6683, 0.4841, 0.8578
8.400, 210, 0.0779, None, None, None, None, None
8.800, 220, 0.1425, None, None, None, None, None
9.000, 225, None, 1.1689, 0.4224, 0.6633, 0.5161, 0.8728
9.200, 230, 0.0833, None, None, None, None, None
9.600, 240, 0.0690, None, None, None, None, None
10.000, 250, 0.0989, None, None, None, None, None
10.000, 250, None, 1.1636, 0.4224, 0.6633, 0.5161, 0.8714
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1636, 0.4224, 0.6633, 0.5161, 0.8714

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2397, None, None, None, None, None
0.800, 20, 2.8779, None, None, None, None, None
1.000, 25, None, 2.2396, 0.0377, 0.3981, 0.0688, 0.0677
1.200, 30, 2.4154, None, None, None, None, None
1.600, 40, 1.9333, None, None, None, None, None
2.000, 50, 1.4688, None, None, None, None, None
2.000, 50, None, 1.2156, 0.1159, 0.6056, 0.1945, 0.3203
2.400, 60, 1.0139, None, None, None, None, None
2.800, 70, 0.9467, None, None, None, None, None
3.000, 75, None, 0.6050, 0.1594, 0.7252, 0.2614, 0.5252
3.200, 80, 0.5849, None, None, None, None, None
3.600, 90, 0.4807, None, None, None, None, None
4.000, 100, 0.4523, None, None, None, None, None
4.000, 100, None, 0.4398, 0.3306, 0.7477, 0.4585, 0.7869
4.400, 110, 0.2947, None, None, None, None, None
4.800, 120, 0.2798, None, None, None, None, None
5.000, 125, None, 0.4530, 0.2461, 0.7570, 0.3714, 0.6040
5.200, 130, 0.3212, None, None, None, None, None
5.600, 140, 0.2367, None, None, None, None, None
6.000, 150, 0.1574, None, None, None, None, None
6.000, 150, None, 0.3749, 0.4078, 0.7402, 0.5259, 0.8475
6.400, 160, 0.1733, None, None, None, None, None
6.800, 170, 0.1356, None, None, None, None, None
7.000, 175, None, 0.3771, 0.3614, 0.6972, 0.4761, 0.8207
7.200, 180, 0.1051, None, None, None, None, None
7.600, 190, 0.0914, None, None, None, None, None
8.000, 200, 0.1062, None, None, None, None, None
8.000, 200, None, 0.3837, 0.4677, 0.7439, 0.5743, 0.8770
8.400, 210, 0.0902, None, None, None, None, None
8.800, 220, 0.0886, None, None, None, None, None
9.000, 225, None, 0.3882, 0.4645, 0.7327, 0.5685, 0.8706
9.200, 230, 0.0911, None, None, None, None, None
9.600, 240, 0.0640, None, None, None, None, None
10.000, 250, 0.1024, None, None, None, None, None
10.000, 250, None, 0.3886, 0.4782, 0.7364, 0.5798, 0.8808
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.3886, 0.4782, 0.7364, 0.5798, 0.8808

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2200, None, None, None, None, None
0.800, 20, 2.8992, None, None, None, None, None
1.000, 25, None, 2.4104, 0.0314, 0.3913, 0.0581, 0.0809
1.200, 30, 2.3201, None, None, None, None, None
1.600, 40, 1.8603, None, None, None, None, None
2.000, 50, 1.5058, None, None, None, None, None
2.000, 50, None, 1.4734, 0.1059, 0.5696, 0.1787, 0.4722
2.400, 60, 1.0043, None, None, None, None, None
2.800, 70, 0.7239, None, None, None, None, None
3.000, 75, None, 1.0191, 0.1516, 0.6478, 0.2457, 0.4795
3.200, 80, 0.5542, None, None, None, None, None
3.600, 90, 0.3976, None, None, None, None, None
4.000, 100, 0.5281, None, None, None, None, None
4.000, 100, None, 1.1294, 0.1951, 0.6196, 0.2967, 0.6897
4.400, 110, 0.2606, None, None, None, None, None
4.800, 120, 0.3672, None, None, None, None, None
5.000, 125, None, 0.9330, 0.2718, 0.6304, 0.3798, 0.8276
5.200, 130, 0.2347, None, None, None, None, None
5.600, 140, 0.1830, None, None, None, None, None
6.000, 150, 0.1813, None, None, None, None, None
6.000, 150, None, 0.9157, 0.3126, 0.6326, 0.4184, 0.8466
6.400, 160, 0.1480, None, None, None, None, None
6.800, 170, 0.1336, None, None, None, None, None
7.000, 175, None, 1.0916, 0.3424, 0.6304, 0.4438, 0.8401
7.200, 180, 0.1332, None, None, None, None, None
7.600, 190, 0.1077, None, None, None, None, None
8.000, 200, 0.0959, None, None, None, None, None
8.000, 200, None, 1.0425, 0.4072, 0.6630, 0.5045, 0.8783
8.400, 210, 0.0904, None, None, None, None, None
8.800, 220, 0.0916, None, None, None, None, None
9.000, 225, None, 1.0938, 0.4444, 0.6609, 0.5315, 0.9020
9.200, 230, 0.0656, None, None, None, None, None
9.600, 240, 0.0657, None, None, None, None, None
10.000, 250, 0.1047, None, None, None, None, None
10.000, 250, None, 1.0991, 0.4528, 0.6565, 0.5359, 0.9050
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.0991, 0.4528, 0.6565, 0.5359, 0.9050

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2209, None, None, None, None, None
0.800, 20, 2.9283, None, None, None, None, None
1.000, 25, None, 2.2132, 0.0364, 0.4600, 0.0675, 0.0734
1.200, 30, 2.4041, None, None, None, None, None
1.600, 40, 1.9090, None, None, None, None, None
2.000, 50, 1.4818, None, None, None, None, None
2.000, 50, None, 1.2143, 0.1229, 0.6711, 0.2078, 0.5127
2.400, 60, 1.0249, None, None, None, None, None
2.800, 70, 0.8384, None, None, None, None, None
3.000, 75, None, 0.7329, 0.1666, 0.7689, 0.2738, 0.6052
3.200, 80, 0.5856, None, None, None, None, None
3.600, 90, 0.4411, None, None, None, None, None
4.000, 100, 0.4465, None, None, None, None, None
4.000, 100, None, 0.6886, 0.2260, 0.6911, 0.3406, 0.7383
4.400, 110, 0.2661, None, None, None, None, None
4.800, 120, 0.3245, None, None, None, None, None
5.000, 125, None, 0.6643, 0.2651, 0.6844, 0.3821, 0.7203
5.200, 130, 0.2623, None, None, None, None, None
5.600, 140, 0.2162, None, None, None, None, None
6.000, 150, 0.1731, None, None, None, None, None
6.000, 150, None, 0.6910, 0.3768, 0.6800, 0.4849, 0.8625
6.400, 160, 0.1448, None, None, None, None, None
6.800, 170, 0.1387, None, None, None, None, None
7.000, 175, None, 0.7267, 0.4399, 0.7156, 0.5448, 0.8846
7.200, 180, 0.1419, None, None, None, None, None
7.600, 190, 0.0864, None, None, None, None, None
8.000, 200, 0.0752, None, None, None, None, None
8.000, 200, None, 0.7908, 0.5030, 0.7422, 0.5996, 0.9029
8.400, 210, 0.0652, None, None, None, None, None
8.800, 220, 0.0950, None, None, None, None, None
9.000, 225, None, 0.8010, 0.5008, 0.7378, 0.5966, 0.9002
9.200, 230, 0.0798, None, None, None, None, None
9.600, 240, 0.0651, None, None, None, None, None
10.000, 250, 0.0786, None, None, None, None, None
10.000, 250, None, 0.8103, 0.5107, 0.7400, 0.6044, 0.9039
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.8103, 0.5107, 0.7400, 0.6044, 0.9039

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.417, 10, 3.2617, None, None, None, None, None
0.833, 20, 2.9183, None, None, None, None, None
1.000, 24, None, 2.5390, 0.0222, 0.2481, 0.0408, 0.0522
1.250, 30, 2.3142, None, None, None, None, None
1.667, 40, 1.9430, None, None, None, None, None
2.000, 48, None, 1.5033, 0.1297, 0.6455, 0.2160, 0.5987
2.083, 50, 1.4338, None, None, None, None, None
2.500, 60, 1.0016, None, None, None, None, None
2.917, 70, 0.7924, None, None, None, None, None
3.000, 72, None, 1.0643, 0.1406, 0.6716, 0.2326, 0.3447
3.333, 80, 0.5865, None, None, None, None, None
3.750, 90, 0.4970, None, None, None, None, None
4.000, 96, None, 0.9999, 0.1735, 0.6306, 0.2721, 0.6476
4.167, 100, 0.4084, None, None, None, None, None
4.583, 110, 0.3769, None, None, None, None, None
5.000, 120, 0.3429, None, None, None, None, None
5.000, 120, None, 0.8642, 0.2583, 0.6119, 0.3632, 0.7783
5.417, 130, 0.2498, None, None, None, None, None
5.833, 140, 0.1908, None, None, None, None, None
6.000, 144, None, 0.8320, 0.2669, 0.6474, 0.3780, 0.7401
6.250, 150, 0.1628, None, None, None, None, None
6.667, 160, 0.1781, None, None, None, None, None
7.000, 168, None, 1.0343, 0.3788, 0.6119, 0.4679, 0.8754
7.083, 170, 0.1539, None, None, None, None, None
7.500, 180, 0.1115, None, None, None, None, None
7.917, 190, 0.0968, None, None, None, None, None
8.000, 192, None, 1.0556, 0.4188, 0.6493, 0.5091, 0.8868
8.333, 200, 0.0843, None, None, None, None, None
8.750, 210, 0.0974, None, None, None, None, None
9.000, 216, None, 1.1066, 0.4484, 0.6399, 0.5273, 0.9006
9.167, 220, 0.0748, None, None, None, None, None
9.583, 230, 0.0759, None, None, None, None, None
10.000, 240, 0.0649, None, None, None, None, None
10.000, 240, None, 1.1547, 0.4501, 0.6399, 0.5285, 0.9010
10.000, 240, None, None, None, None, None, None
10.000, 240, None, 1.1547, 0.4501, 0.6399, 0.5285, 0.9010

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2864, None, None, None, None, None
0.800, 20, 2.8068, None, None, None, None, None
1.000, 25, None, 2.4964, 0.0216, 0.2588, 0.0398, 0.0463
1.200, 30, 2.4438, None, None, None, None, None
1.600, 40, 1.9381, None, None, None, None, None
2.000, 50, 1.5727, None, None, None, None, None
2.000, 50, None, 1.5762, 0.0935, 0.6156, 0.1624, 0.4385
2.400, 60, 1.0831, None, None, None, None, None
2.800, 70, 0.8450, None, None, None, None, None
3.000, 75, None, 1.2982, 0.1377, 0.5704, 0.2219, 0.5390
3.200, 80, 0.6716, None, None, None, None, None
3.600, 90, 0.6185, None, None, None, None, None
4.000, 100, 0.5648, None, None, None, None, None
4.000, 100, None, 1.0943, 0.2111, 0.6683, 0.3209, 0.7017
4.400, 110, 0.3475, None, None, None, None, None
4.800, 120, 0.4022, None, None, None, None, None
5.000, 125, None, 0.9843, 0.2216, 0.6131, 0.3256, 0.7475
5.200, 130, 0.3077, None, None, None, None, None
5.600, 140, 0.2366, None, None, None, None, None
6.000, 150, 0.2488, None, None, None, None, None
6.000, 150, None, 0.9873, 0.2727, 0.6633, 0.3865, 0.7843
6.400, 160, 0.1791, None, None, None, None, None
6.800, 170, 0.1887, None, None, None, None, None
7.000, 175, None, 1.0634, 0.3442, 0.6658, 0.4538, 0.8304
7.200, 180, 0.1601, None, None, None, None, None
7.600, 190, 0.1299, None, None, None, None, None
8.000, 200, 0.1240, None, None, None, None, None
8.000, 200, None, 1.1369, 0.4161, 0.6608, 0.5107, 0.8687
8.400, 210, 0.0838, None, None, None, None, None
8.800, 220, 0.1505, None, None, None, None, None
9.000, 225, None, 1.1551, 0.4028, 0.6508, 0.4976, 0.8716
9.200, 230, 0.0802, None, None, None, None, None
9.600, 240, 0.0705, None, None, None, None, None
10.000, 250, 0.0958, None, None, None, None, None
10.000, 250, None, 1.1781, 0.4241, 0.6533, 0.5143, 0.8766
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1781, 0.4241, 0.6533, 0.5143, 0.8766

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2397, None, None, None, None, None
0.800, 20, 2.8780, None, None, None, None, None
1.000, 25, None, 2.2395, 0.0377, 0.3981, 0.0688, 0.0677
1.200, 30, 2.4155, None, None, None, None, None
1.600, 40, 1.9349, None, None, None, None, None
2.000, 50, 1.4804, None, None, None, None, None
2.000, 50, None, 1.2320, 0.1134, 0.6075, 0.1912, 0.3206
2.400, 60, 1.0345, None, None, None, None, None
2.800, 70, 0.9652, None, None, None, None, None
3.000, 75, None, 0.6269, 0.1555, 0.7271, 0.2562, 0.5166
3.200, 80, 0.6138, None, None, None, None, None
3.600, 90, 0.5099, None, None, None, None, None
4.000, 100, 0.4801, None, None, None, None, None
4.000, 100, None, 0.4694, 0.3580, 0.7607, 0.4868, 0.8391
4.400, 110, 0.3317, None, None, None, None, None
4.800, 120, 0.3181, None, None, None, None, None
5.000, 125, None, 0.4526, 0.2389, 0.7626, 0.3638, 0.6023
5.200, 130, 0.3473, None, None, None, None, None
5.600, 140, 0.2534, None, None, None, None, None
6.000, 150, 0.1756, None, None, None, None, None
6.000, 150, None, 0.3907, 0.4036, 0.7477, 0.5242, 0.8507
6.400, 160, 0.1918, None, None, None, None, None
6.800, 170, 0.1543, None, None, None, None, None
7.000, 175, None, 0.3880, 0.3687, 0.7271, 0.4893, 0.7972
7.200, 180, 0.1270, None, None, None, None, None
7.600, 190, 0.0976, None, None, None, None, None
8.000, 200, 0.1173, None, None, None, None, None
8.000, 200, None, 0.4120, 0.4653, 0.7383, 0.5708, 0.8732
8.400, 210, 0.0978, None, None, None, None, None
8.800, 220, 0.1015, None, None, None, None, None
9.000, 225, None, 0.3977, 0.4443, 0.7159, 0.5483, 0.8645
9.200, 230, 0.0895, None, None, None, None, None
9.600, 240, 0.0675, None, None, None, None, None
10.000, 250, 0.1081, None, None, None, None, None
10.000, 250, None, 0.4160, 0.5187, 0.7514, 0.6137, 0.9011
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.4160, 0.5187, 0.7514, 0.6137, 0.9011

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2200, None, None, None, None, None
0.800, 20, 2.8992, None, None, None, None, None
1.000, 25, None, 2.4104, 0.0314, 0.3913, 0.0582, 0.0809
1.200, 30, 2.3203, None, None, None, None, None
1.600, 40, 1.8651, None, None, None, None, None
2.000, 50, 1.5137, None, None, None, None, None
2.000, 50, None, 1.4877, 0.1030, 0.5630, 0.1741, 0.4546
2.400, 60, 1.0205, None, None, None, None, None
2.800, 70, 0.7393, None, None, None, None, None
3.000, 75, None, 1.0407, 0.1472, 0.6478, 0.2398, 0.4444
3.200, 80, 0.5734, None, None, None, None, None
3.600, 90, 0.4213, None, None, None, None, None
4.000, 100, 0.5049, None, None, None, None, None
4.000, 100, None, 1.0300, 0.2022, 0.6478, 0.3082, 0.7044
4.400, 110, 0.2586, None, None, None, None, None
4.800, 120, 0.3781, None, None, None, None, None
5.000, 125, None, 0.9138, 0.2629, 0.6304, 0.3711, 0.8171
5.200, 130, 0.2388, None, None, None, None, None
5.600, 140, 0.1967, None, None, None, None, None
6.000, 150, 0.2047, None, None, None, None, None
6.000, 150, None, 0.9967, 0.3124, 0.6500, 0.4220, 0.8276
6.400, 160, 0.1715, None, None, None, None, None
6.800, 170, 0.1436, None, None, None, None, None
7.000, 175, None, 1.1157, 0.3508, 0.6391, 0.4530, 0.8551
7.200, 180, 0.1480, None, None, None, None, None
7.600, 190, 0.1408, None, None, None, None, None
8.000, 200, 0.1027, None, None, None, None, None
8.000, 200, None, 1.0679, 0.3946, 0.6674, 0.4960, 0.8754
8.400, 210, 0.0927, None, None, None, None, None
8.800, 220, 0.1049, None, None, None, None, None
9.000, 225, None, 1.1433, 0.4618, 0.6696, 0.5466, 0.8980
9.200, 230, 0.0689, None, None, None, None, None
9.600, 240, 0.0588, None, None, None, None, None
10.000, 250, 0.1066, None, None, None, None, None
10.000, 250, None, 1.1464, 0.4792, 0.6761, 0.5609, 0.9067
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1464, 0.4792, 0.6761, 0.5609, 0.9067

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2209, None, None, None, None, None
0.800, 20, 2.9283, None, None, None, None, None
1.000, 25, None, 2.2132, 0.0364, 0.4600, 0.0675, 0.0734
1.200, 30, 2.4043, None, None, None, None, None
1.600, 40, 1.9147, None, None, None, None, None
2.000, 50, 1.4932, None, None, None, None, None
2.000, 50, None, 1.2341, 0.1209, 0.6667, 0.2047, 0.5055
2.400, 60, 1.0462, None, None, None, None, None
2.800, 70, 0.8534, None, None, None, None, None
3.000, 75, None, 0.7473, 0.1648, 0.7711, 0.2715, 0.6039
3.200, 80, 0.6133, None, None, None, None, None
3.600, 90, 0.4632, None, None, None, None, None
4.000, 100, 0.4533, None, None, None, None, None
4.000, 100, None, 0.6825, 0.2161, 0.7044, 0.3307, 0.7168
4.400, 110, 0.2671, None, None, None, None, None
4.800, 120, 0.3213, None, None, None, None, None
5.000, 125, None, 0.6329, 0.2447, 0.6733, 0.3590, 0.7097
5.200, 130, 0.2754, None, None, None, None, None
5.600, 140, 0.2456, None, None, None, None, None
6.000, 150, 0.2011, None, None, None, None, None
6.000, 150, None, 0.6792, 0.3720, 0.6844, 0.4820, 0.8562
6.400, 160, 0.1693, None, None, None, None, None
6.800, 170, 0.1495, None, None, None, None, None
7.000, 175, None, 0.7395, 0.4684, 0.7422, 0.5744, 0.8926
7.200, 180, 0.1530, None, None, None, None, None
7.600, 190, 0.1020, None, None, None, None, None
8.000, 200, 0.0901, None, None, None, None, None
8.000, 200, None, 0.8074, 0.5168, 0.7533, 0.6130, 0.9053
8.400, 210, 0.0647, None, None, None, None, None
8.800, 220, 0.1142, None, None, None, None, None
9.000, 225, None, 0.7951, 0.4882, 0.7378, 0.5876, 0.8965
9.200, 230, 0.0798, None, None, None, None, None
9.600, 240, 0.0563, None, None, None, None, None
10.000, 250, 0.0775, None, None, None, None, None
10.000, 250, None, 0.8724, 0.5484, 0.7556, 0.6355, 0.9160
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.8724, 0.5484, 0.7556, 0.6355, 0.9160

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.417, 10, 3.2617, None, None, None, None, None
0.833, 20, 2.9183, None, None, None, None, None
1.000, 24, None, 2.5390, 0.0222, 0.2481, 0.0408, 0.0522
1.250, 30, 2.3139, None, None, None, None, None
1.667, 40, 1.9379, None, None, None, None, None
2.000, 48, None, 1.4715, 0.1318, 0.6493, 0.2191, 0.5985
2.083, 50, 1.4162, None, None, None, None, None
2.500, 60, 0.9761, None, None, None, None, None
2.917, 70, 0.7634, None, None, None, None, None
3.000, 72, None, 1.0523, 0.1451, 0.6847, 0.2394, 0.3505
3.333, 80, 0.5577, None, None, None, None, None
3.750, 90, 0.4833, None, None, None, None, None
4.000, 96, None, 0.9875, 0.1785, 0.6250, 0.2777, 0.6510
4.167, 100, 0.3929, None, None, None, None, None
4.583, 110, 0.3540, None, None, None, None, None
5.000, 120, 0.3150, None, None, None, None, None
5.000, 120, None, 0.8936, 0.2764, 0.6306, 0.3843, 0.7798
5.417, 130, 0.2219, None, None, None, None, None
5.833, 140, 0.1923, None, None, None, None, None
6.000, 144, None, 0.8408, 0.3017, 0.6474, 0.4116, 0.7882
6.250, 150, 0.1424, None, None, None, None, None
6.667, 160, 0.1449, None, None, None, None, None
7.000, 168, None, 1.0688, 0.3855, 0.6250, 0.4769, 0.8724
7.083, 170, 0.1300, None, None, None, None, None
7.500, 180, 0.0984, None, None, None, None, None
7.917, 190, 0.0909, None, None, None, None, None
8.000, 192, None, 1.0116, 0.3801, 0.6269, 0.4732, 0.8724
8.333, 200, 0.0798, None, None, None, None, None
8.750, 210, 0.0953, None, None, None, None, None
9.000, 216, None, 1.0246, 0.4187, 0.6437, 0.5074, 0.8841
9.167, 220, 0.0729, None, None, None, None, None
9.583, 230, 0.0840, None, None, None, None, None
10.000, 240, 0.0626, None, None, None, None, None
10.000, 240, None, 1.0491, 0.4279, 0.6474, 0.5152, 0.8878
10.000, 240, None, None, None, None, None, None
10.000, 240, None, 1.0491, 0.4279, 0.6474, 0.5152, 0.8878

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2864, None, None, None, None, None
0.800, 20, 2.8067, None, None, None, None, None
1.000, 25, None, 2.4964, 0.0216, 0.2588, 0.0398, 0.0463
1.200, 30, 2.4436, None, None, None, None, None
1.600, 40, 1.9337, None, None, None, None, None
2.000, 50, 1.5554, None, None, None, None, None
2.000, 50, None, 1.5596, 0.0921, 0.6055, 0.1599, 0.4294
2.400, 60, 1.0528, None, None, None, None, None
2.800, 70, 0.8283, None, None, None, None, None
3.000, 75, None, 1.3057, 0.1405, 0.5578, 0.2245, 0.5444
3.200, 80, 0.6524, None, None, None, None, None
3.600, 90, 0.5830, None, None, None, None, None
4.000, 100, 0.5252, None, None, None, None, None
4.000, 100, None, 1.0752, 0.2038, 0.6809, 0.3137, 0.6343
4.400, 110, 0.3063, None, None, None, None, None
4.800, 120, 0.3773, None, None, None, None, None
5.000, 125, None, 0.9913, 0.2326, 0.6131, 0.3372, 0.7529
5.200, 130, 0.2861, None, None, None, None, None
5.600, 140, 0.2208, None, None, None, None, None
6.000, 150, 0.2220, None, None, None, None, None
6.000, 150, None, 1.0186, 0.2639, 0.6457, 0.3746, 0.7710
6.400, 160, 0.1595, None, None, None, None, None
6.800, 170, 0.1596, None, None, None, None, None
7.000, 175, None, 1.0964, 0.3611, 0.6533, 0.4651, 0.8532
7.200, 180, 0.1497, None, None, None, None, None
7.600, 190, 0.1211, None, None, None, None, None
8.000, 200, 0.1089, None, None, None, None, None
8.000, 200, None, 1.1011, 0.3797, 0.6658, 0.4836, 0.8583
8.400, 210, 0.0778, None, None, None, None, None
8.800, 220, 0.1428, None, None, None, None, None
9.000, 225, None, 1.1696, 0.4215, 0.6608, 0.5147, 0.8728
9.200, 230, 0.0835, None, None, None, None, None
9.600, 240, 0.0690, None, None, None, None, None
10.000, 250, 0.0991, None, None, None, None, None
10.000, 250, None, 1.1649, 0.4201, 0.6608, 0.5137, 0.8710
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1649, 0.4201, 0.6608, 0.5137, 0.8710

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2397, None, None, None, None, None
0.800, 20, 2.8779, None, None, None, None, None
1.000, 25, None, 2.2394, 0.0377, 0.3981, 0.0689, 0.0677
1.200, 30, 2.4153, None, None, None, None, None
1.600, 40, 1.9332, None, None, None, None, None
2.000, 50, 1.4687, None, None, None, None, None
2.000, 50, None, 1.2155, 0.1160, 0.6056, 0.1947, 0.3201
2.400, 60, 1.0141, None, None, None, None, None
2.800, 70, 0.9468, None, None, None, None, None
3.000, 75, None, 0.6050, 0.1593, 0.7252, 0.2612, 0.5252
3.200, 80, 0.5850, None, None, None, None, None
3.600, 90, 0.4807, None, None, None, None, None
4.000, 100, 0.4522, None, None, None, None, None
4.000, 100, None, 0.4397, 0.3317, 0.7477, 0.4595, 0.7856
4.400, 110, 0.2947, None, None, None, None, None
4.800, 120, 0.2801, None, None, None, None, None
5.000, 125, None, 0.4533, 0.2459, 0.7570, 0.3712, 0.6037
5.200, 130, 0.3216, None, None, None, None, None
5.600, 140, 0.2369, None, None, None, None, None
6.000, 150, 0.1575, None, None, None, None, None
6.000, 150, None, 0.3750, 0.4082, 0.7402, 0.5262, 0.8472
6.400, 160, 0.1733, None, None, None, None, None
6.800, 170, 0.1401, None, None, None, None, None
7.000, 175, None, 0.3778, 0.3585, 0.6935, 0.4726, 0.8200
7.200, 180, 0.1054, None, None, None, None, None
7.600, 190, 0.0923, None, None, None, None, None
8.000, 200, 0.1062, None, None, None, None, None
8.000, 200, None, 0.3819, 0.4654, 0.7421, 0.5720, 0.8762
8.400, 210, 0.0919, None, None, None, None, None
8.800, 220, 0.0888, None, None, None, None, None
9.000, 225, None, 0.3865, 0.4674, 0.7364, 0.5718, 0.8714
9.200, 230, 0.0912, None, None, None, None, None
9.600, 240, 0.0653, None, None, None, None, None
10.000, 250, 0.1026, None, None, None, None, None
10.000, 250, None, 0.3870, 0.4764, 0.7346, 0.5779, 0.8806
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.3870, 0.4764, 0.7346, 0.5779, 0.8806

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2200, None, None, None, None, None
0.800, 20, 2.8992, None, None, None, None, None
1.000, 25, None, 2.4104, 0.0314, 0.3913, 0.0582, 0.0811
1.200, 30, 2.3201, None, None, None, None, None
1.600, 40, 1.8603, None, None, None, None, None
2.000, 50, 1.5058, None, None, None, None, None
2.000, 50, None, 1.4734, 0.1059, 0.5696, 0.1787, 0.4722
2.400, 60, 1.0043, None, None, None, None, None
2.800, 70, 0.7240, None, None, None, None, None
3.000, 75, None, 1.0191, 0.1515, 0.6478, 0.2456, 0.4792
3.200, 80, 0.5544, None, None, None, None, None
3.600, 90, 0.3978, None, None, None, None, None
4.000, 100, 0.5277, None, None, None, None, None
4.000, 100, None, 1.1276, 0.1948, 0.6196, 0.2964, 0.6894
4.400, 110, 0.2605, None, None, None, None, None
4.800, 120, 0.3670, None, None, None, None, None
5.000, 125, None, 0.9329, 0.2730, 0.6326, 0.3814, 0.8287
5.200, 130, 0.2344, None, None, None, None, None
5.600, 140, 0.1828, None, None, None, None, None
6.000, 150, 0.1811, None, None, None, None, None
6.000, 150, None, 0.9154, 0.3136, 0.6348, 0.4198, 0.8471
6.400, 160, 0.1479, None, None, None, None, None
6.800, 170, 0.1337, None, None, None, None, None
7.000, 175, None, 1.0908, 0.3428, 0.6304, 0.4441, 0.8401
7.200, 180, 0.1331, None, None, None, None, None
7.600, 190, 0.1078, None, None, None, None, None
8.000, 200, 0.0962, None, None, None, None, None
8.000, 200, None, 1.0429, 0.4078, 0.6630, 0.5050, 0.8787
8.400, 210, 0.0904, None, None, None, None, None
8.800, 220, 0.0915, None, None, None, None, None
9.000, 225, None, 1.0947, 0.4436, 0.6587, 0.5302, 0.9020
9.200, 230, 0.0657, None, None, None, None, None
9.600, 240, 0.0657, None, None, None, None, None
10.000, 250, 0.1047, None, None, None, None, None
10.000, 250, None, 1.1000, 0.4535, 0.6565, 0.5364, 0.9051
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1000, 0.4535, 0.6565, 0.5364, 0.9051

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2209, None, None, None, None, None
0.800, 20, 2.9283, None, None, None, None, None
1.000, 25, None, 2.2131, 0.0364, 0.4600, 0.0675, 0.0734
1.200, 30, 2.4041, None, None, None, None, None
1.600, 40, 1.9091, None, None, None, None, None
2.000, 50, 1.4819, None, None, None, None, None
2.000, 50, None, 1.2144, 0.1229, 0.6711, 0.2078, 0.5129
2.400, 60, 1.0252, None, None, None, None, None
2.800, 70, 0.8385, None, None, None, None, None
3.000, 75, None, 0.7327, 0.1663, 0.7689, 0.2735, 0.6047
3.200, 80, 0.5856, None, None, None, None, None
3.600, 90, 0.4410, None, None, None, None, None
4.000, 100, 0.4469, None, None, None, None, None
4.000, 100, None, 0.6888, 0.2260, 0.6911, 0.3406, 0.7385
4.400, 110, 0.2657, None, None, None, None, None
4.800, 120, 0.3247, None, None, None, None, None
5.000, 125, None, 0.6574, 0.2637, 0.6844, 0.3807, 0.7204
5.200, 130, 0.2625, None, None, None, None, None
5.600, 140, 0.2172, None, None, None, None, None
6.000, 150, 0.1737, None, None, None, None, None
6.000, 150, None, 0.6907, 0.3779, 0.6844, 0.4870, 0.8626
6.400, 160, 0.1444, None, None, None, None, None
6.800, 170, 0.1377, None, None, None, None, None
7.000, 175, None, 0.7234, 0.4337, 0.7200, 0.5414, 0.8806
7.200, 180, 0.1442, None, None, None, None, None
7.600, 190, 0.0871, None, None, None, None, None
8.000, 200, 0.0743, None, None, None, None, None
8.000, 200, None, 0.7860, 0.4993, 0.7400, 0.5962, 0.9015
8.400, 210, 0.0646, None, None, None, None, None
8.800, 220, 0.0950, None, None, None, None, None
9.000, 225, None, 0.7996, 0.4962, 0.7333, 0.5919, 0.9000
9.200, 230, 0.0800, None, None, None, None, None
9.600, 240, 0.0652, None, None, None, None, None
10.000, 250, 0.0792, None, None, None, None, None
10.000, 250, None, 0.8091, 0.5076, 0.7378, 0.6014, 0.9036
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.8091, 0.5076, 0.7378, 0.6014, 0.9036

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.417, 10, 3.2617, None, None, None, None, None
0.833, 20, 2.9183, None, None, None, None, None
1.000, 24, None, 2.5389, 0.0222, 0.2481, 0.0407, 0.0522
1.250, 30, 2.3141, None, None, None, None, None
1.667, 40, 1.9431, None, None, None, None, None
2.000, 48, None, 1.5035, 0.1297, 0.6455, 0.2160, 0.5990
2.083, 50, 1.4340, None, None, None, None, None
2.500, 60, 1.0018, None, None, None, None, None
2.917, 70, 0.7924, None, None, None, None, None
3.000, 72, None, 1.0645, 0.1404, 0.6716, 0.2323, 0.3438
3.333, 80, 0.5866, None, None, None, None, None
3.750, 90, 0.4969, None, None, None, None, None
4.000, 96, None, 1.0001, 0.1738, 0.6306, 0.2725, 0.6485
4.167, 100, 0.4085, None, None, None, None, None
4.583, 110, 0.3769, None, None, None, None, None
5.000, 120, 0.3434, None, None, None, None, None
5.000, 120, None, 0.8589, 0.2594, 0.6157, 0.3650, 0.7779
5.417, 130, 0.2498, None, None, None, None, None
5.833, 140, 0.1910, None, None, None, None, None
6.000, 144, None, 0.8300, 0.2668, 0.6455, 0.3775, 0.7404
6.250, 150, 0.1633, None, None, None, None, None
6.667, 160, 0.1783, None, None, None, None, None
7.000, 168, None, 1.0291, 0.3783, 0.6119, 0.4676, 0.8753
7.083, 170, 0.1542, None, None, None, None, None
7.500, 180, 0.1117, None, None, None, None, None
7.917, 190, 0.0970, None, None, None, None, None
8.000, 192, None, 1.0493, 0.4188, 0.6493, 0.5091, 0.8866
8.333, 200, 0.0845, None, None, None, None, None
8.750, 210, 0.0975, None, None, None, None, None
9.000, 216, None, 1.1027, 0.4478, 0.6399, 0.5269, 0.9003
9.167, 220, 0.0750, None, None, None, None, None
9.583, 230, 0.0761, None, None, None, None, None
10.000, 240, 0.0649, None, None, None, None, None
10.000, 240, None, 1.1501, 0.4494, 0.6381, 0.5274, 0.9010
10.000, 240, None, None, None, None, None, None
10.000, 240, None, 1.1501, 0.4494, 0.6381, 0.5274, 0.9010

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2864, None, None, None, None, None
0.800, 20, 2.8068, None, None, None, None, None
1.000, 25, None, 2.4964, 0.0216, 0.2588, 0.0398, 0.0463
1.200, 30, 2.4438, None, None, None, None, None
1.600, 40, 1.9381, None, None, None, None, None
2.000, 50, 1.5728, None, None, None, None, None
2.000, 50, None, 1.5763, 0.0936, 0.6156, 0.1625, 0.4387
2.400, 60, 1.0831, None, None, None, None, None
2.800, 70, 0.8451, None, None, None, None, None
3.000, 75, None, 1.2982, 0.1374, 0.5704, 0.2215, 0.5376
3.200, 80, 0.6718, None, None, None, None, None
3.600, 90, 0.6183, None, None, None, None, None
4.000, 100, 0.5650, None, None, None, None, None
4.000, 100, None, 1.0943, 0.2113, 0.6683, 0.3211, 0.7012
4.400, 110, 0.3477, None, None, None, None, None
4.800, 120, 0.4023, None, None, None, None, None
5.000, 125, None, 0.9849, 0.2218, 0.6131, 0.3258, 0.7473
5.200, 130, 0.3079, None, None, None, None, None
5.600, 140, 0.2368, None, None, None, None, None
6.000, 150, 0.2490, None, None, None, None, None
6.000, 150, None, 0.9873, 0.2716, 0.6633, 0.3854, 0.7841
6.400, 160, 0.1790, None, None, None, None, None
6.800, 170, 0.1894, None, None, None, None, None
7.000, 175, None, 1.0639, 0.3437, 0.6658, 0.4534, 0.8307
7.200, 180, 0.1596, None, None, None, None, None
7.600, 190, 0.1298, None, None, None, None, None
8.000, 200, 0.1242, None, None, None, None, None
8.000, 200, None, 1.1359, 0.4151, 0.6633, 0.5106, 0.8681
8.400, 210, 0.0842, None, None, None, None, None
8.800, 220, 0.1501, None, None, None, None, None
9.000, 225, None, 1.1556, 0.4022, 0.6508, 0.4971, 0.8714
9.200, 230, 0.0801, None, None, None, None, None
9.600, 240, 0.0707, None, None, None, None, None
10.000, 250, 0.0964, None, None, None, None, None
10.000, 250, None, 1.1769, 0.4202, 0.6482, 0.5099, 0.8763
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1769, 0.4202, 0.6482, 0.5099, 0.8763

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2397, None, None, None, None, None
0.800, 20, 2.8779, None, None, None, None, None
1.000, 25, None, 2.2394, 0.0377, 0.3981, 0.0689, 0.0677
1.200, 30, 2.4155, None, None, None, None, None
1.600, 40, 1.9348, None, None, None, None, None
2.000, 50, 1.4803, None, None, None, None, None
2.000, 50, None, 1.2320, 0.1134, 0.6075, 0.1912, 0.3203
2.400, 60, 1.0348, None, None, None, None, None
2.800, 70, 0.9655, None, None, None, None, None
3.000, 75, None, 0.6269, 0.1553, 0.7271, 0.2559, 0.5172
3.200, 80, 0.6139, None, None, None, None, None
3.600, 90, 0.5101, None, None, None, None, None
4.000, 100, 0.4803, None, None, None, None, None
4.000, 100, None, 0.4691, 0.3589, 0.7607, 0.4877, 0.8388
4.400, 110, 0.3317, None, None, None, None, None
4.800, 120, 0.3180, None, None, None, None, None
5.000, 125, None, 0.4525, 0.2380, 0.7607, 0.3626, 0.6023
5.200, 130, 0.3475, None, None, None, None, None
5.600, 140, 0.2535, None, None, None, None, None
6.000, 150, 0.1755, None, None, None, None, None
6.000, 150, None, 0.3906, 0.4028, 0.7477, 0.5236, 0.8499
6.400, 160, 0.1918, None, None, None, None, None
6.800, 170, 0.1544, None, None, None, None, None
7.000, 175, None, 0.3877, 0.3687, 0.7271, 0.4893, 0.7969
7.200, 180, 0.1271, None, None, None, None, None
7.600, 190, 0.0978, None, None, None, None, None
8.000, 200, 0.1173, None, None, None, None, None
8.000, 200, None, 0.4119, 0.4654, 0.7421, 0.5720, 0.8729
8.400, 210, 0.0979, None, None, None, None, None
8.800, 220, 0.1016, None, None, None, None, None
9.000, 225, None, 0.3974, 0.4438, 0.7159, 0.5479, 0.8643
9.200, 230, 0.0896, None, None, None, None, None
9.600, 240, 0.0677, None, None, None, None, None
10.000, 250, 0.1082, None, None, None, None, None
10.000, 250, None, 0.4163, 0.5213, 0.7551, 0.6168, 0.9013
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.4163, 0.5213, 0.7551, 0.6168, 0.9013

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2200, None, None, None, None, None
0.800, 20, 2.8992, None, None, None, None, None
1.000, 25, None, 2.4104, 0.0314, 0.3913, 0.0581, 0.0809
1.200, 30, 2.3203, None, None, None, None, None
1.600, 40, 1.8652, None, None, None, None, None
2.000, 50, 1.5138, None, None, None, None, None
2.000, 50, None, 1.4878, 0.1033, 0.5652, 0.1747, 0.4547
2.400, 60, 1.0205, None, None, None, None, None
2.800, 70, 0.7393, None, None, None, None, None
3.000, 75, None, 1.0403, 0.1472, 0.6478, 0.2399, 0.4439
3.200, 80, 0.5736, None, None, None, None, None
3.600, 90, 0.4214, None, None, None, None, None
4.000, 100, 0.5044, None, None, None, None, None
4.000, 100, None, 1.0289, 0.2018, 0.6478, 0.3077, 0.7041
4.400, 110, 0.2586, None, None, None, None, None
4.800, 120, 0.3788, None, None, None, None, None
5.000, 125, None, 0.9133, 0.2629, 0.6304, 0.3711, 0.8180
5.200, 130, 0.2394, None, None, None, None, None
5.600, 140, 0.1973, None, None, None, None, None
6.000, 150, 0.2042, None, None, None, None, None
6.000, 150, None, 0.9864, 0.3111, 0.6478, 0.4203, 0.8245
6.400, 160, 0.1711, None, None, None, None, None
6.800, 170, 0.1430, None, None, None, None, None
7.000, 175, None, 1.1204, 0.3484, 0.6370, 0.4504, 0.8540
7.200, 180, 0.1470, None, None, None, None, None
7.600, 190, 0.1415, None, None, None, None, None
8.000, 200, 0.1009, None, None, None, None, None
8.000, 200, None, 1.0526, 0.3912, 0.6565, 0.4903, 0.8773
8.400, 210, 0.0959, None, None, None, None, None
8.800, 220, 0.1079, None, None, None, None, None
9.000, 225, None, 1.1806, 0.4607, 0.6630, 0.5437, 0.8977
9.200, 230, 0.0690, None, None, None, None, None
9.600, 240, 0.0591, None, None, None, None, None
10.000, 250, 0.1084, None, None, None, None, None
10.000, 250, None, 1.1686, 0.4822, 0.6761, 0.5629, 0.9081
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1686, 0.4822, 0.6761, 0.5629, 0.9081

# Starting new run with hyperparams:
{
  "learning_rate": 1e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2209, None, None, None, None, None
0.800, 20, 2.9283, None, None, None, None, None
1.000, 25, None, 2.2132, 0.0364, 0.4600, 0.0675, 0.0734
1.200, 30, 2.4041, None, None, None, None, None
1.600, 40, 1.9143, None, None, None, None, None
2.000, 50, 1.4931, None, None, None, None, None
2.000, 50, None, 1.2338, 0.1208, 0.6644, 0.2044, 0.5052
2.400, 60, 1.0459, None, None, None, None, None
2.800, 70, 0.8531, None, None, None, None, None
3.000, 75, None, 0.7471, 0.1651, 0.7711, 0.2719, 0.6044
3.200, 80, 0.6131, None, None, None, None, None
3.600, 90, 0.4630, None, None, None, None, None
4.000, 100, 0.4530, None, None, None, None, None
4.000, 100, None, 0.6826, 0.2164, 0.7044, 0.3311, 0.7179
4.400, 110, 0.2670, None, None, None, None, None
4.800, 120, 0.3227, None, None, None, None, None
5.000, 125, None, 0.6318, 0.2457, 0.6733, 0.3601, 0.7114
5.200, 130, 0.2754, None, None, None, None, None
5.600, 140, 0.2462, None, None, None, None, None
6.000, 150, 0.2007, None, None, None, None, None
6.000, 150, None, 0.6766, 0.3705, 0.6867, 0.4813, 0.8539
6.400, 160, 0.1687, None, None, None, None, None
6.800, 170, 0.1489, None, None, None, None, None
7.000, 175, None, 0.7357, 0.4605, 0.7378, 0.5670, 0.8896
7.200, 180, 0.1546, None, None, None, None, None
7.600, 190, 0.1018, None, None, None, None, None
8.000, 200, 0.0955, None, None, None, None, None
8.000, 200, None, 0.8066, 0.5238, 0.7578, 0.6194, 0.9069
8.400, 210, 0.0644, None, None, None, None, None
8.800, 220, 0.0987, None, None, None, None, None
9.000, 225, None, 0.7998, 0.4861, 0.7400, 0.5868, 0.8957
9.200, 230, 0.0827, None, None, None, None, None
9.600, 240, 0.0589, None, None, None, None, None
10.000, 250, 0.0770, None, None, None, None, None
10.000, 250, None, 0.8772, 0.5559, 0.7622, 0.6429, 0.9174
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.8772, 0.5559, 0.7622, 0.6429, 0.9174

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.208, 10, 3.3577, None, None, None, None, None
0.417, 20, 3.1316, None, None, None, None, None
0.625, 30, 2.7201, None, None, None, None, None
0.833, 40, 2.7118, None, None, None, None, None
1.000, 48, None, 2.3678, 0.0410, 0.3713, 0.0738, 0.0974
1.042, 50, 2.2646, None, None, None, None, None
1.250, 60, 1.7309, None, None, None, None, None
1.458, 70, 1.5700, None, None, None, None, None
1.667, 80, 1.3874, None, None, None, None, None
1.875, 90, 1.0965, None, None, None, None, None
2.000, 96, None, 1.1770, 0.1676, 0.7052, 0.2708, 0.6242
2.083, 100, 1.0327, None, None, None, None, None
2.292, 110, 0.7986, None, None, None, None, None
2.500, 120, 0.6527, None, None, None, None, None
2.708, 130, 0.5159, None, None, None, None, None
2.917, 140, 0.5095, None, None, None, None, None
3.000, 144, None, 0.9729, 0.2765, 0.6959, 0.3958, 0.8125
3.125, 150, 0.4251, None, None, None, None, None
3.333, 160, 0.4861, None, None, None, None, None
3.542, 170, 0.3234, None, None, None, None, None
3.750, 180, 0.3356, None, None, None, None, None
3.958, 190, 0.4682, None, None, None, None, None
4.000, 192, None, 0.8232, 0.2549, 0.6250, 0.3622, 0.7672
4.167, 200, 0.2380, None, None, None, None, None
4.375, 210, 0.3187, None, None, None, None, None
4.583, 220, 0.1825, None, None, None, None, None
4.792, 230, 0.1846, None, None, None, None, None
5.000, 240, 0.2230, None, None, None, None, None
5.000, 240, None, 0.9581, 0.3727, 0.6530, 0.4746, 0.8743
5.208, 250, 0.1504, None, None, None, None, None
5.417, 260, 0.1173, None, None, None, None, None
5.625, 270, 0.1129, None, None, None, None, None
5.833, 280, 0.0927, None, None, None, None, None
6.000, 288, None, 1.2090, 0.5056, 0.6772, 0.5789, 0.9019
6.042, 290, 0.1031, None, None, None, None, None
6.250, 300, 0.0605, None, None, None, None, None
6.458, 310, 0.1154, None, None, None, None, None
6.667, 320, 0.0879, None, None, None, None, None
6.875, 330, 0.1000, None, None, None, None, None
7.000, 336, None, 1.0741, 0.4373, 0.6306, 0.5164, 0.8837
7.083, 340, 0.0679, None, None, None, None, None
7.292, 350, 0.0713, None, None, None, None, None
7.500, 360, 0.0588, None, None, None, None, None
7.708, 370, 0.0548, None, None, None, None, None
7.917, 380, 0.0335, None, None, None, None, None
8.000, 384, None, 1.2182, 0.5092, 0.6698, 0.5786, 0.9102
8.125, 390, 0.0477, None, None, None, None, None
8.333, 400, 0.0415, None, None, None, None, None
8.542, 410, 0.0472, None, None, None, None, None
8.750, 420, 0.0452, None, None, None, None, None
8.958, 430, 0.0506, None, None, None, None, None
9.000, 432, None, 1.2668, 0.5329, 0.6791, 0.5972, 0.9165
9.167, 440, 0.0314, None, None, None, None, None
9.375, 450, 0.0354, None, None, None, None, None
9.583, 460, 0.0582, None, None, None, None, None
9.792, 470, 0.0224, None, None, None, None, None
10.000, 480, 0.0430, None, None, None, None, None
10.000, 480, None, 1.2710, 0.5360, 0.6810, 0.5998, 0.9169
10.000, 480, None, None, None, None, None, None
10.000, 480, None, 1.2710, 0.5360, 0.6810, 0.5998, 0.9169

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2870, None, None, None, None, None
0.408, 20, 3.2307, None, None, None, None, None
0.612, 30, 2.7948, None, None, None, None, None
0.816, 40, 2.4717, None, None, None, None, None
1.000, 49, None, 2.1858, 0.0429, 0.4397, 0.0781, 0.1567
1.020, 50, 2.2007, None, None, None, None, None
1.224, 60, 1.7741, None, None, None, None, None
1.429, 70, 1.5438, None, None, None, None, None
1.633, 80, 1.4071, None, None, None, None, None
1.837, 90, 1.1306, None, None, None, None, None
2.000, 98, None, 1.1991, 0.1827, 0.6809, 0.2881, 0.7152
2.041, 100, 0.9905, None, None, None, None, None
2.245, 110, 0.6332, None, None, None, None, None
2.449, 120, 0.5676, None, None, None, None, None
2.653, 130, 0.6126, None, None, None, None, None
2.857, 140, 0.5792, None, None, None, None, None
3.000, 147, None, 1.1943, 0.1694, 0.6206, 0.2662, 0.5160
3.061, 150, 0.4377, None, None, None, None, None
3.265, 160, 0.3636, None, None, None, None, None
3.469, 170, 0.3726, None, None, None, None, None
3.673, 180, 0.3250, None, None, None, None, None
3.878, 190, 0.2619, None, None, None, None, None
4.000, 196, None, 1.0641, 0.2194, 0.6583, 0.3291, 0.5571
4.082, 200, 0.3243, None, None, None, None, None
4.286, 210, 0.1649, None, None, None, None, None
4.490, 220, 0.2275, None, None, None, None, None
4.694, 230, 0.2228, None, None, None, None, None
4.898, 240, 0.2594, None, None, None, None, None
5.000, 245, None, 1.0752, 0.2723, 0.5603, 0.3665, 0.7905
5.102, 250, 0.1814, None, None, None, None, None
5.306, 260, 0.1125, None, None, None, None, None
5.510, 270, 0.1311, None, None, None, None, None
5.714, 280, 0.1386, None, None, None, None, None
5.918, 290, 0.1502, None, None, None, None, None
6.000, 294, None, 1.1236, 0.3718, 0.6558, 0.4745, 0.8240
6.122, 300, 0.1678, None, None, None, None, None
6.327, 310, 0.0731, None, None, None, None, None
6.531, 320, 0.0856, None, None, None, None, None
6.735, 330, 0.0988, None, None, None, None, None
6.939, 340, 0.1390, None, None, None, None, None
7.000, 343, None, 1.4124, 0.4790, 0.6583, 0.5545, 0.9035
7.143, 350, 0.0859, None, None, None, None, None
7.347, 360, 0.0845, None, None, None, None, None
7.551, 370, 0.0761, None, None, None, None, None
7.755, 380, 0.1061, None, None, None, None, None
7.959, 390, 0.0223, None, None, None, None, None
8.000, 392, None, 1.4628, 0.5200, 0.6859, 0.5915, 0.9087
8.163, 400, 0.0441, None, None, None, None, None
8.367, 410, 0.0472, None, None, None, None, None
8.571, 420, 0.0689, None, None, None, None, None
8.776, 430, 0.0741, None, None, None, None, None
8.980, 440, 0.0499, None, None, None, None, None
9.000, 441, None, 1.4679, 0.5114, 0.6759, 0.5823, 0.9024
9.184, 450, 0.0945, None, None, None, None, None
9.388, 460, 0.0250, None, None, None, None, None
9.592, 470, 0.0197, None, None, None, None, None
9.796, 480, 0.0413, None, None, None, None, None
10.000, 490, 0.0678, None, None, None, None, None
10.000, 490, None, 1.4966, 0.5183, 0.6759, 0.5867, 0.9078
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.4966, 0.5183, 0.6759, 0.5867, 0.9078

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3243, None, None, None, None, None
0.408, 20, 3.1308, None, None, None, None, None
0.612, 30, 2.7688, None, None, None, None, None
0.816, 40, 2.7049, None, None, None, None, None
1.000, 49, None, 1.9304, 0.0705, 0.5234, 0.1242, 0.1478
1.020, 50, 2.3554, None, None, None, None, None
1.224, 60, 1.8393, None, None, None, None, None
1.429, 70, 1.5889, None, None, None, None, None
1.633, 80, 1.4388, None, None, None, None, None
1.837, 90, 1.0943, None, None, None, None, None
2.000, 98, None, 1.0055, 0.1354, 0.6393, 0.2235, 0.1431
2.041, 100, 1.3154, None, None, None, None, None
2.245, 110, 0.7813, None, None, None, None, None
2.449, 120, 0.7045, None, None, None, None, None
2.653, 130, 0.6826, None, None, None, None, None
2.857, 140, 0.7315, None, None, None, None, None
3.000, 147, None, 0.5525, 0.2288, 0.6972, 0.3446, 0.6949
3.061, 150, 0.4410, None, None, None, None, None
3.265, 160, 0.4643, None, None, None, None, None
3.469, 170, 0.3893, None, None, None, None, None
3.673, 180, 0.3818, None, None, None, None, None
3.878, 190, 0.2762, None, None, None, None, None
4.000, 196, None, 0.4084, 0.1949, 0.6243, 0.2970, 0.6545
4.082, 200, 0.3568, None, None, None, None, None
4.286, 210, 0.2270, None, None, None, None, None
4.490, 220, 0.2516, None, None, None, None, None
4.694, 230, 0.1847, None, None, None, None, None
4.898, 240, 0.3539, None, None, None, None, None
5.000, 245, None, 0.4480, 0.2648, 0.6617, 0.3782, 0.6537
5.102, 250, 0.2954, None, None, None, None, None
5.306, 260, 0.1754, None, None, None, None, None
5.510, 270, 0.2067, None, None, None, None, None
5.714, 280, 0.1980, None, None, None, None, None
5.918, 290, 0.1156, None, None, None, None, None
6.000, 294, None, 0.4340, 0.4649, 0.7178, 0.5643, 0.8776
6.122, 300, 0.1026, None, None, None, None, None
6.327, 310, 0.1195, None, None, None, None, None
6.531, 320, 0.1660, None, None, None, None, None
6.735, 330, 0.1158, None, None, None, None, None
6.939, 340, 0.0620, None, None, None, None, None
7.000, 343, None, 0.5215, 0.5638, 0.7682, 0.6503, 0.9096
7.143, 350, 0.1053, None, None, None, None, None
7.347, 360, 0.0743, None, None, None, None, None
7.551, 370, 0.0566, None, None, None, None, None
7.755, 380, 0.0955, None, None, None, None, None
7.959, 390, 0.0279, None, None, None, None, None
8.000, 392, None, 0.5303, 0.5452, 0.7439, 0.6292, 0.9088
8.163, 400, 0.0874, None, None, None, None, None
8.367, 410, 0.0625, None, None, None, None, None
8.571, 420, 0.0575, None, None, None, None, None
8.776, 430, 0.1085, None, None, None, None, None
8.980, 440, 0.0720, None, None, None, None, None
9.000, 441, None, 0.5547, 0.5740, 0.7682, 0.6571, 0.9154
9.184, 450, 0.0981, None, None, None, None, None
9.388, 460, 0.0322, None, None, None, None, None
9.592, 470, 0.0270, None, None, None, None, None
9.796, 480, 0.0308, None, None, None, None, None
10.000, 490, 0.1054, None, None, None, None, None
10.000, 490, None, 0.5621, 0.5738, 0.7626, 0.6549, 0.9160
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 0.5621, 0.5738, 0.7626, 0.6549, 0.9160

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2728, None, None, None, None, None
0.408, 20, 3.0710, None, None, None, None, None
0.612, 30, 2.9176, None, None, None, None, None
0.816, 40, 2.5616, None, None, None, None, None
1.000, 49, None, 2.1547, 0.0480, 0.3543, 0.0845, 0.3962
1.020, 50, 2.2635, None, None, None, None, None
1.224, 60, 1.7294, None, None, None, None, None
1.429, 70, 1.6342, None, None, None, None, None
1.633, 80, 1.1587, None, None, None, None, None
1.837, 90, 1.4128, None, None, None, None, None
2.000, 98, None, 1.1913, 0.1500, 0.5739, 0.2378, 0.6507
2.041, 100, 0.8569, None, None, None, None, None
2.245, 110, 0.6955, None, None, None, None, None
2.449, 120, 0.5971, None, None, None, None, None
2.653, 130, 0.4257, None, None, None, None, None
2.857, 140, 0.5377, None, None, None, None, None
3.000, 147, None, 1.0773, 0.2554, 0.6196, 0.3617, 0.7072
3.061, 150, 0.4989, None, None, None, None, None
3.265, 160, 0.3242, None, None, None, None, None
3.469, 170, 0.2817, None, None, None, None, None
3.673, 180, 0.2378, None, None, None, None, None
3.878, 190, 0.3798, None, None, None, None, None
4.000, 196, None, 0.9302, 0.2923, 0.6457, 0.4024, 0.8492
4.082, 200, 0.3508, None, None, None, None, None
4.286, 210, 0.1358, None, None, None, None, None
4.490, 220, 0.2011, None, None, None, None, None
4.694, 230, 0.2184, None, None, None, None, None
4.898, 240, 0.2042, None, None, None, None, None
5.000, 245, None, 1.2504, 0.2988, 0.5891, 0.3965, 0.8245
5.102, 250, 0.1737, None, None, None, None, None
5.306, 260, 0.1201, None, None, None, None, None
5.510, 270, 0.1369, None, None, None, None, None
5.714, 280, 0.1748, None, None, None, None, None
5.918, 290, 0.1160, None, None, None, None, None
6.000, 294, None, 1.3324, 0.4296, 0.6304, 0.5110, 0.8771
6.122, 300, 0.0935, None, None, None, None, None
6.327, 310, 0.0392, None, None, None, None, None
6.531, 320, 0.0910, None, None, None, None, None
6.735, 330, 0.1192, None, None, None, None, None
6.939, 340, 0.1038, None, None, None, None, None
7.000, 343, None, 1.3585, 0.4389, 0.6326, 0.5183, 0.8975
7.143, 350, 0.0767, None, None, None, None, None
7.347, 360, 0.0692, None, None, None, None, None
7.551, 370, 0.0805, None, None, None, None, None
7.755, 380, 0.0816, None, None, None, None, None
7.959, 390, 0.0267, None, None, None, None, None
8.000, 392, None, 1.3170, 0.5483, 0.6783, 0.6064, 0.9384
8.163, 400, 0.0418, None, None, None, None, None
8.367, 410, 0.0716, None, None, None, None, None
8.571, 420, 0.0325, None, None, None, None, None
8.776, 430, 0.0891, None, None, None, None, None
8.980, 440, 0.0197, None, None, None, None, None
9.000, 441, None, 1.3484, 0.5383, 0.6870, 0.6036, 0.9319
9.184, 450, 0.0371, None, None, None, None, None
9.388, 460, 0.0266, None, None, None, None, None
9.592, 470, 0.0414, None, None, None, None, None
9.796, 480, 0.0366, None, None, None, None, None
10.000, 490, 0.0843, None, None, None, None, None
10.000, 490, None, 1.3785, 0.5775, 0.7043, 0.6347, 0.9410
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.3785, 0.5775, 0.7043, 0.6347, 0.9410

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3034, None, None, None, None, None
0.408, 20, 3.0937, None, None, None, None, None
0.612, 30, 2.9349, None, None, None, None, None
0.816, 40, 2.6328, None, None, None, None, None
1.000, 49, None, 2.0130, 0.0558, 0.5178, 0.1007, 0.2252
1.020, 50, 2.4059, None, None, None, None, None
1.224, 60, 1.9066, None, None, None, None, None
1.429, 70, 1.4063, None, None, None, None, None
1.633, 80, 1.3480, None, None, None, None, None
1.837, 90, 1.1309, None, None, None, None, None
2.000, 98, None, 1.0340, 0.1762, 0.6467, 0.2769, 0.7023
2.041, 100, 1.2469, None, None, None, None, None
2.245, 110, 0.7138, None, None, None, None, None
2.449, 120, 0.6027, None, None, None, None, None
2.653, 130, 0.7140, None, None, None, None, None
2.857, 140, 0.6921, None, None, None, None, None
3.000, 147, None, 0.7057, 0.2707, 0.7622, 0.3995, 0.7457
3.061, 150, 0.4795, None, None, None, None, None
3.265, 160, 0.4124, None, None, None, None, None
3.469, 170, 0.3778, None, None, None, None, None
3.673, 180, 0.3341, None, None, None, None, None
3.878, 190, 0.2974, None, None, None, None, None
4.000, 196, None, 0.7375, 0.2227, 0.6356, 0.3299, 0.6995
4.082, 200, 0.3119, None, None, None, None, None
4.286, 210, 0.1601, None, None, None, None, None
4.490, 220, 0.2771, None, None, None, None, None
4.694, 230, 0.1618, None, None, None, None, None
4.898, 240, 0.2772, None, None, None, None, None
5.000, 245, None, 0.7081, 0.3228, 0.6800, 0.4378, 0.8215
5.102, 250, 0.1786, None, None, None, None, None
5.306, 260, 0.1030, None, None, None, None, None
5.510, 270, 0.1365, None, None, None, None, None
5.714, 280, 0.2858, None, None, None, None, None
5.918, 290, 0.0848, None, None, None, None, None
6.000, 294, None, 0.9139, 0.5370, 0.7422, 0.6231, 0.9142
6.122, 300, 0.0927, None, None, None, None, None
6.327, 310, 0.0608, None, None, None, None, None
6.531, 320, 0.1174, None, None, None, None, None
6.735, 330, 0.1127, None, None, None, None, None
6.939, 340, 0.0900, None, None, None, None, None
7.000, 343, None, 0.9074, 0.5457, 0.7556, 0.6337, 0.9131
7.143, 350, 0.0966, None, None, None, None, None
7.347, 360, 0.0808, None, None, None, None, None
7.551, 370, 0.0550, None, None, None, None, None
7.755, 380, 0.0663, None, None, None, None, None
7.959, 390, 0.0325, None, None, None, None, None
8.000, 392, None, 0.9971, 0.5932, 0.7711, 0.6705, 0.9278
8.163, 400, 0.0322, None, None, None, None, None
8.367, 410, 0.0413, None, None, None, None, None
8.571, 420, 0.0550, None, None, None, None, None
8.776, 430, 0.0875, None, None, None, None, None
8.980, 440, 0.0433, None, None, None, None, None
9.000, 441, None, 0.9992, 0.5935, 0.7756, 0.6724, 0.9259
9.184, 450, 0.0598, None, None, None, None, None
9.388, 460, 0.0482, None, None, None, None, None
9.592, 470, 0.0215, None, None, None, None, None
9.796, 480, 0.0314, None, None, None, None, None
10.000, 490, 0.0704, None, None, None, None, None
10.000, 490, None, 1.0059, 0.5945, 0.7756, 0.6731, 0.9273
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.0059, 0.5945, 0.7756, 0.6731, 0.9273

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.208, 10, 3.3576, None, None, None, None, None
0.417, 20, 3.1316, None, None, None, None, None
0.625, 30, 2.7201, None, None, None, None, None
0.833, 40, 2.7117, None, None, None, None, None
1.000, 48, None, 2.3678, 0.0410, 0.3713, 0.0738, 0.0977
1.042, 50, 2.2646, None, None, None, None, None
1.250, 60, 1.7317, None, None, None, None, None
1.458, 70, 1.5698, None, None, None, None, None
1.667, 80, 1.3887, None, None, None, None, None
1.875, 90, 1.0962, None, None, None, None, None
2.000, 96, None, 1.1786, 0.1688, 0.7034, 0.2722, 0.6345
2.083, 100, 1.0299, None, None, None, None, None
2.292, 110, 0.7659, None, None, None, None, None
2.500, 120, 0.6425, None, None, None, None, None
2.708, 130, 0.5179, None, None, None, None, None
2.917, 140, 0.4993, None, None, None, None, None
3.000, 144, None, 0.9401, 0.2785, 0.7201, 0.4017, 0.8040
3.125, 150, 0.4178, None, None, None, None, None
3.333, 160, 0.4849, None, None, None, None, None
3.542, 170, 0.3294, None, None, None, None, None
3.750, 180, 0.3038, None, None, None, None, None
3.958, 190, 0.4174, None, None, None, None, None
4.000, 192, None, 0.7810, 0.2564, 0.6586, 0.3691, 0.7634
4.167, 200, 0.2473, None, None, None, None, None
4.375, 210, 0.3203, None, None, None, None, None
4.583, 220, 0.1882, None, None, None, None, None
4.792, 230, 0.2067, None, None, None, None, None
5.000, 240, 0.2438, None, None, None, None, None
5.000, 240, None, 0.9789, 0.3386, 0.6362, 0.4420, 0.8644
5.208, 250, 0.1631, None, None, None, None, None
5.417, 260, 0.1400, None, None, None, None, None
5.625, 270, 0.1434, None, None, None, None, None
5.833, 280, 0.0923, None, None, None, None, None
6.000, 288, None, 1.2296, 0.5706, 0.7015, 0.6293, 0.9245
6.042, 290, 0.1131, None, None, None, None, None
6.250, 300, 0.0663, None, None, None, None, None
6.458, 310, 0.1222, None, None, None, None, None
6.667, 320, 0.1133, None, None, None, None, None
6.875, 330, 0.1137, None, None, None, None, None
7.000, 336, None, 1.1726, 0.4038, 0.5877, 0.4787, 0.8812
7.083, 340, 0.0782, None, None, None, None, None
7.292, 350, 0.1029, None, None, None, None, None
7.500, 360, 0.0686, None, None, None, None, None
7.708, 370, 0.0651, None, None, None, None, None
7.917, 380, 0.0430, None, None, None, None, None
8.000, 384, None, 1.1629, 0.4973, 0.6828, 0.5755, 0.9004
8.125, 390, 0.0497, None, None, None, None, None
8.333, 400, 0.0482, None, None, None, None, None
8.542, 410, 0.0461, None, None, None, None, None
8.750, 420, 0.0571, None, None, None, None, None
8.958, 430, 0.0522, None, None, None, None, None
9.000, 432, None, 1.2756, 0.5264, 0.6698, 0.5895, 0.9170
9.167, 440, 0.0302, None, None, None, None, None
9.375, 450, 0.0308, None, None, None, None, None
9.583, 460, 0.0565, None, None, None, None, None
9.792, 470, 0.0225, None, None, None, None, None
10.000, 480, 0.0428, None, None, None, None, None
10.000, 480, None, 1.3389, 0.5455, 0.6828, 0.6065, 0.9197
10.000, 480, None, None, None, None, None, None
10.000, 480, None, 1.3389, 0.5455, 0.6828, 0.6065, 0.9197

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2870, None, None, None, None, None
0.408, 20, 3.2308, None, None, None, None, None
0.612, 30, 2.7948, None, None, None, None, None
0.816, 40, 2.4718, None, None, None, None, None
1.000, 49, None, 2.1855, 0.0428, 0.4397, 0.0781, 0.1571
1.020, 50, 2.2006, None, None, None, None, None
1.224, 60, 1.7749, None, None, None, None, None
1.429, 70, 1.5445, None, None, None, None, None
1.633, 80, 1.4066, None, None, None, None, None
1.837, 90, 1.1289, None, None, None, None, None
2.000, 98, None, 1.2049, 0.1887, 0.6859, 0.2959, 0.7231
2.041, 100, 0.9958, None, None, None, None, None
2.245, 110, 0.6312, None, None, None, None, None
2.449, 120, 0.5722, None, None, None, None, None
2.653, 130, 0.6194, None, None, None, None, None
2.857, 140, 0.5796, None, None, None, None, None
3.000, 147, None, 1.1416, 0.1701, 0.6206, 0.2670, 0.5437
3.061, 150, 0.4421, None, None, None, None, None
3.265, 160, 0.3797, None, None, None, None, None
3.469, 170, 0.4050, None, None, None, None, None
3.673, 180, 0.3507, None, None, None, None, None
3.878, 190, 0.2764, None, None, None, None, None
4.000, 196, None, 1.0522, 0.2365, 0.6910, 0.3523, 0.6288
4.082, 200, 0.3375, None, None, None, None, None
4.286, 210, 0.1630, None, None, None, None, None
4.490, 220, 0.2482, None, None, None, None, None
4.694, 230, 0.1822, None, None, None, None, None
4.898, 240, 0.2542, None, None, None, None, None
5.000, 245, None, 1.0486, 0.2801, 0.5779, 0.3774, 0.7754
5.102, 250, 0.1954, None, None, None, None, None
5.306, 260, 0.1458, None, None, None, None, None
5.510, 270, 0.1252, None, None, None, None, None
5.714, 280, 0.1223, None, None, None, None, None
5.918, 290, 0.1432, None, None, None, None, None
6.000, 294, None, 1.1297, 0.3638, 0.6809, 0.4742, 0.8162
6.122, 300, 0.1723, None, None, None, None, None
6.327, 310, 0.0865, None, None, None, None, None
6.531, 320, 0.0963, None, None, None, None, None
6.735, 330, 0.1234, None, None, None, None, None
6.939, 340, 0.1593, None, None, None, None, None
7.000, 343, None, 1.3922, 0.4664, 0.6633, 0.5477, 0.9015
7.143, 350, 0.0836, None, None, None, None, None
7.347, 360, 0.0963, None, None, None, None, None
7.551, 370, 0.0914, None, None, None, None, None
7.755, 380, 0.1295, None, None, None, None, None
7.959, 390, 0.0217, None, None, None, None, None
8.000, 392, None, 1.5227, 0.5549, 0.6985, 0.6185, 0.9238
8.163, 400, 0.0456, None, None, None, None, None
8.367, 410, 0.0560, None, None, None, None, None
8.571, 420, 0.0784, None, None, None, None, None
8.776, 430, 0.0891, None, None, None, None, None
8.980, 440, 0.0626, None, None, None, None, None
9.000, 441, None, 1.4594, 0.5388, 0.6985, 0.6083, 0.9097
9.184, 450, 0.1055, None, None, None, None, None
9.388, 460, 0.0215, None, None, None, None, None
9.592, 470, 0.0207, None, None, None, None, None
9.796, 480, 0.0451, None, None, None, None, None
10.000, 490, 0.0644, None, None, None, None, None
10.000, 490, None, 1.4953, 0.5615, 0.7111, 0.6275, 0.9169
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.4953, 0.5615, 0.7111, 0.6275, 0.9169

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3243, None, None, None, None, None
0.408, 20, 3.1308, None, None, None, None, None
0.612, 30, 2.7688, None, None, None, None, None
0.816, 40, 2.7049, None, None, None, None, None
1.000, 49, None, 1.9304, 0.0705, 0.5234, 0.1242, 0.1478
1.020, 50, 2.3554, None, None, None, None, None
1.224, 60, 1.8398, None, None, None, None, None
1.429, 70, 1.5921, None, None, None, None, None
1.633, 80, 1.4275, None, None, None, None, None
1.837, 90, 1.0975, None, None, None, None, None
2.000, 98, None, 0.9936, 0.1340, 0.6393, 0.2216, 0.1473
2.041, 100, 1.3054, None, None, None, None, None
2.245, 110, 0.7791, None, None, None, None, None
2.449, 120, 0.7055, None, None, None, None, None
2.653, 130, 0.6722, None, None, None, None, None
2.857, 140, 0.7334, None, None, None, None, None
3.000, 147, None, 0.5449, 0.2338, 0.7196, 0.3529, 0.7029
3.061, 150, 0.4404, None, None, None, None, None
3.265, 160, 0.4421, None, None, None, None, None
3.469, 170, 0.3966, None, None, None, None, None
3.673, 180, 0.3891, None, None, None, None, None
3.878, 190, 0.3061, None, None, None, None, None
4.000, 196, None, 0.4210, 0.2257, 0.6598, 0.3364, 0.7064
4.082, 200, 0.3606, None, None, None, None, None
4.286, 210, 0.2267, None, None, None, None, None
4.490, 220, 0.2853, None, None, None, None, None
4.694, 230, 0.1880, None, None, None, None, None
4.898, 240, 0.3574, None, None, None, None, None
5.000, 245, None, 0.4455, 0.2664, 0.6673, 0.3808, 0.6467
5.102, 250, 0.3241, None, None, None, None, None
5.306, 260, 0.1732, None, None, None, None, None
5.510, 270, 0.2235, None, None, None, None, None
5.714, 280, 0.1969, None, None, None, None, None
5.918, 290, 0.1225, None, None, None, None, None
6.000, 294, None, 0.4328, 0.4522, 0.7065, 0.5514, 0.8801
6.122, 300, 0.1080, None, None, None, None, None
6.327, 310, 0.1321, None, None, None, None, None
6.531, 320, 0.1465, None, None, None, None, None
6.735, 330, 0.1191, None, None, None, None, None
6.939, 340, 0.0643, None, None, None, None, None
7.000, 343, None, 0.5002, 0.5427, 0.7720, 0.6373, 0.9014
7.143, 350, 0.1474, None, None, None, None, None
7.347, 360, 0.0799, None, None, None, None, None
7.551, 370, 0.0640, None, None, None, None, None
7.755, 380, 0.0961, None, None, None, None, None
7.959, 390, 0.0332, None, None, None, None, None
8.000, 392, None, 0.5103, 0.5397, 0.7495, 0.6275, 0.9035
8.163, 400, 0.0722, None, None, None, None, None
8.367, 410, 0.0659, None, None, None, None, None
8.571, 420, 0.0859, None, None, None, None, None
8.776, 430, 0.0969, None, None, None, None, None
8.980, 440, 0.0712, None, None, None, None, None
9.000, 441, None, 0.5416, 0.5472, 0.7364, 0.6279, 0.9096
9.184, 450, 0.0937, None, None, None, None, None
9.388, 460, 0.0334, None, None, None, None, None
9.592, 470, 0.0210, None, None, None, None, None
9.796, 480, 0.0350, None, None, None, None, None
10.000, 490, 0.1003, None, None, None, None, None
10.000, 490, None, 0.5977, 0.6263, 0.7832, 0.6960, 0.9264
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 0.5977, 0.6263, 0.7832, 0.6960, 0.9264

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2728, None, None, None, None, None
0.408, 20, 3.0711, None, None, None, None, None
0.612, 30, 2.9175, None, None, None, None, None
0.816, 40, 2.5615, None, None, None, None, None
1.000, 49, None, 2.1547, 0.0479, 0.3543, 0.0845, 0.3964
1.020, 50, 2.2635, None, None, None, None, None
1.224, 60, 1.7302, None, None, None, None, None
1.429, 70, 1.6350, None, None, None, None, None
1.633, 80, 1.1655, None, None, None, None, None
1.837, 90, 1.4038, None, None, None, None, None
2.000, 98, None, 1.2006, 0.1496, 0.5739, 0.2373, 0.6397
2.041, 100, 0.8627, None, None, None, None, None
2.245, 110, 0.7069, None, None, None, None, None
2.449, 120, 0.5995, None, None, None, None, None
2.653, 130, 0.4291, None, None, None, None, None
2.857, 140, 0.5176, None, None, None, None, None
3.000, 147, None, 1.0641, 0.2532, 0.6109, 0.3580, 0.7075
3.061, 150, 0.4897, None, None, None, None, None
3.265, 160, 0.3281, None, None, None, None, None
3.469, 170, 0.2888, None, None, None, None, None
3.673, 180, 0.2283, None, None, None, None, None
3.878, 190, 0.3654, None, None, None, None, None
4.000, 196, None, 0.9333, 0.2998, 0.6543, 0.4112, 0.8502
4.082, 200, 0.3625, None, None, None, None, None
4.286, 210, 0.1424, None, None, None, None, None
4.490, 220, 0.2119, None, None, None, None, None
4.694, 230, 0.2191, None, None, None, None, None
4.898, 240, 0.1929, None, None, None, None, None
5.000, 245, None, 1.2122, 0.2968, 0.5652, 0.3892, 0.8279
5.102, 250, 0.1574, None, None, None, None, None
5.306, 260, 0.1224, None, None, None, None, None
5.510, 270, 0.1401, None, None, None, None, None
5.714, 280, 0.1850, None, None, None, None, None
5.918, 290, 0.1277, None, None, None, None, None
6.000, 294, None, 1.3895, 0.4319, 0.6543, 0.5203, 0.8808
6.122, 300, 0.1010, None, None, None, None, None
6.327, 310, 0.0519, None, None, None, None, None
6.531, 320, 0.0886, None, None, None, None, None
6.735, 330, 0.1334, None, None, None, None, None
6.939, 340, 0.1103, None, None, None, None, None
7.000, 343, None, 1.4117, 0.3986, 0.6196, 0.4851, 0.8783
7.143, 350, 0.0794, None, None, None, None, None
7.347, 360, 0.0866, None, None, None, None, None
7.551, 370, 0.0843, None, None, None, None, None
7.755, 380, 0.0814, None, None, None, None, None
7.959, 390, 0.0270, None, None, None, None, None
8.000, 392, None, 1.4577, 0.4959, 0.6565, 0.5650, 0.9022
8.163, 400, 0.0450, None, None, None, None, None
8.367, 410, 0.0688, None, None, None, None, None
8.571, 420, 0.0339, None, None, None, None, None
8.776, 430, 0.1802, None, None, None, None, None
8.980, 440, 0.0225, None, None, None, None, None
9.000, 441, None, 1.4306, 0.5278, 0.6804, 0.5945, 0.9304
9.184, 450, 0.0346, None, None, None, None, None
9.388, 460, 0.0258, None, None, None, None, None
9.592, 470, 0.0484, None, None, None, None, None
9.796, 480, 0.0369, None, None, None, None, None
10.000, 490, 0.0817, None, None, None, None, None
10.000, 490, None, 1.4913, 0.5455, 0.6783, 0.6047, 0.9378
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.4913, 0.5455, 0.6783, 0.6047, 0.9378

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3034, None, None, None, None, None
0.408, 20, 3.0937, None, None, None, None, None
0.612, 30, 2.9350, None, None, None, None, None
0.816, 40, 2.6327, None, None, None, None, None
1.000, 49, None, 2.0129, 0.0558, 0.5178, 0.1008, 0.2252
1.020, 50, 2.4059, None, None, None, None, None
1.224, 60, 1.9072, None, None, None, None, None
1.429, 70, 1.4097, None, None, None, None, None
1.633, 80, 1.3474, None, None, None, None, None
1.837, 90, 1.1353, None, None, None, None, None
2.000, 98, None, 1.0135, 0.1712, 0.6511, 0.2712, 0.6892
2.041, 100, 1.2432, None, None, None, None, None
2.245, 110, 0.7073, None, None, None, None, None
2.449, 120, 0.6163, None, None, None, None, None
2.653, 130, 0.7188, None, None, None, None, None
2.857, 140, 0.6998, None, None, None, None, None
3.000, 147, None, 0.6998, 0.2556, 0.7644, 0.3831, 0.7213
3.061, 150, 0.4681, None, None, None, None, None
3.265, 160, 0.3924, None, None, None, None, None
3.469, 170, 0.3818, None, None, None, None, None
3.673, 180, 0.3485, None, None, None, None, None
3.878, 190, 0.3004, None, None, None, None, None
4.000, 196, None, 0.7262, 0.2504, 0.6533, 0.3621, 0.7516
4.082, 200, 0.3172, None, None, None, None, None
4.286, 210, 0.1529, None, None, None, None, None
4.490, 220, 0.2600, None, None, None, None, None
4.694, 230, 0.1773, None, None, None, None, None
4.898, 240, 0.3040, None, None, None, None, None
5.000, 245, None, 0.6999, 0.3384, 0.6978, 0.4557, 0.8249
5.102, 250, 0.1798, None, None, None, None, None
5.306, 260, 0.0990, None, None, None, None, None
5.510, 270, 0.1766, None, None, None, None, None
5.714, 280, 0.2764, None, None, None, None, None
5.918, 290, 0.0897, None, None, None, None, None
6.000, 294, None, 0.8774, 0.5638, 0.7556, 0.6458, 0.9239
6.122, 300, 0.0860, None, None, None, None, None
6.327, 310, 0.0659, None, None, None, None, None
6.531, 320, 0.1328, None, None, None, None, None
6.735, 330, 0.1041, None, None, None, None, None
6.939, 340, 0.0940, None, None, None, None, None
7.000, 343, None, 0.9013, 0.5329, 0.7556, 0.6250, 0.9075
7.143, 350, 0.1067, None, None, None, None, None
7.347, 360, 0.0829, None, None, None, None, None
7.551, 370, 0.0557, None, None, None, None, None
7.755, 380, 0.0688, None, None, None, None, None
7.959, 390, 0.0319, None, None, None, None, None
8.000, 392, None, 1.0534, 0.6007, 0.7822, 0.6795, 0.9323
8.163, 400, 0.0396, None, None, None, None, None
8.367, 410, 0.0359, None, None, None, None, None
8.571, 420, 0.0677, None, None, None, None, None
8.776, 430, 0.1020, None, None, None, None, None
8.980, 440, 0.0482, None, None, None, None, None
9.000, 441, None, 1.0313, 0.5897, 0.7667, 0.6667, 0.9275
9.184, 450, 0.0555, None, None, None, None, None
9.388, 460, 0.0392, None, None, None, None, None
9.592, 470, 0.0304, None, None, None, None, None
9.796, 480, 0.0373, None, None, None, None, None
10.000, 490, 0.0675, None, None, None, None, None
10.000, 490, None, 1.0773, 0.6154, 0.7822, 0.6888, 0.9320
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.0773, 0.6154, 0.7822, 0.6888, 0.9320

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.208, 10, 3.3576, None, None, None, None, None
0.417, 20, 3.1316, None, None, None, None, None
0.625, 30, 2.7200, None, None, None, None, None
0.833, 40, 2.7118, None, None, None, None, None
1.000, 48, None, 2.3679, 0.0410, 0.3713, 0.0738, 0.0975
1.042, 50, 2.2646, None, None, None, None, None
1.250, 60, 1.7309, None, None, None, None, None
1.458, 70, 1.5699, None, None, None, None, None
1.667, 80, 1.3871, None, None, None, None, None
1.875, 90, 1.0964, None, None, None, None, None
2.000, 96, None, 1.1767, 0.1678, 0.7052, 0.2711, 0.6245
2.083, 100, 1.0326, None, None, None, None, None
2.292, 110, 0.7986, None, None, None, None, None
2.500, 120, 0.6530, None, None, None, None, None
2.708, 130, 0.5162, None, None, None, None, None
2.917, 140, 0.5092, None, None, None, None, None
3.000, 144, None, 0.9730, 0.2771, 0.6959, 0.3964, 0.8128
3.125, 150, 0.4249, None, None, None, None, None
3.333, 160, 0.4863, None, None, None, None, None
3.542, 170, 0.3240, None, None, None, None, None
3.750, 180, 0.3357, None, None, None, None, None
3.958, 190, 0.4682, None, None, None, None, None
4.000, 192, None, 0.8195, 0.2540, 0.6231, 0.3609, 0.7662
4.167, 200, 0.2382, None, None, None, None, None
4.375, 210, 0.3180, None, None, None, None, None
4.583, 220, 0.1828, None, None, None, None, None
4.792, 230, 0.1846, None, None, None, None, None
5.000, 240, 0.2255, None, None, None, None, None
5.000, 240, None, 0.9670, 0.3725, 0.6511, 0.4739, 0.8750
5.208, 250, 0.1511, None, None, None, None, None
5.417, 260, 0.1161, None, None, None, None, None
5.625, 270, 0.1168, None, None, None, None, None
5.833, 280, 0.0916, None, None, None, None, None
6.000, 288, None, 1.1871, 0.5199, 0.6810, 0.5897, 0.9085
6.042, 290, 0.1004, None, None, None, None, None
6.250, 300, 0.0586, None, None, None, None, None
6.458, 310, 0.1112, None, None, None, None, None
6.667, 320, 0.0813, None, None, None, None, None
6.875, 330, 0.0904, None, None, None, None, None
7.000, 336, None, 1.0914, 0.4439, 0.6269, 0.5197, 0.8914
7.083, 340, 0.0598, None, None, None, None, None
7.292, 350, 0.0743, None, None, None, None, None
7.500, 360, 0.0587, None, None, None, None, None
7.708, 370, 0.0564, None, None, None, None, None
7.917, 380, 0.0316, None, None, None, None, None
8.000, 384, None, 1.1719, 0.5165, 0.6716, 0.5839, 0.9120
8.125, 390, 0.0452, None, None, None, None, None
8.333, 400, 0.0435, None, None, None, None, None
8.542, 410, 0.0466, None, None, None, None, None
8.750, 420, 0.0454, None, None, None, None, None
8.958, 430, 0.0495, None, None, None, None, None
9.000, 432, None, 1.2325, 0.5295, 0.6698, 0.5914, 0.9170
9.167, 440, 0.0314, None, None, None, None, None
9.375, 450, 0.0360, None, None, None, None, None
9.583, 460, 0.0602, None, None, None, None, None
9.792, 470, 0.0219, None, None, None, None, None
10.000, 480, 0.0433, None, None, None, None, None
10.000, 480, None, 1.2390, 0.5353, 0.6791, 0.5987, 0.9180
10.000, 480, None, None, None, None, None, None
10.000, 480, None, 1.2390, 0.5353, 0.6791, 0.5987, 0.9180

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2870, None, None, None, None, None
0.408, 20, 3.2307, None, None, None, None, None
0.612, 30, 2.7948, None, None, None, None, None
0.816, 40, 2.4717, None, None, None, None, None
1.000, 49, None, 2.1859, 0.0429, 0.4397, 0.0782, 0.1571
1.020, 50, 2.2007, None, None, None, None, None
1.224, 60, 1.7743, None, None, None, None, None
1.429, 70, 1.5438, None, None, None, None, None
1.633, 80, 1.4075, None, None, None, None, None
1.837, 90, 1.1309, None, None, None, None, None
2.000, 98, None, 1.1987, 0.1815, 0.6759, 0.2862, 0.7152
2.041, 100, 0.9898, None, None, None, None, None
2.245, 110, 0.6402, None, None, None, None, None
2.449, 120, 0.5689, None, None, None, None, None
2.653, 130, 0.6113, None, None, None, None, None
2.857, 140, 0.5793, None, None, None, None, None
3.000, 147, None, 1.1894, 0.1715, 0.6231, 0.2690, 0.5145
3.061, 150, 0.4396, None, None, None, None, None
3.265, 160, 0.3638, None, None, None, None, None
3.469, 170, 0.3775, None, None, None, None, None
3.673, 180, 0.3274, None, None, None, None, None
3.878, 190, 0.2611, None, None, None, None, None
4.000, 196, None, 1.0561, 0.2466, 0.6759, 0.3613, 0.6335
4.082, 200, 0.3265, None, None, None, None, None
4.286, 210, 0.1608, None, None, None, None, None
4.490, 220, 0.2101, None, None, None, None, None
4.694, 230, 0.1914, None, None, None, None, None
4.898, 240, 0.2611, None, None, None, None, None
5.000, 245, None, 1.1003, 0.2790, 0.5678, 0.3742, 0.7765
5.102, 250, 0.2094, None, None, None, None, None
5.306, 260, 0.2077, None, None, None, None, None
5.510, 270, 0.1192, None, None, None, None, None
5.714, 280, 0.1281, None, None, None, None, None
5.918, 290, 0.1612, None, None, None, None, None
6.000, 294, None, 1.1292, 0.3534, 0.6784, 0.4647, 0.8081
6.122, 300, 0.1627, None, None, None, None, None
6.327, 310, 0.0733, None, None, None, None, None
6.531, 320, 0.0871, None, None, None, None, None
6.735, 330, 0.0944, None, None, None, None, None
6.939, 340, 0.1542, None, None, None, None, None
7.000, 343, None, 1.3863, 0.5009, 0.6784, 0.5763, 0.9055
7.143, 350, 0.0770, None, None, None, None, None
7.347, 360, 0.0809, None, None, None, None, None
7.551, 370, 0.0745, None, None, None, None, None
7.755, 380, 0.1147, None, None, None, None, None
7.959, 390, 0.0188, None, None, None, None, None
8.000, 392, None, 1.4784, 0.5299, 0.6910, 0.5998, 0.9107
8.163, 400, 0.0408, None, None, None, None, None
8.367, 410, 0.0483, None, None, None, None, None
8.571, 420, 0.0665, None, None, None, None, None
8.776, 430, 0.0685, None, None, None, None, None
8.980, 440, 0.0543, None, None, None, None, None
9.000, 441, None, 1.4469, 0.5065, 0.6859, 0.5827, 0.9011
9.184, 450, 0.0930, None, None, None, None, None
9.388, 460, 0.0224, None, None, None, None, None
9.592, 470, 0.0215, None, None, None, None, None
9.796, 480, 0.0434, None, None, None, None, None
10.000, 490, 0.0676, None, None, None, None, None
10.000, 490, None, 1.4784, 0.5229, 0.6884, 0.5944, 0.9102
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.4784, 0.5229, 0.6884, 0.5944, 0.9102

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3242, None, None, None, None, None
0.408, 20, 3.1309, None, None, None, None, None
0.612, 30, 2.7688, None, None, None, None, None
0.816, 40, 2.7049, None, None, None, None, None
1.000, 49, None, 1.9306, 0.0705, 0.5234, 0.1243, 0.1478
1.020, 50, 2.3553, None, None, None, None, None
1.224, 60, 1.8394, None, None, None, None, None
1.429, 70, 1.5890, None, None, None, None, None
1.633, 80, 1.4382, None, None, None, None, None
1.837, 90, 1.0940, None, None, None, None, None
2.000, 98, None, 1.0060, 0.1356, 0.6393, 0.2237, 0.1431
2.041, 100, 1.3154, None, None, None, None, None
2.245, 110, 0.7816, None, None, None, None, None
2.449, 120, 0.7046, None, None, None, None, None
2.653, 130, 0.6821, None, None, None, None, None
2.857, 140, 0.7318, None, None, None, None, None
3.000, 147, None, 0.5529, 0.2302, 0.7009, 0.3466, 0.6955
3.061, 150, 0.4402, None, None, None, None, None
3.265, 160, 0.4614, None, None, None, None, None
3.469, 170, 0.3865, None, None, None, None, None
3.673, 180, 0.3788, None, None, None, None, None
3.878, 190, 0.2795, None, None, None, None, None
4.000, 196, None, 0.4068, 0.1977, 0.6336, 0.3013, 0.6597
4.082, 200, 0.3632, None, None, None, None, None
4.286, 210, 0.2260, None, None, None, None, None
4.490, 220, 0.2502, None, None, None, None, None
4.694, 230, 0.1825, None, None, None, None, None
4.898, 240, 0.3556, None, None, None, None, None
5.000, 245, None, 0.4424, 0.2626, 0.6598, 0.3757, 0.6528
5.102, 250, 0.3010, None, None, None, None, None
5.306, 260, 0.1786, None, None, None, None, None
5.510, 270, 0.1999, None, None, None, None, None
5.714, 280, 0.2066, None, None, None, None, None
5.918, 290, 0.1243, None, None, None, None, None
6.000, 294, None, 0.4484, 0.4956, 0.7402, 0.5937, 0.8869
6.122, 300, 0.1033, None, None, None, None, None
6.327, 310, 0.1259, None, None, None, None, None
6.531, 320, 0.1561, None, None, None, None, None
6.735, 330, 0.1146, None, None, None, None, None
6.939, 340, 0.0613, None, None, None, None, None
7.000, 343, None, 0.5253, 0.5532, 0.7682, 0.6432, 0.9033
7.143, 350, 0.1051, None, None, None, None, None
7.347, 360, 0.0741, None, None, None, None, None
7.551, 370, 0.0569, None, None, None, None, None
7.755, 380, 0.0958, None, None, None, None, None
7.959, 390, 0.0288, None, None, None, None, None
8.000, 392, None, 0.5238, 0.5281, 0.7383, 0.6157, 0.9041
8.163, 400, 0.0852, None, None, None, None, None
8.367, 410, 0.0625, None, None, None, None, None
8.571, 420, 0.0603, None, None, None, None, None
8.776, 430, 0.1044, None, None, None, None, None
8.980, 440, 0.0742, None, None, None, None, None
9.000, 441, None, 0.5548, 0.5623, 0.7589, 0.6460, 0.9107
9.184, 450, 0.1017, None, None, None, None, None
9.388, 460, 0.0318, None, None, None, None, None
9.592, 470, 0.0288, None, None, None, None, None
9.796, 480, 0.0308, None, None, None, None, None
10.000, 490, 0.0981, None, None, None, None, None
10.000, 490, None, 0.5630, 0.5664, 0.7570, 0.6480, 0.9134
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 0.5630, 0.5664, 0.7570, 0.6480, 0.9134

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2728, None, None, None, None, None
0.408, 20, 3.0711, None, None, None, None, None
0.612, 30, 2.9176, None, None, None, None, None
0.816, 40, 2.5615, None, None, None, None, None
1.000, 49, None, 2.1546, 0.0480, 0.3543, 0.0845, 0.3962
1.020, 50, 2.2635, None, None, None, None, None
1.224, 60, 1.7292, None, None, None, None, None
1.429, 70, 1.6342, None, None, None, None, None
1.633, 80, 1.1589, None, None, None, None, None
1.837, 90, 1.4127, None, None, None, None, None
2.000, 98, None, 1.1912, 0.1504, 0.5739, 0.2384, 0.6525
2.041, 100, 0.8569, None, None, None, None, None
2.245, 110, 0.6956, None, None, None, None, None
2.449, 120, 0.5977, None, None, None, None, None
2.653, 130, 0.4253, None, None, None, None, None
2.857, 140, 0.5391, None, None, None, None, None
3.000, 147, None, 1.0784, 0.2536, 0.6152, 0.3591, 0.7072
3.061, 150, 0.4989, None, None, None, None, None
3.265, 160, 0.3239, None, None, None, None, None
3.469, 170, 0.2817, None, None, None, None, None
3.673, 180, 0.2395, None, None, None, None, None
3.878, 190, 0.3776, None, None, None, None, None
4.000, 196, None, 0.9325, 0.2912, 0.6457, 0.4014, 0.8485
4.082, 200, 0.3501, None, None, None, None, None
4.286, 210, 0.1360, None, None, None, None, None
4.490, 220, 0.2005, None, None, None, None, None
4.694, 230, 0.2179, None, None, None, None, None
4.898, 240, 0.2040, None, None, None, None, None
5.000, 245, None, 1.2454, 0.2938, 0.5870, 0.3916, 0.8225
5.102, 250, 0.1744, None, None, None, None, None
5.306, 260, 0.1210, None, None, None, None, None
5.510, 270, 0.1330, None, None, None, None, None
5.714, 280, 0.1755, None, None, None, None, None
5.918, 290, 0.1124, None, None, None, None, None
6.000, 294, None, 1.3693, 0.4365, 0.6348, 0.5173, 0.8788
6.122, 300, 0.0923, None, None, None, None, None
6.327, 310, 0.0376, None, None, None, None, None
6.531, 320, 0.0961, None, None, None, None, None
6.735, 330, 0.1229, None, None, None, None, None
6.939, 340, 0.1031, None, None, None, None, None
7.000, 343, None, 1.3575, 0.4475, 0.6391, 0.5264, 0.9005
7.143, 350, 0.0791, None, None, None, None, None
7.347, 360, 0.0668, None, None, None, None, None
7.551, 370, 0.0852, None, None, None, None, None
7.755, 380, 0.0827, None, None, None, None, None
7.959, 390, 0.0257, None, None, None, None, None
8.000, 392, None, 1.3399, 0.5477, 0.6739, 0.6043, 0.9369
8.163, 400, 0.0406, None, None, None, None, None
8.367, 410, 0.0717, None, None, None, None, None
8.571, 420, 0.0322, None, None, None, None, None
8.776, 430, 0.0901, None, None, None, None, None
8.980, 440, 0.0197, None, None, None, None, None
9.000, 441, None, 1.3674, 0.5420, 0.6870, 0.6059, 0.9330
9.184, 450, 0.0375, None, None, None, None, None
9.388, 460, 0.0268, None, None, None, None, None
9.592, 470, 0.0413, None, None, None, None, None
9.796, 480, 0.0347, None, None, None, None, None
10.000, 490, 0.0838, None, None, None, None, None
10.000, 490, None, 1.3967, 0.5737, 0.7022, 0.6315, 0.9403
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.3967, 0.5737, 0.7022, 0.6315, 0.9403

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3034, None, None, None, None, None
0.408, 20, 3.0937, None, None, None, None, None
0.612, 30, 2.9349, None, None, None, None, None
0.816, 40, 2.6328, None, None, None, None, None
1.000, 49, None, 2.0130, 0.0558, 0.5178, 0.1007, 0.2249
1.020, 50, 2.4059, None, None, None, None, None
1.224, 60, 1.9068, None, None, None, None, None
1.429, 70, 1.4064, None, None, None, None, None
1.633, 80, 1.3481, None, None, None, None, None
1.837, 90, 1.1312, None, None, None, None, None
2.000, 98, None, 1.0350, 0.1763, 0.6467, 0.2770, 0.7023
2.041, 100, 1.2470, None, None, None, None, None
2.245, 110, 0.7142, None, None, None, None, None
2.449, 120, 0.6030, None, None, None, None, None
2.653, 130, 0.7139, None, None, None, None, None
2.857, 140, 0.6925, None, None, None, None, None
3.000, 147, None, 0.7057, 0.2705, 0.7622, 0.3993, 0.7454
3.061, 150, 0.4797, None, None, None, None, None
3.265, 160, 0.4123, None, None, None, None, None
3.469, 170, 0.3790, None, None, None, None, None
3.673, 180, 0.3342, None, None, None, None, None
3.878, 190, 0.2974, None, None, None, None, None
4.000, 196, None, 0.7376, 0.2226, 0.6356, 0.3297, 0.6994
4.082, 200, 0.3120, None, None, None, None, None
4.286, 210, 0.1599, None, None, None, None, None
4.490, 220, 0.2761, None, None, None, None, None
4.694, 230, 0.1605, None, None, None, None, None
4.898, 240, 0.2775, None, None, None, None, None
5.000, 245, None, 0.7113, 0.3235, 0.6800, 0.4384, 0.8211
5.102, 250, 0.1739, None, None, None, None, None
5.306, 260, 0.1037, None, None, None, None, None
5.510, 270, 0.1360, None, None, None, None, None
5.714, 280, 0.2866, None, None, None, None, None
5.918, 290, 0.0845, None, None, None, None, None
6.000, 294, None, 0.9184, 0.5345, 0.7400, 0.6207, 0.9147
6.122, 300, 0.0924, None, None, None, None, None
6.327, 310, 0.0607, None, None, None, None, None
6.531, 320, 0.1181, None, None, None, None, None
6.735, 330, 0.1137, None, None, None, None, None
6.939, 340, 0.0896, None, None, None, None, None
7.000, 343, None, 0.9056, 0.5424, 0.7533, 0.6307, 0.9127
7.143, 350, 0.0957, None, None, None, None, None
7.347, 360, 0.0807, None, None, None, None, None
7.551, 370, 0.0558, None, None, None, None, None
7.755, 380, 0.0682, None, None, None, None, None
7.959, 390, 0.0323, None, None, None, None, None
8.000, 392, None, 0.9952, 0.5949, 0.7733, 0.6725, 0.9275
8.163, 400, 0.0349, None, None, None, None, None
8.367, 410, 0.0416, None, None, None, None, None
8.571, 420, 0.0543, None, None, None, None, None
8.776, 430, 0.0852, None, None, None, None, None
8.980, 440, 0.0435, None, None, None, None, None
9.000, 441, None, 1.0001, 0.5963, 0.7778, 0.6750, 0.9261
9.184, 450, 0.0596, None, None, None, None, None
9.388, 460, 0.0481, None, None, None, None, None
9.592, 470, 0.0216, None, None, None, None, None
9.796, 480, 0.0315, None, None, None, None, None
10.000, 490, 0.0716, None, None, None, None, None
10.000, 490, None, 1.0061, 0.5935, 0.7756, 0.6724, 0.9275
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.0061, 0.5935, 0.7756, 0.6724, 0.9275

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.208, 10, 3.3576, None, None, None, None, None
0.417, 20, 3.1316, None, None, None, None, None
0.625, 30, 2.7200, None, None, None, None, None
0.833, 40, 2.7117, None, None, None, None, None
1.000, 48, None, 2.3679, 0.0410, 0.3713, 0.0738, 0.0974
1.042, 50, 2.2647, None, None, None, None, None
1.250, 60, 1.7316, None, None, None, None, None
1.458, 70, 1.5699, None, None, None, None, None
1.667, 80, 1.3887, None, None, None, None, None
1.875, 90, 1.0963, None, None, None, None, None
2.000, 96, None, 1.1786, 0.1688, 0.7034, 0.2722, 0.6344
2.083, 100, 1.0299, None, None, None, None, None
2.292, 110, 0.7662, None, None, None, None, None
2.500, 120, 0.6427, None, None, None, None, None
2.708, 130, 0.5179, None, None, None, None, None
2.917, 140, 0.4990, None, None, None, None, None
3.000, 144, None, 0.9397, 0.2783, 0.7201, 0.4015, 0.8036
3.125, 150, 0.4179, None, None, None, None, None
3.333, 160, 0.4852, None, None, None, None, None
3.542, 170, 0.3297, None, None, None, None, None
3.750, 180, 0.3036, None, None, None, None, None
3.958, 190, 0.4167, None, None, None, None, None
4.000, 192, None, 0.7810, 0.2560, 0.6586, 0.3687, 0.7635
4.167, 200, 0.2468, None, None, None, None, None
4.375, 210, 0.3203, None, None, None, None, None
4.583, 220, 0.1885, None, None, None, None, None
4.792, 230, 0.2067, None, None, None, None, None
5.000, 240, 0.2432, None, None, None, None, None
5.000, 240, None, 0.9768, 0.3370, 0.6343, 0.4401, 0.8651
5.208, 250, 0.1632, None, None, None, None, None
5.417, 260, 0.1401, None, None, None, None, None
5.625, 270, 0.1448, None, None, None, None, None
5.833, 280, 0.0927, None, None, None, None, None
6.000, 288, None, 1.2269, 0.5706, 0.7015, 0.6293, 0.9243
6.042, 290, 0.1125, None, None, None, None, None
6.250, 300, 0.0657, None, None, None, None, None
6.458, 310, 0.1221, None, None, None, None, None
6.667, 320, 0.1139, None, None, None, None, None
6.875, 330, 0.1138, None, None, None, None, None
7.000, 336, None, 1.1719, 0.4044, 0.5877, 0.4791, 0.8817
7.083, 340, 0.0774, None, None, None, None, None
7.292, 350, 0.1057, None, None, None, None, None
7.500, 360, 0.0683, None, None, None, None, None
7.708, 370, 0.0656, None, None, None, None, None
7.917, 380, 0.0413, None, None, None, None, None
8.000, 384, None, 1.1519, 0.4993, 0.6828, 0.5768, 0.9007
8.125, 390, 0.0501, None, None, None, None, None
8.333, 400, 0.0473, None, None, None, None, None
8.542, 410, 0.0455, None, None, None, None, None
8.750, 420, 0.0576, None, None, None, None, None
8.958, 430, 0.0536, None, None, None, None, None
9.000, 432, None, 1.2804, 0.5242, 0.6679, 0.5874, 0.9168
9.167, 440, 0.0305, None, None, None, None, None
9.375, 450, 0.0310, None, None, None, None, None
9.583, 460, 0.0578, None, None, None, None, None
9.792, 470, 0.0221, None, None, None, None, None
10.000, 480, 0.0423, None, None, None, None, None
10.000, 480, None, 1.3396, 0.5446, 0.6828, 0.6060, 0.9197
10.000, 480, None, None, None, None, None, None
10.000, 480, None, 1.3396, 0.5446, 0.6828, 0.6060, 0.9197

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2870, None, None, None, None, None
0.408, 20, 3.2307, None, None, None, None, None
0.612, 30, 2.7948, None, None, None, None, None
0.816, 40, 2.4717, None, None, None, None, None
1.000, 49, None, 2.1857, 0.0431, 0.4422, 0.0785, 0.1573
1.020, 50, 2.2007, None, None, None, None, None
1.224, 60, 1.7750, None, None, None, None, None
1.429, 70, 1.5446, None, None, None, None, None
1.633, 80, 1.4064, None, None, None, None, None
1.837, 90, 1.1293, None, None, None, None, None
2.000, 98, None, 1.2047, 0.1887, 0.6859, 0.2959, 0.7230
2.041, 100, 0.9958, None, None, None, None, None
2.245, 110, 0.6308, None, None, None, None, None
2.449, 120, 0.5723, None, None, None, None, None
2.653, 130, 0.6199, None, None, None, None, None
2.857, 140, 0.5800, None, None, None, None, None
3.000, 147, None, 1.1411, 0.1701, 0.6206, 0.2670, 0.5437
3.061, 150, 0.4420, None, None, None, None, None
3.265, 160, 0.3797, None, None, None, None, None
3.469, 170, 0.4071, None, None, None, None, None
3.673, 180, 0.3524, None, None, None, None, None
3.878, 190, 0.2781, None, None, None, None, None
4.000, 196, None, 1.0524, 0.2417, 0.6960, 0.3588, 0.6370
4.082, 200, 0.3370, None, None, None, None, None
4.286, 210, 0.1639, None, None, None, None, None
4.490, 220, 0.2515, None, None, None, None, None
4.694, 230, 0.1826, None, None, None, None, None
4.898, 240, 0.2534, None, None, None, None, None
5.000, 245, None, 1.0491, 0.2859, 0.5854, 0.3842, 0.7763
5.102, 250, 0.1937, None, None, None, None, None
5.306, 260, 0.1421, None, None, None, None, None
5.510, 270, 0.1259, None, None, None, None, None
5.714, 280, 0.1243, None, None, None, None, None
5.918, 290, 0.1491, None, None, None, None, None
6.000, 294, None, 1.1500, 0.3463, 0.6734, 0.4573, 0.8240
6.122, 300, 0.1711, None, None, None, None, None
6.327, 310, 0.0755, None, None, None, None, None
6.531, 320, 0.0926, None, None, None, None, None
6.735, 330, 0.1002, None, None, None, None, None
6.939, 340, 0.1635, None, None, None, None, None
7.000, 343, None, 1.3804, 0.4664, 0.6633, 0.5477, 0.8982
7.143, 350, 0.0775, None, None, None, None, None
7.347, 360, 0.0900, None, None, None, None, None
7.551, 370, 0.0895, None, None, None, None, None
7.755, 380, 0.1335, None, None, None, None, None
7.959, 390, 0.0207, None, None, None, None, None
8.000, 392, None, 1.5710, 0.5635, 0.6910, 0.6208, 0.9258
8.163, 400, 0.0453, None, None, None, None, None
8.367, 410, 0.0519, None, None, None, None, None
8.571, 420, 0.0756, None, None, None, None, None
8.776, 430, 0.0907, None, None, None, None, None
8.980, 440, 0.0586, None, None, None, None, None
9.000, 441, None, 1.4993, 0.5453, 0.6960, 0.6115, 0.9111
9.184, 450, 0.0989, None, None, None, None, None
9.388, 460, 0.0209, None, None, None, None, None
9.592, 470, 0.0210, None, None, None, None, None
9.796, 480, 0.0411, None, None, None, None, None
10.000, 490, 0.0650, None, None, None, None, None
10.000, 490, None, 1.5468, 0.5551, 0.6960, 0.6176, 0.9142
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.5468, 0.5551, 0.6960, 0.6176, 0.9142

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3242, None, None, None, None, None
0.408, 20, 3.1309, None, None, None, None, None
0.612, 30, 2.7688, None, None, None, None, None
0.816, 40, 2.7048, None, None, None, None, None
1.000, 49, None, 1.9305, 0.0705, 0.5234, 0.1243, 0.1478
1.020, 50, 2.3553, None, None, None, None, None
1.224, 60, 1.8399, None, None, None, None, None
1.429, 70, 1.5921, None, None, None, None, None
1.633, 80, 1.4274, None, None, None, None, None
1.837, 90, 1.0971, None, None, None, None, None
2.000, 98, None, 0.9940, 0.1341, 0.6393, 0.2216, 0.1473
2.041, 100, 1.3048, None, None, None, None, None
2.245, 110, 0.7793, None, None, None, None, None
2.449, 120, 0.7054, None, None, None, None, None
2.653, 130, 0.6723, None, None, None, None, None
2.857, 140, 0.7334, None, None, None, None, None
3.000, 147, None, 0.5451, 0.2348, 0.7215, 0.3543, 0.7028
3.061, 150, 0.4406, None, None, None, None, None
3.265, 160, 0.4423, None, None, None, None, None
3.469, 170, 0.3957, None, None, None, None, None
3.673, 180, 0.3877, None, None, None, None, None
3.878, 190, 0.3059, None, None, None, None, None
4.000, 196, None, 0.4202, 0.2267, 0.6636, 0.3379, 0.7054
4.082, 200, 0.3612, None, None, None, None, None
4.286, 210, 0.2244, None, None, None, None, None
4.490, 220, 0.2888, None, None, None, None, None
4.694, 230, 0.1883, None, None, None, None, None
4.898, 240, 0.3585, None, None, None, None, None
5.000, 245, None, 0.4426, 0.2643, 0.6654, 0.3783, 0.6484
5.102, 250, 0.3216, None, None, None, None, None
5.306, 260, 0.1732, None, None, None, None, None
5.510, 270, 0.2238, None, None, None, None, None
5.714, 280, 0.1984, None, None, None, None, None
5.918, 290, 0.1224, None, None, None, None, None
6.000, 294, None, 0.4340, 0.4485, 0.6916, 0.5441, 0.8808
6.122, 300, 0.1062, None, None, None, None, None
6.327, 310, 0.1289, None, None, None, None, None
6.531, 320, 0.1493, None, None, None, None, None
6.735, 330, 0.1217, None, None, None, None, None
6.939, 340, 0.0634, None, None, None, None, None
7.000, 343, None, 0.5122, 0.5377, 0.7589, 0.6295, 0.9014
7.143, 350, 0.1485, None, None, None, None, None
7.347, 360, 0.0798, None, None, None, None, None
7.551, 370, 0.0627, None, None, None, None, None
7.755, 380, 0.0959, None, None, None, None, None
7.959, 390, 0.0334, None, None, None, None, None
8.000, 392, None, 0.5057, 0.5328, 0.7439, 0.6209, 0.9032
8.163, 400, 0.0719, None, None, None, None, None
8.367, 410, 0.0679, None, None, None, None, None
8.571, 420, 0.0787, None, None, None, None, None
8.776, 430, 0.0975, None, None, None, None, None
8.980, 440, 0.0698, None, None, None, None, None
9.000, 441, None, 0.5413, 0.5458, 0.7346, 0.6263, 0.9108
9.184, 450, 0.0883, None, None, None, None, None
9.388, 460, 0.0332, None, None, None, None, None
9.592, 470, 0.0209, None, None, None, None, None
9.796, 480, 0.0336, None, None, None, None, None
10.000, 490, 0.1039, None, None, None, None, None
10.000, 490, None, 0.5942, 0.6224, 0.7794, 0.6921, 0.9257
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 0.5942, 0.6224, 0.7794, 0.6921, 0.9257

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2728, None, None, None, None, None
0.408, 20, 3.0710, None, None, None, None, None
0.612, 30, 2.9176, None, None, None, None, None
0.816, 40, 2.5615, None, None, None, None, None
1.000, 49, None, 2.1547, 0.0480, 0.3543, 0.0845, 0.3959
1.020, 50, 2.2635, None, None, None, None, None
1.224, 60, 1.7302, None, None, None, None, None
1.429, 70, 1.6351, None, None, None, None, None
1.633, 80, 1.1654, None, None, None, None, None
1.837, 90, 1.4034, None, None, None, None, None
2.000, 98, None, 1.2003, 0.1501, 0.5761, 0.2382, 0.6400
2.041, 100, 0.8625, None, None, None, None, None
2.245, 110, 0.7073, None, None, None, None, None
2.449, 120, 0.5992, None, None, None, None, None
2.653, 130, 0.4288, None, None, None, None, None
2.857, 140, 0.5187, None, None, None, None, None
3.000, 147, None, 1.0628, 0.2532, 0.6109, 0.3580, 0.7095
3.061, 150, 0.4907, None, None, None, None, None
3.265, 160, 0.3283, None, None, None, None, None
3.469, 170, 0.2890, None, None, None, None, None
3.673, 180, 0.2276, None, None, None, None, None
3.878, 190, 0.3645, None, None, None, None, None
4.000, 196, None, 0.9373, 0.2995, 0.6543, 0.4109, 0.8494
4.082, 200, 0.3613, None, None, None, None, None
4.286, 210, 0.1430, None, None, None, None, None
4.490, 220, 0.2120, None, None, None, None, None
4.694, 230, 0.2222, None, None, None, None, None
4.898, 240, 0.1932, None, None, None, None, None
5.000, 245, None, 1.2095, 0.2948, 0.5652, 0.3875, 0.8260
5.102, 250, 0.1606, None, None, None, None, None
5.306, 260, 0.1231, None, None, None, None, None
5.510, 270, 0.1433, None, None, None, None, None
5.714, 280, 0.1854, None, None, None, None, None
5.918, 290, 0.1296, None, None, None, None, None
6.000, 294, None, 1.4070, 0.4401, 0.6543, 0.5262, 0.8853
6.122, 300, 0.1010, None, None, None, None, None
6.327, 310, 0.0527, None, None, None, None, None
6.531, 320, 0.0937, None, None, None, None, None
6.735, 330, 0.1311, None, None, None, None, None
6.939, 340, 0.1085, None, None, None, None, None
7.000, 343, None, 1.4072, 0.4045, 0.6217, 0.4901, 0.8825
7.143, 350, 0.0807, None, None, None, None, None
7.347, 360, 0.0794, None, None, None, None, None
7.551, 370, 0.0857, None, None, None, None, None
7.755, 380, 0.0813, None, None, None, None, None
7.959, 390, 0.0289, None, None, None, None, None
8.000, 392, None, 1.4704, 0.4944, 0.6674, 0.5680, 0.8946
8.163, 400, 0.0448, None, None, None, None, None
8.367, 410, 0.0683, None, None, None, None, None
8.571, 420, 0.0348, None, None, None, None, None
8.776, 430, 0.1830, None, None, None, None, None
8.980, 440, 0.0232, None, None, None, None, None
9.000, 441, None, 1.4012, 0.5316, 0.6761, 0.5952, 0.9331
9.184, 450, 0.0356, None, None, None, None, None
9.388, 460, 0.0254, None, None, None, None, None
9.592, 470, 0.0483, None, None, None, None, None
9.796, 480, 0.0377, None, None, None, None, None
10.000, 490, 0.0819, None, None, None, None, None
10.000, 490, None, 1.4476, 0.5418, 0.6761, 0.6015, 0.9382
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.4476, 0.5418, 0.6761, 0.6015, 0.9382

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3034, None, None, None, None, None
0.408, 20, 3.0937, None, None, None, None, None
0.612, 30, 2.9349, None, None, None, None, None
0.816, 40, 2.6328, None, None, None, None, None
1.000, 49, None, 2.0129, 0.0558, 0.5178, 0.1007, 0.2249
1.020, 50, 2.4058, None, None, None, None, None
1.224, 60, 1.9074, None, None, None, None, None
1.429, 70, 1.4097, None, None, None, None, None
1.633, 80, 1.3476, None, None, None, None, None
1.837, 90, 1.1354, None, None, None, None, None
2.000, 98, None, 1.0143, 0.1716, 0.6511, 0.2717, 0.6888
2.041, 100, 1.2436, None, None, None, None, None
2.245, 110, 0.7077, None, None, None, None, None
2.449, 120, 0.6171, None, None, None, None, None
2.653, 130, 0.7202, None, None, None, None, None
2.857, 140, 0.7004, None, None, None, None, None
3.000, 147, None, 0.7001, 0.2558, 0.7644, 0.3833, 0.7224
3.061, 150, 0.4687, None, None, None, None, None
3.265, 160, 0.3925, None, None, None, None, None
3.469, 170, 0.3841, None, None, None, None, None
3.673, 180, 0.3488, None, None, None, None, None
3.878, 190, 0.3004, None, None, None, None, None
4.000, 196, None, 0.7276, 0.2479, 0.6511, 0.3591, 0.7491
4.082, 200, 0.3178, None, None, None, None, None
4.286, 210, 0.1522, None, None, None, None, None
4.490, 220, 0.2595, None, None, None, None, None
4.694, 230, 0.1773, None, None, None, None, None
4.898, 240, 0.3033, None, None, None, None, None
5.000, 245, None, 0.6958, 0.3344, 0.6911, 0.4507, 0.8243
5.102, 250, 0.1834, None, None, None, None, None
5.306, 260, 0.0998, None, None, None, None, None
5.510, 270, 0.1723, None, None, None, None, None
5.714, 280, 0.2781, None, None, None, None, None
5.918, 290, 0.0896, None, None, None, None, None
6.000, 294, None, 0.8764, 0.5599, 0.7578, 0.6440, 0.9239
6.122, 300, 0.0851, None, None, None, None, None
6.327, 310, 0.0658, None, None, None, None, None
6.531, 320, 0.1307, None, None, None, None, None
6.735, 330, 0.1078, None, None, None, None, None
6.939, 340, 0.0953, None, None, None, None, None
7.000, 343, None, 0.8989, 0.5354, 0.7556, 0.6267, 0.9100
7.143, 350, 0.1094, None, None, None, None, None
7.347, 360, 0.0836, None, None, None, None, None
7.551, 370, 0.0593, None, None, None, None, None
7.755, 380, 0.0673, None, None, None, None, None
7.959, 390, 0.0327, None, None, None, None, None
8.000, 392, None, 1.0609, 0.5963, 0.7778, 0.6750, 0.9319
8.163, 400, 0.0385, None, None, None, None, None
8.367, 410, 0.0370, None, None, None, None, None
8.571, 420, 0.0668, None, None, None, None, None
8.776, 430, 0.1057, None, None, None, None, None
8.980, 440, 0.0491, None, None, None, None, None
9.000, 441, None, 1.0418, 0.5904, 0.7689, 0.6680, 0.9275
9.184, 450, 0.0558, None, None, None, None, None
9.388, 460, 0.0397, None, None, None, None, None
9.592, 470, 0.0298, None, None, None, None, None
9.796, 480, 0.0364, None, None, None, None, None
10.000, 490, 0.0692, None, None, None, None, None
10.000, 490, None, 1.0873, 0.6186, 0.7822, 0.6909, 0.9322
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.0873, 0.6186, 0.7822, 0.6909, 0.9322

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.417, 10, 3.2617, None, None, None, None, None
0.833, 20, 2.9183, None, None, None, None, None
1.000, 24, None, 2.5390, 0.0222, 0.2481, 0.0408, 0.0522
1.250, 30, 2.3139, None, None, None, None, None
1.667, 40, 1.9378, None, None, None, None, None
2.000, 48, None, 1.4713, 0.1318, 0.6493, 0.2191, 0.5985
2.083, 50, 1.4158, None, None, None, None, None
2.500, 60, 0.9761, None, None, None, None, None
2.917, 70, 0.7634, None, None, None, None, None
3.000, 72, None, 1.0520, 0.1450, 0.6847, 0.2393, 0.3508
3.333, 80, 0.5577, None, None, None, None, None
3.750, 90, 0.4832, None, None, None, None, None
4.000, 96, None, 0.9862, 0.1783, 0.6250, 0.2774, 0.6514
4.167, 100, 0.3928, None, None, None, None, None
4.583, 110, 0.3539, None, None, None, None, None
5.000, 120, 0.3140, None, None, None, None, None
5.000, 120, None, 0.8918, 0.2764, 0.6306, 0.3843, 0.7800
5.417, 130, 0.2219, None, None, None, None, None
5.833, 140, 0.1917, None, None, None, None, None
6.000, 144, None, 0.8405, 0.3012, 0.6474, 0.4111, 0.7866
6.250, 150, 0.1423, None, None, None, None, None
6.667, 160, 0.1456, None, None, None, None, None
7.000, 168, None, 1.0692, 0.3868, 0.6250, 0.4779, 0.8741
7.083, 170, 0.1301, None, None, None, None, None
7.500, 180, 0.0982, None, None, None, None, None
7.917, 190, 0.0909, None, None, None, None, None
8.000, 192, None, 1.0080, 0.3792, 0.6269, 0.4726, 0.8721
8.333, 200, 0.0796, None, None, None, None, None
8.750, 210, 0.0951, None, None, None, None, None
9.000, 216, None, 1.0243, 0.4204, 0.6455, 0.5092, 0.8849
9.167, 220, 0.0730, None, None, None, None, None
9.583, 230, 0.0839, None, None, None, None, None
10.000, 240, 0.0624, None, None, None, None, None
10.000, 240, None, 1.0487, 0.4295, 0.6474, 0.5164, 0.8882
10.000, 240, None, None, None, None, None, None
10.000, 240, None, 1.0487, 0.4295, 0.6474, 0.5164, 0.8882

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2865, None, None, None, None, None
0.800, 20, 2.8067, None, None, None, None, None
1.000, 25, None, 2.4962, 0.0218, 0.2613, 0.0402, 0.0464
1.200, 30, 2.4435, None, None, None, None, None
1.600, 40, 1.9335, None, None, None, None, None
2.000, 50, 1.5552, None, None, None, None, None
2.000, 50, None, 1.5598, 0.0917, 0.6030, 0.1592, 0.4289
2.400, 60, 1.0528, None, None, None, None, None
2.800, 70, 0.8283, None, None, None, None, None
3.000, 75, None, 1.3056, 0.1407, 0.5578, 0.2247, 0.5459
3.200, 80, 0.6521, None, None, None, None, None
3.600, 90, 0.5825, None, None, None, None, None
4.000, 100, 0.5246, None, None, None, None, None
4.000, 100, None, 1.0755, 0.2030, 0.6784, 0.3125, 0.6343
4.400, 110, 0.3064, None, None, None, None, None
4.800, 120, 0.3772, None, None, None, None, None
5.000, 125, None, 0.9908, 0.2350, 0.6181, 0.3405, 0.7538
5.200, 130, 0.2861, None, None, None, None, None
5.600, 140, 0.2212, None, None, None, None, None
6.000, 150, 0.2228, None, None, None, None, None
6.000, 150, None, 1.0182, 0.2658, 0.6457, 0.3766, 0.7739
6.400, 160, 0.1599, None, None, None, None, None
6.800, 170, 0.1580, None, None, None, None, None
7.000, 175, None, 1.0987, 0.3627, 0.6508, 0.4658, 0.8534
7.200, 180, 0.1498, None, None, None, None, None
7.600, 190, 0.1202, None, None, None, None, None
8.000, 200, 0.1093, None, None, None, None, None
8.000, 200, None, 1.0994, 0.3789, 0.6683, 0.4836, 0.8578
8.400, 210, 0.0775, None, None, None, None, None
8.800, 220, 0.1428, None, None, None, None, None
9.000, 225, None, 1.1692, 0.4247, 0.6658, 0.5186, 0.8732
9.200, 230, 0.0834, None, None, None, None, None
9.600, 240, 0.0695, None, None, None, None, None
10.000, 250, 0.0985, None, None, None, None, None
10.000, 250, None, 1.1642, 0.4204, 0.6633, 0.5146, 0.8706
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1642, 0.4204, 0.6633, 0.5146, 0.8706

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2397, None, None, None, None, None
0.800, 20, 2.8779, None, None, None, None, None
1.000, 25, None, 2.2395, 0.0377, 0.3981, 0.0688, 0.0677
1.200, 30, 2.4153, None, None, None, None, None
1.600, 40, 1.9332, None, None, None, None, None
2.000, 50, 1.4688, None, None, None, None, None
2.000, 50, None, 1.2155, 0.1159, 0.6056, 0.1945, 0.3203
2.400, 60, 1.0140, None, None, None, None, None
2.800, 70, 0.9467, None, None, None, None, None
3.000, 75, None, 0.6049, 0.1594, 0.7252, 0.2614, 0.5252
3.200, 80, 0.5849, None, None, None, None, None
3.600, 90, 0.4809, None, None, None, None, None
4.000, 100, 0.4522, None, None, None, None, None
4.000, 100, None, 0.4398, 0.3306, 0.7477, 0.4585, 0.7867
4.400, 110, 0.2946, None, None, None, None, None
4.800, 120, 0.2796, None, None, None, None, None
5.000, 125, None, 0.4529, 0.2456, 0.7570, 0.3709, 0.6039
5.200, 130, 0.3210, None, None, None, None, None
5.600, 140, 0.2367, None, None, None, None, None
6.000, 150, 0.1575, None, None, None, None, None
6.000, 150, None, 0.3747, 0.4068, 0.7383, 0.5246, 0.8474
6.400, 160, 0.1735, None, None, None, None, None
6.800, 170, 0.1369, None, None, None, None, None
7.000, 175, None, 0.3774, 0.3598, 0.6953, 0.4742, 0.8196
7.200, 180, 0.1050, None, None, None, None, None
7.600, 190, 0.0925, None, None, None, None, None
8.000, 200, 0.1059, None, None, None, None, None
8.000, 200, None, 0.3812, 0.4638, 0.7421, 0.5708, 0.8762
8.400, 210, 0.0926, None, None, None, None, None
8.800, 220, 0.0889, None, None, None, None, None
9.000, 225, None, 0.3861, 0.4674, 0.7364, 0.5718, 0.8715
9.200, 230, 0.0911, None, None, None, None, None
9.600, 240, 0.0657, None, None, None, None, None
10.000, 250, 0.1028, None, None, None, None, None
10.000, 250, None, 0.3865, 0.4757, 0.7327, 0.5769, 0.8804
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.3865, 0.4757, 0.7327, 0.5769, 0.8804

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2200, None, None, None, None, None
0.800, 20, 2.8992, None, None, None, None, None
1.000, 25, None, 2.4105, 0.0314, 0.3913, 0.0581, 0.0811
1.200, 30, 2.3201, None, None, None, None, None
1.600, 40, 1.8603, None, None, None, None, None
2.000, 50, 1.5057, None, None, None, None, None
2.000, 50, None, 1.4734, 0.1060, 0.5696, 0.1787, 0.4724
2.400, 60, 1.0043, None, None, None, None, None
2.800, 70, 0.7240, None, None, None, None, None
3.000, 75, None, 1.0191, 0.1515, 0.6478, 0.2456, 0.4793
3.200, 80, 0.5542, None, None, None, None, None
3.600, 90, 0.3976, None, None, None, None, None
4.000, 100, 0.5280, None, None, None, None, None
4.000, 100, None, 1.1291, 0.1953, 0.6196, 0.2970, 0.6898
4.400, 110, 0.2608, None, None, None, None, None
4.800, 120, 0.3668, None, None, None, None, None
5.000, 125, None, 0.9329, 0.2722, 0.6326, 0.3806, 0.8276
5.200, 130, 0.2345, None, None, None, None, None
5.600, 140, 0.1829, None, None, None, None, None
6.000, 150, 0.1812, None, None, None, None, None
6.000, 150, None, 0.9157, 0.3140, 0.6348, 0.4201, 0.8471
6.400, 160, 0.1480, None, None, None, None, None
6.800, 170, 0.1336, None, None, None, None, None
7.000, 175, None, 1.0927, 0.3416, 0.6304, 0.4431, 0.8398
7.200, 180, 0.1332, None, None, None, None, None
7.600, 190, 0.1076, None, None, None, None, None
8.000, 200, 0.0957, None, None, None, None, None
8.000, 200, None, 1.0427, 0.4072, 0.6630, 0.5045, 0.8783
8.400, 210, 0.0903, None, None, None, None, None
8.800, 220, 0.0916, None, None, None, None, None
9.000, 225, None, 1.0940, 0.4443, 0.6587, 0.5306, 0.9022
9.200, 230, 0.0655, None, None, None, None, None
9.600, 240, 0.0657, None, None, None, None, None
10.000, 250, 0.1047, None, None, None, None, None
10.000, 250, None, 1.0995, 0.4535, 0.6565, 0.5364, 0.9051
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.0995, 0.4535, 0.6565, 0.5364, 0.9051

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2209, None, None, None, None, None
0.800, 20, 2.9283, None, None, None, None, None
1.000, 25, None, 2.2131, 0.0364, 0.4600, 0.0675, 0.0734
1.200, 30, 2.4040, None, None, None, None, None
1.600, 40, 1.9089, None, None, None, None, None
2.000, 50, 1.4818, None, None, None, None, None
2.000, 50, None, 1.2144, 0.1229, 0.6711, 0.2078, 0.5126
2.400, 60, 1.0249, None, None, None, None, None
2.800, 70, 0.8383, None, None, None, None, None
3.000, 75, None, 0.7329, 0.1666, 0.7689, 0.2738, 0.6055
3.200, 80, 0.5856, None, None, None, None, None
3.600, 90, 0.4410, None, None, None, None, None
4.000, 100, 0.4465, None, None, None, None, None
4.000, 100, None, 0.6887, 0.2263, 0.6911, 0.3410, 0.7387
4.400, 110, 0.2660, None, None, None, None, None
4.800, 120, 0.3247, None, None, None, None, None
5.000, 125, None, 0.6607, 0.2639, 0.6844, 0.3810, 0.7204
5.200, 130, 0.2623, None, None, None, None, None
5.600, 140, 0.2159, None, None, None, None, None
6.000, 150, 0.1733, None, None, None, None, None
6.000, 150, None, 0.6907, 0.3768, 0.6800, 0.4849, 0.8629
6.400, 160, 0.1439, None, None, None, None, None
6.800, 170, 0.1378, None, None, None, None, None
7.000, 175, None, 0.7234, 0.4359, 0.7178, 0.5424, 0.8823
7.200, 180, 0.1429, None, None, None, None, None
7.600, 190, 0.0866, None, None, None, None, None
8.000, 200, 0.0742, None, None, None, None, None
8.000, 200, None, 0.7888, 0.5030, 0.7422, 0.5996, 0.9024
8.400, 210, 0.0647, None, None, None, None, None
8.800, 220, 0.0945, None, None, None, None, None
9.000, 225, None, 0.7985, 0.4977, 0.7356, 0.5937, 0.9002
9.200, 230, 0.0799, None, None, None, None, None
9.600, 240, 0.0652, None, None, None, None, None
10.000, 250, 0.0787, None, None, None, None, None
10.000, 250, None, 0.8078, 0.5099, 0.7422, 0.6045, 0.9036
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.8078, 0.5099, 0.7422, 0.6045, 0.9036

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.417, 10, 3.2617, None, None, None, None, None
0.833, 20, 2.9183, None, None, None, None, None
1.000, 24, None, 2.5390, 0.0222, 0.2481, 0.0408, 0.0522
1.250, 30, 2.3142, None, None, None, None, None
1.667, 40, 1.9429, None, None, None, None, None
2.000, 48, None, 1.5024, 0.1300, 0.6455, 0.2164, 0.5994
2.083, 50, 1.4331, None, None, None, None, None
2.500, 60, 1.0014, None, None, None, None, None
2.917, 70, 0.7923, None, None, None, None, None
3.000, 72, None, 1.0644, 0.1405, 0.6716, 0.2324, 0.3451
3.333, 80, 0.5865, None, None, None, None, None
3.750, 90, 0.4969, None, None, None, None, None
4.000, 96, None, 1.0009, 0.1732, 0.6306, 0.2718, 0.6470
4.167, 100, 0.4086, None, None, None, None, None
4.583, 110, 0.3771, None, None, None, None, None
5.000, 120, 0.3435, None, None, None, None, None
5.000, 120, None, 0.8594, 0.2587, 0.6119, 0.3636, 0.7790
5.417, 130, 0.2500, None, None, None, None, None
5.833, 140, 0.1905, None, None, None, None, None
6.000, 144, None, 0.8311, 0.2680, 0.6474, 0.3790, 0.7407
6.250, 150, 0.1635, None, None, None, None, None
6.667, 160, 0.1785, None, None, None, None, None
7.000, 168, None, 1.0298, 0.3808, 0.6138, 0.4700, 0.8758
7.083, 170, 0.1548, None, None, None, None, None
7.500, 180, 0.1117, None, None, None, None, None
7.917, 190, 0.0966, None, None, None, None, None
8.000, 192, None, 1.0585, 0.4208, 0.6493, 0.5106, 0.8872
8.333, 200, 0.0846, None, None, None, None, None
8.750, 210, 0.0974, None, None, None, None, None
9.000, 216, None, 1.1044, 0.4446, 0.6362, 0.5234, 0.9002
9.167, 220, 0.0740, None, None, None, None, None
9.583, 230, 0.0745, None, None, None, None, None
10.000, 240, 0.0640, None, None, None, None, None
10.000, 240, None, 1.1581, 0.4532, 0.6418, 0.5313, 0.9014
10.000, 240, None, None, None, None, None, None
10.000, 240, None, 1.1581, 0.4532, 0.6418, 0.5313, 0.9014

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2864, None, None, None, None, None
0.800, 20, 2.8067, None, None, None, None, None
1.000, 25, None, 2.4963, 0.0218, 0.2613, 0.0402, 0.0464
1.200, 30, 2.4436, None, None, None, None, None
1.600, 40, 1.9379, None, None, None, None, None
2.000, 50, 1.5725, None, None, None, None, None
2.000, 50, None, 1.5761, 0.0935, 0.6156, 0.1624, 0.4387
2.400, 60, 1.0830, None, None, None, None, None
2.800, 70, 0.8448, None, None, None, None, None
3.000, 75, None, 1.2980, 0.1377, 0.5704, 0.2219, 0.5386
3.200, 80, 0.6715, None, None, None, None, None
3.600, 90, 0.6185, None, None, None, None, None
4.000, 100, 0.5647, None, None, None, None, None
4.000, 100, None, 1.0945, 0.2111, 0.6683, 0.3209, 0.7021
4.400, 110, 0.3476, None, None, None, None, None
4.800, 120, 0.4021, None, None, None, None, None
5.000, 125, None, 0.9840, 0.2225, 0.6156, 0.3269, 0.7476
5.200, 130, 0.3076, None, None, None, None, None
5.600, 140, 0.2371, None, None, None, None, None
6.000, 150, 0.2490, None, None, None, None, None
6.000, 150, None, 0.9875, 0.2732, 0.6658, 0.3874, 0.7843
6.400, 160, 0.1790, None, None, None, None, None
6.800, 170, 0.1898, None, None, None, None, None
7.000, 175, None, 1.0642, 0.3460, 0.6658, 0.4553, 0.8324
7.200, 180, 0.1594, None, None, None, None, None
7.600, 190, 0.1300, None, None, None, None, None
8.000, 200, 0.1244, None, None, None, None, None
8.000, 200, None, 1.1342, 0.4125, 0.6633, 0.5087, 0.8672
8.400, 210, 0.0845, None, None, None, None, None
8.800, 220, 0.1498, None, None, None, None, None
9.000, 225, None, 1.1547, 0.4050, 0.6533, 0.5000, 0.8716
9.200, 230, 0.0802, None, None, None, None, None
9.600, 240, 0.0708, None, None, None, None, None
10.000, 250, 0.0963, None, None, None, None, None
10.000, 250, None, 1.1767, 0.4225, 0.6508, 0.5124, 0.8765
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1767, 0.4225, 0.6508, 0.5124, 0.8765

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2398, None, None, None, None, None
0.800, 20, 2.8779, None, None, None, None, None
1.000, 25, None, 2.2396, 0.0377, 0.3981, 0.0689, 0.0677
1.200, 30, 2.4155, None, None, None, None, None
1.600, 40, 1.9349, None, None, None, None, None
2.000, 50, 1.4804, None, None, None, None, None
2.000, 50, None, 1.2320, 0.1135, 0.6075, 0.1912, 0.3204
2.400, 60, 1.0347, None, None, None, None, None
2.800, 70, 0.9653, None, None, None, None, None
3.000, 75, None, 0.6268, 0.1554, 0.7271, 0.2560, 0.5171
3.200, 80, 0.6137, None, None, None, None, None
3.600, 90, 0.5099, None, None, None, None, None
4.000, 100, 0.4802, None, None, None, None, None
4.000, 100, None, 0.4695, 0.3583, 0.7607, 0.4871, 0.8392
4.400, 110, 0.3317, None, None, None, None, None
4.800, 120, 0.3181, None, None, None, None, None
5.000, 125, None, 0.4525, 0.2382, 0.7607, 0.3627, 0.6022
5.200, 130, 0.3473, None, None, None, None, None
5.600, 140, 0.2534, None, None, None, None, None
6.000, 150, 0.1756, None, None, None, None, None
6.000, 150, None, 0.3907, 0.4036, 0.7477, 0.5242, 0.8504
6.400, 160, 0.1918, None, None, None, None, None
6.800, 170, 0.1543, None, None, None, None, None
7.000, 175, None, 0.3878, 0.3687, 0.7271, 0.4893, 0.7972
7.200, 180, 0.1270, None, None, None, None, None
7.600, 190, 0.0976, None, None, None, None, None
8.000, 200, 0.1173, None, None, None, None, None
8.000, 200, None, 0.4119, 0.4653, 0.7383, 0.5708, 0.8732
8.400, 210, 0.0978, None, None, None, None, None
8.800, 220, 0.1015, None, None, None, None, None
9.000, 225, None, 0.3977, 0.4443, 0.7159, 0.5483, 0.8645
9.200, 230, 0.0895, None, None, None, None, None
9.600, 240, 0.0675, None, None, None, None, None
10.000, 250, 0.1081, None, None, None, None, None
10.000, 250, None, 0.4160, 0.5187, 0.7514, 0.6137, 0.9011
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.4160, 0.5187, 0.7514, 0.6137, 0.9011

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2200, None, None, None, None, None
0.800, 20, 2.8992, None, None, None, None, None
1.000, 25, None, 2.4105, 0.0314, 0.3913, 0.0581, 0.0809
1.200, 30, 2.3203, None, None, None, None, None
1.600, 40, 1.8651, None, None, None, None, None
2.000, 50, 1.5138, None, None, None, None, None
2.000, 50, None, 1.4878, 0.1029, 0.5630, 0.1741, 0.4547
2.400, 60, 1.0206, None, None, None, None, None
2.800, 70, 0.7394, None, None, None, None, None
3.000, 75, None, 1.0407, 0.1472, 0.6478, 0.2398, 0.4444
3.200, 80, 0.5733, None, None, None, None, None
3.600, 90, 0.4213, None, None, None, None, None
4.000, 100, 0.5062, None, None, None, None, None
4.000, 100, None, 1.0345, 0.2033, 0.6478, 0.3094, 0.7044
4.400, 110, 0.2590, None, None, None, None, None
4.800, 120, 0.3777, None, None, None, None, None
5.000, 125, None, 0.9138, 0.2653, 0.6326, 0.3738, 0.8167
5.200, 130, 0.2383, None, None, None, None, None
5.600, 140, 0.1973, None, None, None, None, None
6.000, 150, 0.2034, None, None, None, None, None
6.000, 150, None, 0.9948, 0.3121, 0.6500, 0.4217, 0.8274
6.400, 160, 0.1712, None, None, None, None, None
6.800, 170, 0.1440, None, None, None, None, None
7.000, 175, None, 1.1146, 0.3521, 0.6391, 0.4541, 0.8557
7.200, 180, 0.1483, None, None, None, None, None
7.600, 190, 0.1406, None, None, None, None, None
8.000, 200, 0.1021, None, None, None, None, None
8.000, 200, None, 1.0635, 0.3917, 0.6565, 0.4907, 0.8774
8.400, 210, 0.0951, None, None, None, None, None
8.800, 220, 0.1058, None, None, None, None, None
9.000, 225, None, 1.1555, 0.4640, 0.6717, 0.5488, 0.8974
9.200, 230, 0.0699, None, None, None, None, None
9.600, 240, 0.0586, None, None, None, None, None
10.000, 250, 0.1075, None, None, None, None, None
10.000, 250, None, 1.1525, 0.4740, 0.6739, 0.5566, 0.9074
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1525, 0.4740, 0.6739, 0.5566, 0.9074

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2209, None, None, None, None, None
0.800, 20, 2.9283, None, None, None, None, None
1.000, 25, None, 2.2131, 0.0364, 0.4600, 0.0675, 0.0734
1.200, 30, 2.4041, None, None, None, None, None
1.600, 40, 1.9143, None, None, None, None, None
2.000, 50, 1.4931, None, None, None, None, None
2.000, 50, None, 1.2338, 0.1207, 0.6644, 0.2043, 0.5054
2.400, 60, 1.0459, None, None, None, None, None
2.800, 70, 0.8532, None, None, None, None, None
3.000, 75, None, 0.7473, 0.1650, 0.7711, 0.2718, 0.6042
3.200, 80, 0.6132, None, None, None, None, None
3.600, 90, 0.4630, None, None, None, None, None
4.000, 100, 0.4530, None, None, None, None, None
4.000, 100, None, 0.6826, 0.2162, 0.7044, 0.3309, 0.7178
4.400, 110, 0.2671, None, None, None, None, None
4.800, 120, 0.3223, None, None, None, None, None
5.000, 125, None, 0.6323, 0.2455, 0.6733, 0.3599, 0.7107
5.200, 130, 0.2752, None, None, None, None, None
5.600, 140, 0.2462, None, None, None, None, None
6.000, 150, 0.2005, None, None, None, None, None
6.000, 150, None, 0.6780, 0.3648, 0.6867, 0.4765, 0.8522
6.400, 160, 0.1680, None, None, None, None, None
6.800, 170, 0.1497, None, None, None, None, None
7.000, 175, None, 0.7320, 0.4671, 0.7422, 0.5734, 0.8915
7.200, 180, 0.1533, None, None, None, None, None
7.600, 190, 0.1012, None, None, None, None, None
8.000, 200, 0.0946, None, None, None, None, None
8.000, 200, None, 0.8048, 0.5206, 0.7578, 0.6172, 0.9057
8.400, 210, 0.0646, None, None, None, None, None
8.800, 220, 0.0980, None, None, None, None, None
9.000, 225, None, 0.8007, 0.4905, 0.7422, 0.5906, 0.8965
9.200, 230, 0.0830, None, None, None, None, None
9.600, 240, 0.0588, None, None, None, None, None
10.000, 250, 0.0768, None, None, None, None, None
10.000, 250, None, 0.8741, 0.5525, 0.7600, 0.6399, 0.9164
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.8741, 0.5525, 0.7600, 0.6399, 0.9164

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.417, 10, 3.2617, None, None, None, None, None
0.833, 20, 2.9183, None, None, None, None, None
1.000, 24, None, 2.5390, 0.0222, 0.2481, 0.0408, 0.0522
1.250, 30, 2.3139, None, None, None, None, None
1.667, 40, 1.9379, None, None, None, None, None
2.000, 48, None, 1.4716, 0.1318, 0.6493, 0.2191, 0.5985
2.083, 50, 1.4162, None, None, None, None, None
2.500, 60, 0.9761, None, None, None, None, None
2.917, 70, 0.7633, None, None, None, None, None
3.000, 72, None, 1.0523, 0.1449, 0.6847, 0.2392, 0.3508
3.333, 80, 0.5577, None, None, None, None, None
3.750, 90, 0.4832, None, None, None, None, None
4.000, 96, None, 0.9864, 0.1790, 0.6269, 0.2785, 0.6510
4.167, 100, 0.3928, None, None, None, None, None
4.583, 110, 0.3540, None, None, None, None, None
5.000, 120, 0.3133, None, None, None, None, None
5.000, 120, None, 0.8914, 0.2776, 0.6325, 0.3859, 0.7801
5.417, 130, 0.2219, None, None, None, None, None
5.833, 140, 0.1922, None, None, None, None, None
6.000, 144, None, 0.8402, 0.3020, 0.6474, 0.4119, 0.7884
6.250, 150, 0.1424, None, None, None, None, None
6.667, 160, 0.1449, None, None, None, None, None
7.000, 168, None, 1.0648, 0.3882, 0.6287, 0.4801, 0.8724
7.083, 170, 0.1301, None, None, None, None, None
7.500, 180, 0.0986, None, None, None, None, None
7.917, 190, 0.0912, None, None, None, None, None
8.000, 192, None, 1.0020, 0.3797, 0.6269, 0.4729, 0.8724
8.333, 200, 0.0798, None, None, None, None, None
8.750, 210, 0.0954, None, None, None, None, None
9.000, 216, None, 1.0139, 0.4184, 0.6455, 0.5077, 0.8841
9.167, 220, 0.0731, None, None, None, None, None
9.583, 230, 0.0844, None, None, None, None, None
10.000, 240, 0.0625, None, None, None, None, None
10.000, 240, None, 1.0399, 0.4272, 0.6455, 0.5141, 0.8875
10.000, 240, None, None, None, None, None, None
10.000, 240, None, 1.0399, 0.4272, 0.6455, 0.5141, 0.8875

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2864, None, None, None, None, None
0.800, 20, 2.8068, None, None, None, None, None
1.000, 25, None, 2.4964, 0.0216, 0.2588, 0.0398, 0.0463
1.200, 30, 2.4436, None, None, None, None, None
1.600, 40, 1.9337, None, None, None, None, None
2.000, 50, 1.5555, None, None, None, None, None
2.000, 50, None, 1.5596, 0.0921, 0.6055, 0.1598, 0.4289
2.400, 60, 1.0528, None, None, None, None, None
2.800, 70, 0.8281, None, None, None, None, None
3.000, 75, None, 1.3055, 0.1405, 0.5578, 0.2245, 0.5448
3.200, 80, 0.6524, None, None, None, None, None
3.600, 90, 0.5829, None, None, None, None, None
4.000, 100, 0.5254, None, None, None, None, None
4.000, 100, None, 1.0753, 0.2038, 0.6809, 0.3137, 0.6357
4.400, 110, 0.3060, None, None, None, None, None
4.800, 120, 0.3771, None, None, None, None, None
5.000, 125, None, 0.9915, 0.2330, 0.6131, 0.3377, 0.7531
5.200, 130, 0.2859, None, None, None, None, None
5.600, 140, 0.2203, None, None, None, None, None
6.000, 150, 0.2215, None, None, None, None, None
6.000, 150, None, 1.0183, 0.2621, 0.6407, 0.3720, 0.7696
6.400, 160, 0.1593, None, None, None, None, None
6.800, 170, 0.1601, None, None, None, None, None
7.000, 175, None, 1.0968, 0.3601, 0.6533, 0.4643, 0.8530
7.200, 180, 0.1498, None, None, None, None, None
7.600, 190, 0.1211, None, None, None, None, None
8.000, 200, 0.1088, None, None, None, None, None
8.000, 200, None, 1.1015, 0.3805, 0.6683, 0.4850, 0.8581
8.400, 210, 0.0779, None, None, None, None, None
8.800, 220, 0.1427, None, None, None, None, None
9.000, 225, None, 1.1685, 0.4199, 0.6583, 0.5127, 0.8726
9.200, 230, 0.0834, None, None, None, None, None
9.600, 240, 0.0690, None, None, None, None, None
10.000, 250, 0.0992, None, None, None, None, None
10.000, 250, None, 1.1641, 0.4195, 0.6608, 0.5132, 0.8708
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1641, 0.4195, 0.6608, 0.5132, 0.8708

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2397, None, None, None, None, None
0.800, 20, 2.8780, None, None, None, None, None
1.000, 25, None, 2.2394, 0.0377, 0.3981, 0.0689, 0.0677
1.200, 30, 2.4154, None, None, None, None, None
1.600, 40, 1.9333, None, None, None, None, None
2.000, 50, 1.4687, None, None, None, None, None
2.000, 50, None, 1.2154, 0.1160, 0.6056, 0.1947, 0.3201
2.400, 60, 1.0141, None, None, None, None, None
2.800, 70, 0.9468, None, None, None, None, None
3.000, 75, None, 0.6050, 0.1592, 0.7252, 0.2611, 0.5251
3.200, 80, 0.5851, None, None, None, None, None
3.600, 90, 0.4810, None, None, None, None, None
4.000, 100, 0.4523, None, None, None, None, None
4.000, 100, None, 0.4397, 0.3311, 0.7477, 0.4590, 0.7869
4.400, 110, 0.2948, None, None, None, None, None
4.800, 120, 0.2799, None, None, None, None, None
5.000, 125, None, 0.4532, 0.2455, 0.7570, 0.3707, 0.6034
5.200, 130, 0.3213, None, None, None, None, None
5.600, 140, 0.2371, None, None, None, None, None
6.000, 150, 0.1575, None, None, None, None, None
6.000, 150, None, 0.3748, 0.4082, 0.7402, 0.5262, 0.8472
6.400, 160, 0.1734, None, None, None, None, None
6.800, 170, 0.1371, None, None, None, None, None
7.000, 175, None, 0.3775, 0.3574, 0.6935, 0.4717, 0.8196
7.200, 180, 0.1053, None, None, None, None, None
7.600, 190, 0.0927, None, None, None, None, None
8.000, 200, 0.1060, None, None, None, None, None
8.000, 200, None, 0.3814, 0.4649, 0.7421, 0.5716, 0.8762
8.400, 210, 0.0927, None, None, None, None, None
8.800, 220, 0.0889, None, None, None, None, None
9.000, 225, None, 0.3861, 0.4674, 0.7364, 0.5718, 0.8714
9.200, 230, 0.0911, None, None, None, None, None
9.600, 240, 0.0659, None, None, None, None, None
10.000, 250, 0.1026, None, None, None, None, None
10.000, 250, None, 0.3866, 0.4763, 0.7327, 0.5773, 0.8804
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.3866, 0.4763, 0.7327, 0.5773, 0.8804

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2200, None, None, None, None, None
0.800, 20, 2.8992, None, None, None, None, None
1.000, 25, None, 2.4105, 0.0314, 0.3913, 0.0582, 0.0811
1.200, 30, 2.3201, None, None, None, None, None
1.600, 40, 1.8604, None, None, None, None, None
2.000, 50, 1.5058, None, None, None, None, None
2.000, 50, None, 1.4734, 0.1059, 0.5696, 0.1787, 0.4722
2.400, 60, 1.0044, None, None, None, None, None
2.800, 70, 0.7241, None, None, None, None, None
3.000, 75, None, 1.0191, 0.1515, 0.6478, 0.2456, 0.4792
3.200, 80, 0.5545, None, None, None, None, None
3.600, 90, 0.3979, None, None, None, None, None
4.000, 100, 0.5284, None, None, None, None, None
4.000, 100, None, 1.1292, 0.1953, 0.6196, 0.2970, 0.6903
4.400, 110, 0.2609, None, None, None, None, None
4.800, 120, 0.3672, None, None, None, None, None
5.000, 125, None, 0.9341, 0.2725, 0.6326, 0.3809, 0.8287
5.200, 130, 0.2347, None, None, None, None, None
5.600, 140, 0.1828, None, None, None, None, None
6.000, 150, 0.1814, None, None, None, None, None
6.000, 150, None, 0.9174, 0.3129, 0.6326, 0.4187, 0.8469
6.400, 160, 0.1482, None, None, None, None, None
6.800, 170, 0.1337, None, None, None, None, None
7.000, 175, None, 1.0929, 0.3416, 0.6304, 0.4431, 0.8397
7.200, 180, 0.1333, None, None, None, None, None
7.600, 190, 0.1077, None, None, None, None, None
8.000, 200, 0.0959, None, None, None, None, None
8.000, 200, None, 1.0437, 0.4072, 0.6630, 0.5045, 0.8787
8.400, 210, 0.0905, None, None, None, None, None
8.800, 220, 0.0917, None, None, None, None, None
9.000, 225, None, 1.0944, 0.4457, 0.6609, 0.5324, 0.9025
9.200, 230, 0.0657, None, None, None, None, None
9.600, 240, 0.0658, None, None, None, None, None
10.000, 250, 0.1048, None, None, None, None, None
10.000, 250, None, 1.1000, 0.4535, 0.6565, 0.5364, 0.9051
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1000, 0.4535, 0.6565, 0.5364, 0.9051

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2209, None, None, None, None, None
0.800, 20, 2.9283, None, None, None, None, None
1.000, 25, None, 2.2131, 0.0364, 0.4600, 0.0675, 0.0734
1.200, 30, 2.4040, None, None, None, None, None
1.600, 40, 1.9089, None, None, None, None, None
2.000, 50, 1.4818, None, None, None, None, None
2.000, 50, None, 1.2143, 0.1229, 0.6711, 0.2077, 0.5127
2.400, 60, 1.0249, None, None, None, None, None
2.800, 70, 0.8383, None, None, None, None, None
3.000, 75, None, 0.7328, 0.1664, 0.7689, 0.2736, 0.6053
3.200, 80, 0.5854, None, None, None, None, None
3.600, 90, 0.4409, None, None, None, None, None
4.000, 100, 0.4467, None, None, None, None, None
4.000, 100, None, 0.6887, 0.2267, 0.6911, 0.3414, 0.7391
4.400, 110, 0.2655, None, None, None, None, None
4.800, 120, 0.3245, None, None, None, None, None
5.000, 125, None, 0.6577, 0.2637, 0.6844, 0.3807, 0.7204
5.200, 130, 0.2623, None, None, None, None, None
5.600, 140, 0.2167, None, None, None, None, None
6.000, 150, 0.1736, None, None, None, None, None
6.000, 150, None, 0.6898, 0.3802, 0.6844, 0.4889, 0.8632
6.400, 160, 0.1442, None, None, None, None, None
6.800, 170, 0.1377, None, None, None, None, None
7.000, 175, None, 0.7228, 0.4337, 0.7200, 0.5414, 0.8806
7.200, 180, 0.1438, None, None, None, None, None
7.600, 190, 0.0871, None, None, None, None, None
8.000, 200, 0.0742, None, None, None, None, None
8.000, 200, None, 0.7857, 0.5007, 0.7422, 0.5980, 0.9018
8.400, 210, 0.0645, None, None, None, None, None
8.800, 220, 0.0948, None, None, None, None, None
9.000, 225, None, 0.7990, 0.4962, 0.7333, 0.5919, 0.9000
9.200, 230, 0.0801, None, None, None, None, None
9.600, 240, 0.0653, None, None, None, None, None
10.000, 250, 0.0789, None, None, None, None, None
10.000, 250, None, 0.8082, 0.5092, 0.7400, 0.6033, 0.9036
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.8082, 0.5092, 0.7400, 0.6033, 0.9036

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.417, 10, 3.2617, None, None, None, None, None
0.833, 20, 2.9183, None, None, None, None, None
1.000, 24, None, 2.5390, 0.0222, 0.2481, 0.0408, 0.0522
1.250, 30, 2.3141, None, None, None, None, None
1.667, 40, 1.9431, None, None, None, None, None
2.000, 48, None, 1.5035, 0.1297, 0.6455, 0.2160, 0.5990
2.083, 50, 1.4339, None, None, None, None, None
2.500, 60, 1.0018, None, None, None, None, None
2.917, 70, 0.7925, None, None, None, None, None
3.000, 72, None, 1.0644, 0.1406, 0.6716, 0.2326, 0.3443
3.333, 80, 0.5865, None, None, None, None, None
3.750, 90, 0.4970, None, None, None, None, None
4.000, 96, None, 0.9997, 0.1733, 0.6306, 0.2719, 0.6476
4.167, 100, 0.4084, None, None, None, None, None
4.583, 110, 0.3768, None, None, None, None, None
5.000, 120, 0.3432, None, None, None, None, None
5.000, 120, None, 0.8603, 0.2599, 0.6138, 0.3651, 0.7786
5.417, 130, 0.2498, None, None, None, None, None
5.833, 140, 0.1910, None, None, None, None, None
6.000, 144, None, 0.8304, 0.2675, 0.6474, 0.3786, 0.7406
6.250, 150, 0.1632, None, None, None, None, None
6.667, 160, 0.1783, None, None, None, None, None
7.000, 168, None, 1.0302, 0.3783, 0.6119, 0.4676, 0.8753
7.083, 170, 0.1539, None, None, None, None, None
7.500, 180, 0.1117, None, None, None, None, None
7.917, 190, 0.0971, None, None, None, None, None
8.000, 192, None, 1.0489, 0.4188, 0.6493, 0.5091, 0.8866
8.333, 200, 0.0844, None, None, None, None, None
8.750, 210, 0.0975, None, None, None, None, None
9.000, 216, None, 1.1028, 0.4478, 0.6399, 0.5269, 0.9003
9.167, 220, 0.0752, None, None, None, None, None
9.583, 230, 0.0763, None, None, None, None, None
10.000, 240, 0.0649, None, None, None, None, None
10.000, 240, None, 1.1483, 0.4506, 0.6381, 0.5282, 0.9012
10.000, 240, None, None, None, None, None, None
10.000, 240, None, 1.1483, 0.4506, 0.6381, 0.5282, 0.9012

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2864, None, None, None, None, None
0.800, 20, 2.8067, None, None, None, None, None
1.000, 25, None, 2.4963, 0.0216, 0.2588, 0.0398, 0.0463
1.200, 30, 2.4438, None, None, None, None, None
1.600, 40, 1.9380, None, None, None, None, None
2.000, 50, 1.5726, None, None, None, None, None
2.000, 50, None, 1.5762, 0.0932, 0.6131, 0.1618, 0.4385
2.400, 60, 1.0830, None, None, None, None, None
2.800, 70, 0.8451, None, None, None, None, None
3.000, 75, None, 1.2982, 0.1373, 0.5704, 0.2214, 0.5377
3.200, 80, 0.6718, None, None, None, None, None
3.600, 90, 0.6184, None, None, None, None, None
4.000, 100, 0.5649, None, None, None, None, None
4.000, 100, None, 1.0940, 0.2103, 0.6658, 0.3197, 0.7001
4.400, 110, 0.3479, None, None, None, None, None
4.800, 120, 0.4024, None, None, None, None, None
5.000, 125, None, 0.9847, 0.2218, 0.6131, 0.3258, 0.7475
5.200, 130, 0.3079, None, None, None, None, None
5.600, 140, 0.2365, None, None, None, None, None
6.000, 150, 0.2486, None, None, None, None, None
6.000, 150, None, 0.9872, 0.2710, 0.6633, 0.3848, 0.7841
6.400, 160, 0.1793, None, None, None, None, None
6.800, 170, 0.1869, None, None, None, None, None
7.000, 175, None, 1.0611, 0.3415, 0.6658, 0.4514, 0.8289
7.200, 180, 0.1597, None, None, None, None, None
7.600, 190, 0.1303, None, None, None, None, None
8.000, 200, 0.1239, None, None, None, None, None
8.000, 200, None, 1.1382, 0.4155, 0.6608, 0.5102, 0.8687
8.400, 210, 0.0834, None, None, None, None, None
8.800, 220, 0.1513, None, None, None, None, None
9.000, 225, None, 1.1542, 0.4044, 0.6533, 0.4995, 0.8717
9.200, 230, 0.0803, None, None, None, None, None
9.600, 240, 0.0706, None, None, None, None, None
10.000, 250, 0.0950, None, None, None, None, None
10.000, 250, None, 1.1785, 0.4241, 0.6533, 0.5143, 0.8770
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1785, 0.4241, 0.6533, 0.5143, 0.8770

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2397, None, None, None, None, None
0.800, 20, 2.8779, None, None, None, None, None
1.000, 25, None, 2.2394, 0.0377, 0.3981, 0.0689, 0.0677
1.200, 30, 2.4155, None, None, None, None, None
1.600, 40, 1.9349, None, None, None, None, None
2.000, 50, 1.4803, None, None, None, None, None
2.000, 50, None, 1.2320, 0.1134, 0.6075, 0.1911, 0.3206
2.400, 60, 1.0347, None, None, None, None, None
2.800, 70, 0.9655, None, None, None, None, None
3.000, 75, None, 0.6269, 0.1554, 0.7271, 0.2560, 0.5171
3.200, 80, 0.6139, None, None, None, None, None
3.600, 90, 0.5102, None, None, None, None, None
4.000, 100, 0.4802, None, None, None, None, None
4.000, 100, None, 0.4690, 0.3583, 0.7607, 0.4871, 0.8381
4.400, 110, 0.3317, None, None, None, None, None
4.800, 120, 0.3179, None, None, None, None, None
5.000, 125, None, 0.4526, 0.2375, 0.7607, 0.3619, 0.6023
5.200, 130, 0.3475, None, None, None, None, None
5.600, 140, 0.2536, None, None, None, None, None
6.000, 150, 0.1754, None, None, None, None, None
6.000, 150, None, 0.3907, 0.4028, 0.7477, 0.5236, 0.8499
6.400, 160, 0.1916, None, None, None, None, None
6.800, 170, 0.1544, None, None, None, None, None
7.000, 175, None, 0.3879, 0.3687, 0.7271, 0.4893, 0.7969
7.200, 180, 0.1271, None, None, None, None, None
7.600, 190, 0.0977, None, None, None, None, None
8.000, 200, 0.1173, None, None, None, None, None
8.000, 200, None, 0.4120, 0.4665, 0.7421, 0.5729, 0.8732
8.400, 210, 0.0979, None, None, None, None, None
8.800, 220, 0.1016, None, None, None, None, None
9.000, 225, None, 0.3974, 0.4455, 0.7178, 0.5497, 0.8645
9.200, 230, 0.0897, None, None, None, None, None
9.600, 240, 0.0677, None, None, None, None, None
10.000, 250, 0.1082, None, None, None, None, None
10.000, 250, None, 0.4162, 0.5193, 0.7533, 0.6148, 0.9007
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.4162, 0.5193, 0.7533, 0.6148, 0.9007

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2200, None, None, None, None, None
0.800, 20, 2.8992, None, None, None, None, None
1.000, 25, None, 2.4104, 0.0314, 0.3913, 0.0581, 0.0809
1.200, 30, 2.3203, None, None, None, None, None
1.600, 40, 1.8651, None, None, None, None, None
2.000, 50, 1.5137, None, None, None, None, None
2.000, 50, None, 1.4877, 0.1029, 0.5630, 0.1740, 0.4543
2.400, 60, 1.0205, None, None, None, None, None
2.800, 70, 0.7394, None, None, None, None, None
3.000, 75, None, 1.0405, 0.1472, 0.6478, 0.2399, 0.4445
3.200, 80, 0.5735, None, None, None, None, None
3.600, 90, 0.4213, None, None, None, None, None
4.000, 100, 0.5045, None, None, None, None, None
4.000, 100, None, 1.0291, 0.2019, 0.6478, 0.3079, 0.7042
4.400, 110, 0.2587, None, None, None, None, None
4.800, 120, 0.3783, None, None, None, None, None
5.000, 125, None, 0.9136, 0.2632, 0.6304, 0.3713, 0.8172
5.200, 130, 0.2389, None, None, None, None, None
5.600, 140, 0.1972, None, None, None, None, None
6.000, 150, 0.2042, None, None, None, None, None
6.000, 150, None, 0.9877, 0.3115, 0.6500, 0.4211, 0.8253
6.400, 160, 0.1707, None, None, None, None, None
6.800, 170, 0.1430, None, None, None, None, None
7.000, 175, None, 1.1207, 0.3508, 0.6391, 0.4530, 0.8551
7.200, 180, 0.1470, None, None, None, None, None
7.600, 190, 0.1421, None, None, None, None, None
8.000, 200, 0.1007, None, None, None, None, None
8.000, 200, None, 1.0519, 0.3912, 0.6565, 0.4903, 0.8762
8.400, 210, 0.0958, None, None, None, None, None
8.800, 220, 0.1083, None, None, None, None, None
9.000, 225, None, 1.1788, 0.4629, 0.6652, 0.5459, 0.8977
9.200, 230, 0.0696, None, None, None, None, None
9.600, 240, 0.0593, None, None, None, None, None
10.000, 250, 0.1083, None, None, None, None, None
10.000, 250, None, 1.1661, 0.4814, 0.6739, 0.5616, 0.9084
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1661, 0.4814, 0.6739, 0.5616, 0.9084

# Starting new run with hyperparams:
{
  "learning_rate": 3e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2209, None, None, None, None, None
0.800, 20, 2.9283, None, None, None, None, None
1.000, 25, None, 2.2131, 0.0364, 0.4600, 0.0674, 0.0733
1.200, 30, 2.4042, None, None, None, None, None
1.600, 40, 1.9144, None, None, None, None, None
2.000, 50, 1.4931, None, None, None, None, None
2.000, 50, None, 1.2340, 0.1210, 0.6667, 0.2048, 0.5049
2.400, 60, 1.0460, None, None, None, None, None
2.800, 70, 0.8531, None, None, None, None, None
3.000, 75, None, 0.7472, 0.1645, 0.7689, 0.2711, 0.6039
3.200, 80, 0.6130, None, None, None, None, None
3.600, 90, 0.4630, None, None, None, None, None
4.000, 100, 0.4531, None, None, None, None, None
4.000, 100, None, 0.6826, 0.2161, 0.7044, 0.3307, 0.7167
4.400, 110, 0.2671, None, None, None, None, None
4.800, 120, 0.3229, None, None, None, None, None
5.000, 125, None, 0.6322, 0.2461, 0.6733, 0.3605, 0.7117
5.200, 130, 0.2754, None, None, None, None, None
5.600, 140, 0.2470, None, None, None, None, None
6.000, 150, 0.2001, None, None, None, None, None
6.000, 150, None, 0.6785, 0.3673, 0.6889, 0.4791, 0.8517
6.400, 160, 0.1679, None, None, None, None, None
6.800, 170, 0.1493, None, None, None, None, None
7.000, 175, None, 0.7321, 0.4625, 0.7400, 0.5692, 0.8904
7.200, 180, 0.1534, None, None, None, None, None
7.600, 190, 0.1011, None, None, None, None, None
8.000, 200, 0.0951, None, None, None, None, None
8.000, 200, None, 0.8050, 0.5230, 0.7578, 0.6189, 0.9057
8.400, 210, 0.0644, None, None, None, None, None
8.800, 220, 0.0978, None, None, None, None, None
9.000, 225, None, 0.8016, 0.4890, 0.7400, 0.5889, 0.8961
9.200, 230, 0.0832, None, None, None, None, None
9.600, 240, 0.0591, None, None, None, None, None
10.000, 250, 0.0767, None, None, None, None, None
10.000, 250, None, 0.8756, 0.5543, 0.7600, 0.6410, 0.9166
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.8756, 0.5543, 0.7600, 0.6410, 0.9166

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.208, 10, 3.3576, None, None, None, None, None
0.417, 20, 3.1316, None, None, None, None, None
0.625, 30, 2.7201, None, None, None, None, None
0.833, 40, 2.7118, None, None, None, None, None
1.000, 48, None, 2.3678, 0.0410, 0.3713, 0.0738, 0.0974
1.042, 50, 2.2647, None, None, None, None, None
1.250, 60, 1.7308, None, None, None, None, None
1.458, 70, 1.5699, None, None, None, None, None
1.667, 80, 1.3873, None, None, None, None, None
1.875, 90, 1.0965, None, None, None, None, None
2.000, 96, None, 1.1771, 0.1678, 0.7052, 0.2711, 0.6244
2.083, 100, 1.0327, None, None, None, None, None
2.292, 110, 0.7988, None, None, None, None, None
2.500, 120, 0.6526, None, None, None, None, None
2.708, 130, 0.5162, None, None, None, None, None
2.917, 140, 0.5093, None, None, None, None, None
3.000, 144, None, 0.9734, 0.2771, 0.6959, 0.3964, 0.8129
3.125, 150, 0.4247, None, None, None, None, None
3.333, 160, 0.4860, None, None, None, None, None
3.542, 170, 0.3237, None, None, None, None, None
3.750, 180, 0.3357, None, None, None, None, None
3.958, 190, 0.4681, None, None, None, None, None
4.000, 192, None, 0.8213, 0.2542, 0.6231, 0.3611, 0.7672
4.167, 200, 0.2384, None, None, None, None, None
4.375, 210, 0.3180, None, None, None, None, None
4.583, 220, 0.1828, None, None, None, None, None
4.792, 230, 0.1848, None, None, None, None, None
5.000, 240, 0.2243, None, None, None, None, None
5.000, 240, None, 0.9650, 0.3737, 0.6511, 0.4748, 0.8749
5.208, 250, 0.1497, None, None, None, None, None
5.417, 260, 0.1170, None, None, None, None, None
5.625, 270, 0.1159, None, None, None, None, None
5.833, 280, 0.0922, None, None, None, None, None
6.000, 288, None, 1.1997, 0.5099, 0.6754, 0.5811, 0.9067
6.042, 290, 0.1008, None, None, None, None, None
6.250, 300, 0.0586, None, None, None, None, None
6.458, 310, 0.1126, None, None, None, None, None
6.667, 320, 0.0821, None, None, None, None, None
6.875, 330, 0.0922, None, None, None, None, None
7.000, 336, None, 1.0658, 0.4485, 0.6343, 0.5255, 0.8892
7.083, 340, 0.0641, None, None, None, None, None
7.292, 350, 0.0737, None, None, None, None, None
7.500, 360, 0.0585, None, None, None, None, None
7.708, 370, 0.0555, None, None, None, None, None
7.917, 380, 0.0321, None, None, None, None, None
8.000, 384, None, 1.1818, 0.5028, 0.6623, 0.5717, 0.9089
8.125, 390, 0.0447, None, None, None, None, None
8.333, 400, 0.0438, None, None, None, None, None
8.542, 410, 0.0487, None, None, None, None, None
8.750, 420, 0.0430, None, None, None, None, None
8.958, 430, 0.0496, None, None, None, None, None
9.000, 432, None, 1.2395, 0.5317, 0.6735, 0.5942, 0.9166
9.167, 440, 0.0320, None, None, None, None, None
9.375, 450, 0.0357, None, None, None, None, None
9.583, 460, 0.0599, None, None, None, None, None
9.792, 470, 0.0218, None, None, None, None, None
10.000, 480, 0.0436, None, None, None, None, None
10.000, 480, None, 1.2428, 0.5353, 0.6791, 0.5987, 0.9176
10.000, 480, None, None, None, None, None, None
10.000, 480, None, 1.2428, 0.5353, 0.6791, 0.5987, 0.9176

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2870, None, None, None, None, None
0.408, 20, 3.2307, None, None, None, None, None
0.612, 30, 2.7948, None, None, None, None, None
0.816, 40, 2.4717, None, None, None, None, None
1.000, 49, None, 2.1857, 0.0428, 0.4397, 0.0781, 0.1566
1.020, 50, 2.2005, None, None, None, None, None
1.224, 60, 1.7743, None, None, None, None, None
1.429, 70, 1.5435, None, None, None, None, None
1.633, 80, 1.4075, None, None, None, None, None
1.837, 90, 1.1309, None, None, None, None, None
2.000, 98, None, 1.1990, 0.1818, 0.6784, 0.2868, 0.7146
2.041, 100, 0.9903, None, None, None, None, None
2.245, 110, 0.6361, None, None, None, None, None
2.449, 120, 0.5681, None, None, None, None, None
2.653, 130, 0.6114, None, None, None, None, None
2.857, 140, 0.5796, None, None, None, None, None
3.000, 147, None, 1.1919, 0.1704, 0.6231, 0.2677, 0.5145
3.061, 150, 0.4384, None, None, None, None, None
3.265, 160, 0.3629, None, None, None, None, None
3.469, 170, 0.3659, None, None, None, None, None
3.673, 180, 0.3224, None, None, None, None, None
3.878, 190, 0.2580, None, None, None, None, None
4.000, 196, None, 1.0482, 0.2312, 0.6709, 0.3439, 0.6065
4.082, 200, 0.3247, None, None, None, None, None
4.286, 210, 0.1592, None, None, None, None, None
4.490, 220, 0.2079, None, None, None, None, None
4.694, 230, 0.2001, None, None, None, None, None
4.898, 240, 0.2712, None, None, None, None, None
5.000, 245, None, 1.0897, 0.2650, 0.5452, 0.3566, 0.8008
5.102, 250, 0.1800, None, None, None, None, None
5.306, 260, 0.1136, None, None, None, None, None
5.510, 270, 0.1278, None, None, None, None, None
5.714, 280, 0.1406, None, None, None, None, None
5.918, 290, 0.1759, None, None, None, None, None
6.000, 294, None, 1.1086, 0.3502, 0.6784, 0.4619, 0.8024
6.122, 300, 0.1541, None, None, None, None, None
6.327, 310, 0.0767, None, None, None, None, None
6.531, 320, 0.0866, None, None, None, None, None
6.735, 330, 0.1108, None, None, None, None, None
6.939, 340, 0.1306, None, None, None, None, None
7.000, 343, None, 1.3737, 0.4718, 0.6508, 0.5470, 0.8980
7.143, 350, 0.0749, None, None, None, None, None
7.347, 360, 0.0793, None, None, None, None, None
7.551, 370, 0.0760, None, None, None, None, None
7.755, 380, 0.1183, None, None, None, None, None
7.959, 390, 0.0191, None, None, None, None, None
8.000, 392, None, 1.4858, 0.5226, 0.6960, 0.5970, 0.9095
8.163, 400, 0.0406, None, None, None, None, None
8.367, 410, 0.0503, None, None, None, None, None
8.571, 420, 0.0643, None, None, None, None, None
8.776, 430, 0.0721, None, None, None, None, None
8.980, 440, 0.0494, None, None, None, None, None
9.000, 441, None, 1.4756, 0.5139, 0.6960, 0.5912, 0.9008
9.184, 450, 0.0888, None, None, None, None, None
9.388, 460, 0.0246, None, None, None, None, None
9.592, 470, 0.0211, None, None, None, None, None
9.796, 480, 0.0428, None, None, None, None, None
10.000, 490, 0.0696, None, None, None, None, None
10.000, 490, None, 1.5037, 0.5296, 0.6960, 0.6015, 0.9102
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.5037, 0.5296, 0.6960, 0.6015, 0.9102

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3242, None, None, None, None, None
0.408, 20, 3.1309, None, None, None, None, None
0.612, 30, 2.7688, None, None, None, None, None
0.816, 40, 2.7049, None, None, None, None, None
1.000, 49, None, 1.9304, 0.0705, 0.5234, 0.1242, 0.1478
1.020, 50, 2.3554, None, None, None, None, None
1.224, 60, 1.8392, None, None, None, None, None
1.429, 70, 1.5890, None, None, None, None, None
1.633, 80, 1.4386, None, None, None, None, None
1.837, 90, 1.0942, None, None, None, None, None
2.000, 98, None, 1.0055, 0.1354, 0.6393, 0.2235, 0.1431
2.041, 100, 1.3155, None, None, None, None, None
2.245, 110, 0.7815, None, None, None, None, None
2.449, 120, 0.7045, None, None, None, None, None
2.653, 130, 0.6820, None, None, None, None, None
2.857, 140, 0.7315, None, None, None, None, None
3.000, 147, None, 0.5530, 0.2299, 0.7009, 0.3463, 0.6952
3.061, 150, 0.4404, None, None, None, None, None
3.265, 160, 0.4627, None, None, None, None, None
3.469, 170, 0.3879, None, None, None, None, None
3.673, 180, 0.3807, None, None, None, None, None
3.878, 190, 0.2778, None, None, None, None, None
4.000, 196, None, 0.4077, 0.1975, 0.6318, 0.3010, 0.6590
4.082, 200, 0.3607, None, None, None, None, None
4.286, 210, 0.2270, None, None, None, None, None
4.490, 220, 0.2513, None, None, None, None, None
4.694, 230, 0.1834, None, None, None, None, None
4.898, 240, 0.3543, None, None, None, None, None
5.000, 245, None, 0.4460, 0.2639, 0.6636, 0.3777, 0.6523
5.102, 250, 0.2992, None, None, None, None, None
5.306, 260, 0.1811, None, None, None, None, None
5.510, 270, 0.2083, None, None, None, None, None
5.714, 280, 0.2016, None, None, None, None, None
5.918, 290, 0.1223, None, None, None, None, None
6.000, 294, None, 0.4418, 0.4798, 0.7327, 0.5799, 0.8828
6.122, 300, 0.1040, None, None, None, None, None
6.327, 310, 0.1252, None, None, None, None, None
6.531, 320, 0.1607, None, None, None, None, None
6.735, 330, 0.1148, None, None, None, None, None
6.939, 340, 0.0600, None, None, None, None, None
7.000, 343, None, 0.5237, 0.5487, 0.7682, 0.6402, 0.9036
7.143, 350, 0.1077, None, None, None, None, None
7.347, 360, 0.0739, None, None, None, None, None
7.551, 370, 0.0567, None, None, None, None, None
7.755, 380, 0.0963, None, None, None, None, None
7.959, 390, 0.0288, None, None, None, None, None
8.000, 392, None, 0.5229, 0.5274, 0.7383, 0.6153, 0.9043
8.163, 400, 0.0870, None, None, None, None, None
8.367, 410, 0.0618, None, None, None, None, None
8.571, 420, 0.0595, None, None, None, None, None
8.776, 430, 0.1085, None, None, None, None, None
8.980, 440, 0.0730, None, None, None, None, None
9.000, 441, None, 0.5549, 0.5661, 0.7607, 0.6491, 0.9126
9.184, 450, 0.1002, None, None, None, None, None
9.388, 460, 0.0320, None, None, None, None, None
9.592, 470, 0.0286, None, None, None, None, None
9.796, 480, 0.0308, None, None, None, None, None
10.000, 490, 0.1030, None, None, None, None, None
10.000, 490, None, 0.5622, 0.5688, 0.7570, 0.6496, 0.9151
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 0.5622, 0.5688, 0.7570, 0.6496, 0.9151

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2728, None, None, None, None, None
0.408, 20, 3.0710, None, None, None, None, None
0.612, 30, 2.9176, None, None, None, None, None
0.816, 40, 2.5614, None, None, None, None, None
1.000, 49, None, 2.1547, 0.0480, 0.3543, 0.0845, 0.3962
1.020, 50, 2.2634, None, None, None, None, None
1.224, 60, 1.7294, None, None, None, None, None
1.429, 70, 1.6342, None, None, None, None, None
1.633, 80, 1.1587, None, None, None, None, None
1.837, 90, 1.4128, None, None, None, None, None
2.000, 98, None, 1.1914, 0.1503, 0.5739, 0.2382, 0.6518
2.041, 100, 0.8569, None, None, None, None, None
2.245, 110, 0.6956, None, None, None, None, None
2.449, 120, 0.5973, None, None, None, None, None
2.653, 130, 0.4256, None, None, None, None, None
2.857, 140, 0.5381, None, None, None, None, None
3.000, 147, None, 1.0775, 0.2538, 0.6152, 0.3594, 0.7072
3.061, 150, 0.4985, None, None, None, None, None
3.265, 160, 0.3244, None, None, None, None, None
3.469, 170, 0.2817, None, None, None, None, None
3.673, 180, 0.2393, None, None, None, None, None
3.878, 190, 0.3783, None, None, None, None, None
4.000, 196, None, 0.9293, 0.2924, 0.6478, 0.4030, 0.8494
4.082, 200, 0.3500, None, None, None, None, None
4.286, 210, 0.1359, None, None, None, None, None
4.490, 220, 0.2027, None, None, None, None, None
4.694, 230, 0.2168, None, None, None, None, None
4.898, 240, 0.2027, None, None, None, None, None
5.000, 245, None, 1.2270, 0.2926, 0.5826, 0.3895, 0.8242
5.102, 250, 0.1635, None, None, None, None, None
5.306, 260, 0.1218, None, None, None, None, None
5.510, 270, 0.1315, None, None, None, None, None
5.714, 280, 0.1748, None, None, None, None, None
5.918, 290, 0.1115, None, None, None, None, None
6.000, 294, None, 1.3643, 0.4419, 0.6370, 0.5218, 0.8796
6.122, 300, 0.0942, None, None, None, None, None
6.327, 310, 0.0370, None, None, None, None, None
6.531, 320, 0.0933, None, None, None, None, None
6.735, 330, 0.1193, None, None, None, None, None
6.939, 340, 0.1086, None, None, None, None, None
7.000, 343, None, 1.3702, 0.4421, 0.6391, 0.5227, 0.8994
7.143, 350, 0.0762, None, None, None, None, None
7.347, 360, 0.0662, None, None, None, None, None
7.551, 370, 0.0868, None, None, None, None, None
7.755, 380, 0.0838, None, None, None, None, None
7.959, 390, 0.0255, None, None, None, None, None
8.000, 392, None, 1.3431, 0.5627, 0.6826, 0.6169, 0.9403
8.163, 400, 0.0416, None, None, None, None, None
8.367, 410, 0.0715, None, None, None, None, None
8.571, 420, 0.0331, None, None, None, None, None
8.776, 430, 0.0874, None, None, None, None, None
8.980, 440, 0.0196, None, None, None, None, None
9.000, 441, None, 1.3635, 0.5445, 0.6913, 0.6092, 0.9314
9.184, 450, 0.0368, None, None, None, None, None
9.388, 460, 0.0268, None, None, None, None, None
9.592, 470, 0.0427, None, None, None, None, None
9.796, 480, 0.0351, None, None, None, None, None
10.000, 490, 0.0834, None, None, None, None, None
10.000, 490, None, 1.3952, 0.5767, 0.7109, 0.6368, 0.9409
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.3952, 0.5767, 0.7109, 0.6368, 0.9409

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3034, None, None, None, None, None
0.408, 20, 3.0937, None, None, None, None, None
0.612, 30, 2.9349, None, None, None, None, None
0.816, 40, 2.6327, None, None, None, None, None
1.000, 49, None, 2.0129, 0.0558, 0.5178, 0.1007, 0.2250
1.020, 50, 2.4058, None, None, None, None, None
1.224, 60, 1.9065, None, None, None, None, None
1.429, 70, 1.4062, None, None, None, None, None
1.633, 80, 1.3479, None, None, None, None, None
1.837, 90, 1.1309, None, None, None, None, None
2.000, 98, None, 1.0345, 0.1762, 0.6467, 0.2769, 0.7026
2.041, 100, 1.2468, None, None, None, None, None
2.245, 110, 0.7140, None, None, None, None, None
2.449, 120, 0.6026, None, None, None, None, None
2.653, 130, 0.7144, None, None, None, None, None
2.857, 140, 0.6922, None, None, None, None, None
3.000, 147, None, 0.7056, 0.2705, 0.7622, 0.3993, 0.7454
3.061, 150, 0.4796, None, None, None, None, None
3.265, 160, 0.4124, None, None, None, None, None
3.469, 170, 0.3789, None, None, None, None, None
3.673, 180, 0.3341, None, None, None, None, None
3.878, 190, 0.2978, None, None, None, None, None
4.000, 196, None, 0.7373, 0.2214, 0.6333, 0.3282, 0.6984
4.082, 200, 0.3118, None, None, None, None, None
4.286, 210, 0.1604, None, None, None, None, None
4.490, 220, 0.2766, None, None, None, None, None
4.694, 230, 0.1609, None, None, None, None, None
4.898, 240, 0.2771, None, None, None, None, None
5.000, 245, None, 0.7100, 0.3228, 0.6800, 0.4378, 0.8215
5.102, 250, 0.1775, None, None, None, None, None
5.306, 260, 0.1032, None, None, None, None, None
5.510, 270, 0.1358, None, None, None, None, None
5.714, 280, 0.2861, None, None, None, None, None
5.918, 290, 0.0846, None, None, None, None, None
6.000, 294, None, 0.9144, 0.5346, 0.7378, 0.6200, 0.9141
6.122, 300, 0.0922, None, None, None, None, None
6.327, 310, 0.0604, None, None, None, None, None
6.531, 320, 0.1189, None, None, None, None, None
6.735, 330, 0.1136, None, None, None, None, None
6.939, 340, 0.0894, None, None, None, None, None
7.000, 343, None, 0.9088, 0.5465, 0.7578, 0.6350, 0.9130
7.143, 350, 0.0956, None, None, None, None, None
7.347, 360, 0.0811, None, None, None, None, None
7.551, 370, 0.0566, None, None, None, None, None
7.755, 380, 0.0672, None, None, None, None, None
7.959, 390, 0.0322, None, None, None, None, None
8.000, 392, None, 0.9953, 0.5911, 0.7711, 0.6692, 0.9272
8.163, 400, 0.0343, None, None, None, None, None
8.367, 410, 0.0415, None, None, None, None, None
8.571, 420, 0.0541, None, None, None, None, None
8.776, 430, 0.0846, None, None, None, None, None
8.980, 440, 0.0436, None, None, None, None, None
9.000, 441, None, 0.9981, 0.5945, 0.7756, 0.6731, 0.9258
9.184, 450, 0.0596, None, None, None, None, None
9.388, 460, 0.0480, None, None, None, None, None
9.592, 470, 0.0216, None, None, None, None, None
9.796, 480, 0.0314, None, None, None, None, None
10.000, 490, 0.0706, None, None, None, None, None
10.000, 490, None, 1.0050, 0.5925, 0.7756, 0.6718, 0.9272
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.0050, 0.5925, 0.7756, 0.6718, 0.9272

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.208, 10, 3.3576, None, None, None, None, None
0.417, 20, 3.1317, None, None, None, None, None
0.625, 30, 2.7201, None, None, None, None, None
0.833, 40, 2.7117, None, None, None, None, None
1.000, 48, None, 2.3678, 0.0410, 0.3713, 0.0739, 0.0979
1.042, 50, 2.2645, None, None, None, None, None
1.250, 60, 1.7315, None, None, None, None, None
1.458, 70, 1.5697, None, None, None, None, None
1.667, 80, 1.3886, None, None, None, None, None
1.875, 90, 1.0963, None, None, None, None, None
2.000, 96, None, 1.1788, 0.1687, 0.7034, 0.2721, 0.6343
2.083, 100, 1.0299, None, None, None, None, None
2.292, 110, 0.7664, None, None, None, None, None
2.500, 120, 0.6426, None, None, None, None, None
2.708, 130, 0.5181, None, None, None, None, None
2.917, 140, 0.4988, None, None, None, None, None
3.000, 144, None, 0.9406, 0.2783, 0.7201, 0.4015, 0.8032
3.125, 150, 0.4177, None, None, None, None, None
3.333, 160, 0.4845, None, None, None, None, None
3.542, 170, 0.3288, None, None, None, None, None
3.750, 180, 0.3049, None, None, None, None, None
3.958, 190, 0.4189, None, None, None, None, None
4.000, 192, None, 0.7810, 0.2560, 0.6586, 0.3687, 0.7634
4.167, 200, 0.2465, None, None, None, None, None
4.375, 210, 0.3214, None, None, None, None, None
4.583, 220, 0.1886, None, None, None, None, None
4.792, 230, 0.2049, None, None, None, None, None
5.000, 240, 0.2454, None, None, None, None, None
5.000, 240, None, 0.9768, 0.3400, 0.6325, 0.4423, 0.8673
5.208, 250, 0.1627, None, None, None, None, None
5.417, 260, 0.1406, None, None, None, None, None
5.625, 270, 0.1429, None, None, None, None, None
5.833, 280, 0.0923, None, None, None, None, None
6.000, 288, None, 1.2371, 0.5699, 0.6996, 0.6281, 0.9245
6.042, 290, 0.1121, None, None, None, None, None
6.250, 300, 0.0661, None, None, None, None, None
6.458, 310, 0.1221, None, None, None, None, None
6.667, 320, 0.1111, None, None, None, None, None
6.875, 330, 0.1113, None, None, None, None, None
7.000, 336, None, 1.1710, 0.4094, 0.5989, 0.4864, 0.8822
7.083, 340, 0.0844, None, None, None, None, None
7.292, 350, 0.1017, None, None, None, None, None
7.500, 360, 0.0692, None, None, None, None, None
7.708, 370, 0.0641, None, None, None, None, None
7.917, 380, 0.0410, None, None, None, None, None
8.000, 384, None, 1.1737, 0.4979, 0.6791, 0.5746, 0.9006
8.125, 390, 0.0503, None, None, None, None, None
8.333, 400, 0.0471, None, None, None, None, None
8.542, 410, 0.0458, None, None, None, None, None
8.750, 420, 0.0568, None, None, None, None, None
8.958, 430, 0.0540, None, None, None, None, None
9.000, 432, None, 1.2971, 0.5249, 0.6698, 0.5885, 0.9165
9.167, 440, 0.0306, None, None, None, None, None
9.375, 450, 0.0306, None, None, None, None, None
9.583, 460, 0.0575, None, None, None, None, None
9.792, 470, 0.0219, None, None, None, None, None
10.000, 480, 0.0426, None, None, None, None, None
10.000, 480, None, 1.3488, 0.5444, 0.6866, 0.6073, 0.9188
10.000, 480, None, None, None, None, None, None
10.000, 480, None, 1.3488, 0.5444, 0.6866, 0.6073, 0.9188

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2870, None, None, None, None, None
0.408, 20, 3.2308, None, None, None, None, None
0.612, 30, 2.7948, None, None, None, None, None
0.816, 40, 2.4717, None, None, None, None, None
1.000, 49, None, 2.1858, 0.0429, 0.4397, 0.0781, 0.1566
1.020, 50, 2.2006, None, None, None, None, None
1.224, 60, 1.7751, None, None, None, None, None
1.429, 70, 1.5444, None, None, None, None, None
1.633, 80, 1.4065, None, None, None, None, None
1.837, 90, 1.1291, None, None, None, None, None
2.000, 98, None, 1.2049, 0.1887, 0.6859, 0.2959, 0.7230
2.041, 100, 0.9958, None, None, None, None, None
2.245, 110, 0.6301, None, None, None, None, None
2.449, 120, 0.5720, None, None, None, None, None
2.653, 130, 0.6202, None, None, None, None, None
2.857, 140, 0.5801, None, None, None, None, None
3.000, 147, None, 1.1413, 0.1691, 0.6206, 0.2657, 0.5432
3.061, 150, 0.4422, None, None, None, None, None
3.265, 160, 0.3795, None, None, None, None, None
3.469, 170, 0.4066, None, None, None, None, None
3.673, 180, 0.3517, None, None, None, None, None
3.878, 190, 0.2773, None, None, None, None, None
4.000, 196, None, 1.0517, 0.2415, 0.6960, 0.3586, 0.6375
4.082, 200, 0.3372, None, None, None, None, None
4.286, 210, 0.1629, None, None, None, None, None
4.490, 220, 0.2530, None, None, None, None, None
4.694, 230, 0.1815, None, None, None, None, None
4.898, 240, 0.2532, None, None, None, None, None
5.000, 245, None, 1.0491, 0.2831, 0.5804, 0.3806, 0.7788
5.102, 250, 0.1941, None, None, None, None, None
5.306, 260, 0.1988, None, None, None, None, None
5.510, 270, 0.1243, None, None, None, None, None
5.714, 280, 0.1247, None, None, None, None, None
5.918, 290, 0.1481, None, None, None, None, None
6.000, 294, None, 1.1324, 0.3503, 0.6910, 0.4649, 0.8229
6.122, 300, 0.1705, None, None, None, None, None
6.327, 310, 0.0744, None, None, None, None, None
6.531, 320, 0.0929, None, None, None, None, None
6.735, 330, 0.1087, None, None, None, None, None
6.939, 340, 0.1569, None, None, None, None, None
7.000, 343, None, 1.3781, 0.4699, 0.6658, 0.5509, 0.8993
7.143, 350, 0.0796, None, None, None, None, None
7.347, 360, 0.0890, None, None, None, None, None
7.551, 370, 0.0977, None, None, None, None, None
7.755, 380, 0.1286, None, None, None, None, None
7.959, 390, 0.0202, None, None, None, None, None
8.000, 392, None, 1.5686, 0.5653, 0.6960, 0.6239, 0.9260
8.163, 400, 0.0414, None, None, None, None, None
8.367, 410, 0.0510, None, None, None, None, None
8.571, 420, 0.0772, None, None, None, None, None
8.776, 430, 0.0864, None, None, None, None, None
8.980, 440, 0.0587, None, None, None, None, None
9.000, 441, None, 1.4766, 0.5349, 0.6935, 0.6039, 0.9087
9.184, 450, 0.0990, None, None, None, None, None
9.388, 460, 0.0213, None, None, None, None, None
9.592, 470, 0.0227, None, None, None, None, None
9.796, 480, 0.0407, None, None, None, None, None
10.000, 490, 0.0615, None, None, None, None, None
10.000, 490, None, 1.5259, 0.5665, 0.7060, 0.6286, 0.9158
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.5259, 0.5665, 0.7060, 0.6286, 0.9158

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3243, None, None, None, None, None
0.408, 20, 3.1308, None, None, None, None, None
0.612, 30, 2.7688, None, None, None, None, None
0.816, 40, 2.7049, None, None, None, None, None
1.000, 49, None, 1.9304, 0.0705, 0.5234, 0.1242, 0.1478
1.020, 50, 2.3554, None, None, None, None, None
1.224, 60, 1.8398, None, None, None, None, None
1.429, 70, 1.5921, None, None, None, None, None
1.633, 80, 1.4275, None, None, None, None, None
1.837, 90, 1.0974, None, None, None, None, None
2.000, 98, None, 0.9937, 0.1340, 0.6393, 0.2216, 0.1473
2.041, 100, 1.3052, None, None, None, None, None
2.245, 110, 0.7792, None, None, None, None, None
2.449, 120, 0.7055, None, None, None, None, None
2.653, 130, 0.6721, None, None, None, None, None
2.857, 140, 0.7335, None, None, None, None, None
3.000, 147, None, 0.5449, 0.2345, 0.7215, 0.3540, 0.7026
3.061, 150, 0.4402, None, None, None, None, None
3.265, 160, 0.4418, None, None, None, None, None
3.469, 170, 0.3956, None, None, None, None, None
3.673, 180, 0.3878, None, None, None, None, None
3.878, 190, 0.3050, None, None, None, None, None
4.000, 196, None, 0.4201, 0.2264, 0.6636, 0.3376, 0.7050
4.082, 200, 0.3603, None, None, None, None, None
4.286, 210, 0.2250, None, None, None, None, None
4.490, 220, 0.2870, None, None, None, None, None
4.694, 230, 0.1885, None, None, None, None, None
4.898, 240, 0.3573, None, None, None, None, None
5.000, 245, None, 0.4449, 0.2656, 0.6673, 0.3800, 0.6473
5.102, 250, 0.3251, None, None, None, None, None
5.306, 260, 0.1729, None, None, None, None, None
5.510, 270, 0.2241, None, None, None, None, None
5.714, 280, 0.1967, None, None, None, None, None
5.918, 290, 0.1227, None, None, None, None, None
6.000, 294, None, 0.4328, 0.4503, 0.7028, 0.5489, 0.8798
6.122, 300, 0.1074, None, None, None, None, None
6.327, 310, 0.1310, None, None, None, None, None
6.531, 320, 0.1486, None, None, None, None, None
6.735, 330, 0.1199, None, None, None, None, None
6.939, 340, 0.0641, None, None, None, None, None
7.000, 343, None, 0.5023, 0.5441, 0.7720, 0.6383, 0.9016
7.143, 350, 0.1483, None, None, None, None, None
7.347, 360, 0.0797, None, None, None, None, None
7.551, 370, 0.0630, None, None, None, None, None
7.755, 380, 0.0961, None, None, None, None, None
7.959, 390, 0.0331, None, None, None, None, None
8.000, 392, None, 0.5086, 0.5347, 0.7495, 0.6241, 0.9027
8.163, 400, 0.0723, None, None, None, None, None
8.367, 410, 0.0660, None, None, None, None, None
8.571, 420, 0.0823, None, None, None, None, None
8.776, 430, 0.0973, None, None, None, None, None
8.980, 440, 0.0708, None, None, None, None, None
9.000, 441, None, 0.5414, 0.5479, 0.7383, 0.6290, 0.9101
9.184, 450, 0.0929, None, None, None, None, None
9.388, 460, 0.0332, None, None, None, None, None
9.592, 470, 0.0210, None, None, None, None, None
9.796, 480, 0.0337, None, None, None, None, None
10.000, 490, 0.1010, None, None, None, None, None
10.000, 490, None, 0.5958, 0.6257, 0.7813, 0.6949, 0.9260
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 0.5958, 0.6257, 0.7813, 0.6949, 0.9260

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2728, None, None, None, None, None
0.408, 20, 3.0710, None, None, None, None, None
0.612, 30, 2.9176, None, None, None, None, None
0.816, 40, 2.5615, None, None, None, None, None
1.000, 49, None, 2.1547, 0.0479, 0.3543, 0.0845, 0.3961
1.020, 50, 2.2635, None, None, None, None, None
1.224, 60, 1.7303, None, None, None, None, None
1.429, 70, 1.6350, None, None, None, None, None
1.633, 80, 1.1656, None, None, None, None, None
1.837, 90, 1.4035, None, None, None, None, None
2.000, 98, None, 1.2005, 0.1501, 0.5761, 0.2381, 0.6397
2.041, 100, 0.8625, None, None, None, None, None
2.245, 110, 0.7073, None, None, None, None, None
2.449, 120, 0.5991, None, None, None, None, None
2.653, 130, 0.4288, None, None, None, None, None
2.857, 140, 0.5186, None, None, None, None, None
3.000, 147, None, 1.0634, 0.2534, 0.6109, 0.3582, 0.7093
3.061, 150, 0.4907, None, None, None, None, None
3.265, 160, 0.3285, None, None, None, None, None
3.469, 170, 0.2889, None, None, None, None, None
3.673, 180, 0.2273, None, None, None, None, None
3.878, 190, 0.3647, None, None, None, None, None
4.000, 196, None, 0.9376, 0.2998, 0.6543, 0.4112, 0.8494
4.082, 200, 0.3620, None, None, None, None, None
4.286, 210, 0.1428, None, None, None, None, None
4.490, 220, 0.2118, None, None, None, None, None
4.694, 230, 0.2210, None, None, None, None, None
4.898, 240, 0.1927, None, None, None, None, None
5.000, 245, None, 1.2093, 0.2992, 0.5652, 0.3913, 0.8288
5.102, 250, 0.1588, None, None, None, None, None
5.306, 260, 0.1223, None, None, None, None, None
5.510, 270, 0.1426, None, None, None, None, None
5.714, 280, 0.1853, None, None, None, None, None
5.918, 290, 0.1291, None, None, None, None, None
6.000, 294, None, 1.4044, 0.4383, 0.6565, 0.5257, 0.8844
6.122, 300, 0.1010, None, None, None, None, None
6.327, 310, 0.0525, None, None, None, None, None
6.531, 320, 0.0916, None, None, None, None, None
6.735, 330, 0.1315, None, None, None, None, None
6.939, 340, 0.1091, None, None, None, None, None
7.000, 343, None, 1.4090, 0.4014, 0.6196, 0.4872, 0.8811
7.143, 350, 0.0806, None, None, None, None, None
7.347, 360, 0.0829, None, None, None, None, None
7.551, 370, 0.0851, None, None, None, None, None
7.755, 380, 0.0808, None, None, None, None, None
7.959, 390, 0.0280, None, None, None, None, None
8.000, 392, None, 1.4647, 0.4911, 0.6630, 0.5643, 0.8963
8.163, 400, 0.0448, None, None, None, None, None
8.367, 410, 0.0685, None, None, None, None, None
8.571, 420, 0.0346, None, None, None, None, None
8.776, 430, 0.1807, None, None, None, None, None
8.980, 440, 0.0227, None, None, None, None, None
9.000, 441, None, 1.3945, 0.5298, 0.6761, 0.5941, 0.9331
9.184, 450, 0.0341, None, None, None, None, None
9.388, 460, 0.0256, None, None, None, None, None
9.592, 470, 0.0487, None, None, None, None, None
9.796, 480, 0.0375, None, None, None, None, None
10.000, 490, 0.0816, None, None, None, None, None
10.000, 490, None, 1.4553, 0.5407, 0.6783, 0.6017, 0.9382
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.4553, 0.5407, 0.6783, 0.6017, 0.9382

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3034, None, None, None, None, None
0.408, 20, 3.0937, None, None, None, None, None
0.612, 30, 2.9349, None, None, None, None, None
0.816, 40, 2.6328, None, None, None, None, None
1.000, 49, None, 2.0130, 0.0557, 0.5178, 0.1006, 0.2250
1.020, 50, 2.4059, None, None, None, None, None
1.224, 60, 1.9073, None, None, None, None, None
1.429, 70, 1.4097, None, None, None, None, None
1.633, 80, 1.3475, None, None, None, None, None
1.837, 90, 1.1354, None, None, None, None, None
2.000, 98, None, 1.0137, 0.1716, 0.6511, 0.2717, 0.6894
2.041, 100, 1.2430, None, None, None, None, None
2.245, 110, 0.7074, None, None, None, None, None
2.449, 120, 0.6168, None, None, None, None, None
2.653, 130, 0.7190, None, None, None, None, None
2.857, 140, 0.7000, None, None, None, None, None
3.000, 147, None, 0.6997, 0.2567, 0.7667, 0.3846, 0.7215
3.061, 150, 0.4681, None, None, None, None, None
3.265, 160, 0.3922, None, None, None, None, None
3.469, 170, 0.3823, None, None, None, None, None
3.673, 180, 0.3491, None, None, None, None, None
3.878, 190, 0.3005, None, None, None, None, None
4.000, 196, None, 0.7272, 0.2500, 0.6556, 0.3620, 0.7508
4.082, 200, 0.3178, None, None, None, None, None
4.286, 210, 0.1532, None, None, None, None, None
4.490, 220, 0.2597, None, None, None, None, None
4.694, 230, 0.1775, None, None, None, None, None
4.898, 240, 0.3039, None, None, None, None, None
5.000, 245, None, 0.6971, 0.3369, 0.6978, 0.4544, 0.8243
5.102, 250, 0.1817, None, None, None, None, None
5.306, 260, 0.0993, None, None, None, None, None
5.510, 270, 0.1742, None, None, None, None, None
5.714, 280, 0.2774, None, None, None, None, None
5.918, 290, 0.0902, None, None, None, None, None
6.000, 294, None, 0.8777, 0.5629, 0.7556, 0.6452, 0.9234
6.122, 300, 0.0859, None, None, None, None, None
6.327, 310, 0.0656, None, None, None, None, None
6.531, 320, 0.1316, None, None, None, None, None
6.735, 330, 0.1066, None, None, None, None, None
6.939, 340, 0.0947, None, None, None, None, None
7.000, 343, None, 0.8982, 0.5377, 0.7600, 0.6298, 0.9100
7.143, 350, 0.1069, None, None, None, None, None
7.347, 360, 0.0844, None, None, None, None, None
7.551, 370, 0.0601, None, None, None, None, None
7.755, 380, 0.0674, None, None, None, None, None
7.959, 390, 0.0321, None, None, None, None, None
8.000, 392, None, 1.0601, 0.6007, 0.7822, 0.6795, 0.9323
8.163, 400, 0.0383, None, None, None, None, None
8.367, 410, 0.0370, None, None, None, None, None
8.571, 420, 0.0668, None, None, None, None, None
8.776, 430, 0.1046, None, None, None, None, None
8.980, 440, 0.0487, None, None, None, None, None
9.000, 441, None, 1.0416, 0.5942, 0.7711, 0.6712, 0.9283
9.184, 450, 0.0553, None, None, None, None, None
9.388, 460, 0.0396, None, None, None, None, None
9.592, 470, 0.0297, None, None, None, None, None
9.796, 480, 0.0365, None, None, None, None, None
10.000, 490, 0.0686, None, None, None, None, None
10.000, 490, None, 1.0872, 0.6193, 0.7844, 0.6922, 0.9325
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.0872, 0.6193, 0.7844, 0.6922, 0.9325

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.208, 10, 3.3576, None, None, None, None, None
0.417, 20, 3.1316, None, None, None, None, None
0.625, 30, 2.7201, None, None, None, None, None
0.833, 40, 2.7117, None, None, None, None, None
1.000, 48, None, 2.3679, 0.0410, 0.3713, 0.0739, 0.0978
1.042, 50, 2.2647, None, None, None, None, None
1.250, 60, 1.7308, None, None, None, None, None
1.458, 70, 1.5699, None, None, None, None, None
1.667, 80, 1.3872, None, None, None, None, None
1.875, 90, 1.0965, None, None, None, None, None
2.000, 96, None, 1.1769, 0.1677, 0.7052, 0.2710, 0.6244
2.083, 100, 1.0326, None, None, None, None, None
2.292, 110, 0.7985, None, None, None, None, None
2.500, 120, 0.6529, None, None, None, None, None
2.708, 130, 0.5160, None, None, None, None, None
2.917, 140, 0.5094, None, None, None, None, None
3.000, 144, None, 0.9731, 0.2773, 0.6959, 0.3966, 0.8133
3.125, 150, 0.4251, None, None, None, None, None
3.333, 160, 0.4862, None, None, None, None, None
3.542, 170, 0.3239, None, None, None, None, None
3.750, 180, 0.3351, None, None, None, None, None
3.958, 190, 0.4684, None, None, None, None, None
4.000, 192, None, 0.8215, 0.2544, 0.6231, 0.3613, 0.7671
4.167, 200, 0.2381, None, None, None, None, None
4.375, 210, 0.3181, None, None, None, None, None
4.583, 220, 0.1829, None, None, None, None, None
4.792, 230, 0.1847, None, None, None, None, None
5.000, 240, 0.2242, None, None, None, None, None
5.000, 240, None, 0.9659, 0.3707, 0.6474, 0.4715, 0.8742
5.208, 250, 0.1509, None, None, None, None, None
5.417, 260, 0.1166, None, None, None, None, None
5.625, 270, 0.1169, None, None, None, None, None
5.833, 280, 0.0922, None, None, None, None, None
6.000, 288, None, 1.1881, 0.5214, 0.6810, 0.5906, 0.9089
6.042, 290, 0.1007, None, None, None, None, None
6.250, 300, 0.0592, None, None, None, None, None
6.458, 310, 0.1108, None, None, None, None, None
6.667, 320, 0.0812, None, None, None, None, None
6.875, 330, 0.0889, None, None, None, None, None
7.000, 336, None, 1.0825, 0.4409, 0.6269, 0.5177, 0.8901
7.083, 340, 0.0601, None, None, None, None, None
7.292, 350, 0.0728, None, None, None, None, None
7.500, 360, 0.0593, None, None, None, None, None
7.708, 370, 0.0571, None, None, None, None, None
7.917, 380, 0.0317, None, None, None, None, None
8.000, 384, None, 1.1658, 0.5114, 0.6679, 0.5793, 0.9118
8.125, 390, 0.0454, None, None, None, None, None
8.333, 400, 0.0434, None, None, None, None, None
8.542, 410, 0.0472, None, None, None, None, None
8.750, 420, 0.0468, None, None, None, None, None
8.958, 430, 0.0492, None, None, None, None, None
9.000, 432, None, 1.2345, 0.5302, 0.6716, 0.5926, 0.9169
9.167, 440, 0.0313, None, None, None, None, None
9.375, 450, 0.0361, None, None, None, None, None
9.583, 460, 0.0600, None, None, None, None, None
9.792, 470, 0.0222, None, None, None, None, None
10.000, 480, 0.0433, None, None, None, None, None
10.000, 480, None, 1.2382, 0.5390, 0.6828, 0.6025, 0.9181
10.000, 480, None, None, None, None, None, None
10.000, 480, None, 1.2382, 0.5390, 0.6828, 0.6025, 0.9181

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2870, None, None, None, None, None
0.408, 20, 3.2307, None, None, None, None, None
0.612, 30, 2.7949, None, None, None, None, None
0.816, 40, 2.4717, None, None, None, None, None
1.000, 49, None, 2.1858, 0.0429, 0.4397, 0.0781, 0.1567
1.020, 50, 2.2007, None, None, None, None, None
1.224, 60, 1.7743, None, None, None, None, None
1.429, 70, 1.5439, None, None, None, None, None
1.633, 80, 1.4074, None, None, None, None, None
1.837, 90, 1.1310, None, None, None, None, None
2.000, 98, None, 1.1992, 0.1822, 0.6784, 0.2872, 0.7155
2.041, 100, 0.9902, None, None, None, None, None
2.245, 110, 0.6392, None, None, None, None, None
2.449, 120, 0.5686, None, None, None, None, None
2.653, 130, 0.6110, None, None, None, None, None
2.857, 140, 0.5798, None, None, None, None, None
3.000, 147, None, 1.1905, 0.1709, 0.6231, 0.2683, 0.5132
3.061, 150, 0.4390, None, None, None, None, None
3.265, 160, 0.3631, None, None, None, None, None
3.469, 170, 0.3737, None, None, None, None, None
3.673, 180, 0.3248, None, None, None, None, None
3.878, 190, 0.2619, None, None, None, None, None
4.000, 196, None, 1.0527, 0.2400, 0.6784, 0.3546, 0.6241
4.082, 200, 0.3274, None, None, None, None, None
4.286, 210, 0.1634, None, None, None, None, None
4.490, 220, 0.2047, None, None, None, None, None
4.694, 230, 0.1851, None, None, None, None, None
4.898, 240, 0.2636, None, None, None, None, None
5.000, 245, None, 1.1009, 0.2748, 0.5704, 0.3709, 0.7796
5.102, 250, 0.2039, None, None, None, None, None
5.306, 260, 0.2153, None, None, None, None, None
5.510, 270, 0.1256, None, None, None, None, None
5.714, 280, 0.1340, None, None, None, None, None
5.918, 290, 0.1650, None, None, None, None, None
6.000, 294, None, 1.1538, 0.3561, 0.6809, 0.4676, 0.8075
6.122, 300, 0.1637, None, None, None, None, None
6.327, 310, 0.0780, None, None, None, None, None
6.531, 320, 0.0831, None, None, None, None, None
6.735, 330, 0.0982, None, None, None, None, None
6.939, 340, 0.1500, None, None, None, None, None
7.000, 343, None, 1.4026, 0.4779, 0.6533, 0.5520, 0.9009
7.143, 350, 0.0760, None, None, None, None, None
7.347, 360, 0.0829, None, None, None, None, None
7.551, 370, 0.0766, None, None, None, None, None
7.755, 380, 0.1187, None, None, None, None, None
7.959, 390, 0.0192, None, None, None, None, None
8.000, 392, None, 1.4670, 0.5255, 0.6985, 0.5998, 0.9091
8.163, 400, 0.0417, None, None, None, None, None
8.367, 410, 0.0438, None, None, None, None, None
8.571, 420, 0.0661, None, None, None, None, None
8.776, 430, 0.0779, None, None, None, None, None
8.980, 440, 0.0567, None, None, None, None, None
9.000, 441, None, 1.4913, 0.5167, 0.6985, 0.5940, 0.9038
9.184, 450, 0.0959, None, None, None, None, None
9.388, 460, 0.0219, None, None, None, None, None
9.592, 470, 0.0204, None, None, None, None, None
9.796, 480, 0.0435, None, None, None, None, None
10.000, 490, 0.0675, None, None, None, None, None
10.000, 490, None, 1.5214, 0.5308, 0.6935, 0.6013, 0.9113
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.5214, 0.5308, 0.6935, 0.6013, 0.9113

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3242, None, None, None, None, None
0.408, 20, 3.1308, None, None, None, None, None
0.612, 30, 2.7688, None, None, None, None, None
0.816, 40, 2.7048, None, None, None, None, None
1.000, 49, None, 1.9304, 0.0705, 0.5234, 0.1243, 0.1478
1.020, 50, 2.3553, None, None, None, None, None
1.224, 60, 1.8392, None, None, None, None, None
1.429, 70, 1.5889, None, None, None, None, None
1.633, 80, 1.4385, None, None, None, None, None
1.837, 90, 1.0942, None, None, None, None, None
2.000, 98, None, 1.0057, 0.1355, 0.6393, 0.2236, 0.1429
2.041, 100, 1.3155, None, None, None, None, None
2.245, 110, 0.7814, None, None, None, None, None
2.449, 120, 0.7046, None, None, None, None, None
2.653, 130, 0.6822, None, None, None, None, None
2.857, 140, 0.7312, None, None, None, None, None
3.000, 147, None, 0.5531, 0.2287, 0.6972, 0.3444, 0.6954
3.061, 150, 0.4405, None, None, None, None, None
3.265, 160, 0.4623, None, None, None, None, None
3.469, 170, 0.3869, None, None, None, None, None
3.673, 180, 0.3793, None, None, None, None, None
3.878, 190, 0.2787, None, None, None, None, None
4.000, 196, None, 0.4075, 0.1957, 0.6262, 0.2982, 0.6581
4.082, 200, 0.3623, None, None, None, None, None
4.286, 210, 0.2275, None, None, None, None, None
4.490, 220, 0.2505, None, None, None, None, None
4.694, 230, 0.1833, None, None, None, None, None
4.898, 240, 0.3559, None, None, None, None, None
5.000, 245, None, 0.4440, 0.2641, 0.6654, 0.3781, 0.6523
5.102, 250, 0.2998, None, None, None, None, None
5.306, 260, 0.1788, None, None, None, None, None
5.510, 270, 0.2060, None, None, None, None, None
5.714, 280, 0.2073, None, None, None, None, None
5.918, 290, 0.1240, None, None, None, None, None
6.000, 294, None, 0.4472, 0.4852, 0.7346, 0.5844, 0.8859
6.122, 300, 0.1025, None, None, None, None, None
6.327, 310, 0.1260, None, None, None, None, None
6.531, 320, 0.1507, None, None, None, None, None
6.735, 330, 0.1129, None, None, None, None, None
6.939, 340, 0.0598, None, None, None, None, None
7.000, 343, None, 0.5446, 0.5685, 0.7682, 0.6534, 0.9126
7.143, 350, 0.1172, None, None, None, None, None
7.347, 360, 0.0733, None, None, None, None, None
7.551, 370, 0.0571, None, None, None, None, None
7.755, 380, 0.0974, None, None, None, None, None
7.959, 390, 0.0288, None, None, None, None, None
8.000, 392, None, 0.5321, 0.5352, 0.7383, 0.6206, 0.9069
8.163, 400, 0.0862, None, None, None, None, None
8.367, 410, 0.0598, None, None, None, None, None
8.571, 420, 0.0596, None, None, None, None, None
8.776, 430, 0.1084, None, None, None, None, None
8.980, 440, 0.0730, None, None, None, None, None
9.000, 441, None, 0.5593, 0.5658, 0.7551, 0.6469, 0.9134
9.184, 450, 0.0991, None, None, None, None, None
9.388, 460, 0.0321, None, None, None, None, None
9.592, 470, 0.0298, None, None, None, None, None
9.796, 480, 0.0311, None, None, None, None, None
10.000, 490, 0.1000, None, None, None, None, None
10.000, 490, None, 0.5679, 0.5682, 0.7551, 0.6485, 0.9146
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 0.5679, 0.5682, 0.7551, 0.6485, 0.9146

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2728, None, None, None, None, None
0.408, 20, 3.0711, None, None, None, None, None
0.612, 30, 2.9176, None, None, None, None, None
0.816, 40, 2.5615, None, None, None, None, None
1.000, 49, None, 2.1547, 0.0480, 0.3543, 0.0845, 0.3962
1.020, 50, 2.2635, None, None, None, None, None
1.224, 60, 1.7292, None, None, None, None, None
1.429, 70, 1.6342, None, None, None, None, None
1.633, 80, 1.1589, None, None, None, None, None
1.837, 90, 1.4129, None, None, None, None, None
2.000, 98, None, 1.1913, 0.1505, 0.5739, 0.2385, 0.6531
2.041, 100, 0.8571, None, None, None, None, None
2.245, 110, 0.6956, None, None, None, None, None
2.449, 120, 0.5974, None, None, None, None, None
2.653, 130, 0.4253, None, None, None, None, None
2.857, 140, 0.5381, None, None, None, None, None
3.000, 147, None, 1.0776, 0.2527, 0.6130, 0.3579, 0.7064
3.061, 150, 0.4989, None, None, None, None, None
3.265, 160, 0.3240, None, None, None, None, None
3.469, 170, 0.2821, None, None, None, None, None
3.673, 180, 0.2393, None, None, None, None, None
3.878, 190, 0.3778, None, None, None, None, None
4.000, 196, None, 0.9318, 0.2917, 0.6457, 0.4019, 0.8486
4.082, 200, 0.3498, None, None, None, None, None
4.286, 210, 0.1360, None, None, None, None, None
4.490, 220, 0.2011, None, None, None, None, None
4.694, 230, 0.2192, None, None, None, None, None
4.898, 240, 0.2040, None, None, None, None, None
5.000, 245, None, 1.2459, 0.2944, 0.5870, 0.3922, 0.8245
5.102, 250, 0.1737, None, None, None, None, None
5.306, 260, 0.1215, None, None, None, None, None
5.510, 270, 0.1336, None, None, None, None, None
5.714, 280, 0.1745, None, None, None, None, None
5.918, 290, 0.1147, None, None, None, None, None
6.000, 294, None, 1.3440, 0.4203, 0.6304, 0.5043, 0.8705
6.122, 300, 0.0947, None, None, None, None, None
6.327, 310, 0.0385, None, None, None, None, None
6.531, 320, 0.0936, None, None, None, None, None
6.735, 330, 0.1192, None, None, None, None, None
6.939, 340, 0.1065, None, None, None, None, None
7.000, 343, None, 1.3641, 0.4446, 0.6370, 0.5237, 0.8989
7.143, 350, 0.0778, None, None, None, None, None
7.347, 360, 0.0693, None, None, None, None, None
7.551, 370, 0.0811, None, None, None, None, None
7.755, 380, 0.0839, None, None, None, None, None
7.959, 390, 0.0267, None, None, None, None, None
8.000, 392, None, 1.3185, 0.5558, 0.6826, 0.6127, 0.9395
8.163, 400, 0.0414, None, None, None, None, None
8.367, 410, 0.0734, None, None, None, None, None
8.571, 420, 0.0324, None, None, None, None, None
8.776, 430, 0.0894, None, None, None, None, None
8.980, 440, 0.0196, None, None, None, None, None
9.000, 441, None, 1.3506, 0.5391, 0.6891, 0.6050, 0.9324
9.184, 450, 0.0370, None, None, None, None, None
9.388, 460, 0.0269, None, None, None, None, None
9.592, 470, 0.0418, None, None, None, None, None
9.796, 480, 0.0362, None, None, None, None, None
10.000, 490, 0.0847, None, None, None, None, None
10.000, 490, None, 1.3815, 0.5737, 0.7022, 0.6315, 0.9409
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.3815, 0.5737, 0.7022, 0.6315, 0.9409

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3034, None, None, None, None, None
0.408, 20, 3.0937, None, None, None, None, None
0.612, 30, 2.9349, None, None, None, None, None
0.816, 40, 2.6328, None, None, None, None, None
1.000, 49, None, 2.0128, 0.0558, 0.5178, 0.1008, 0.2247
1.020, 50, 2.4058, None, None, None, None, None
1.224, 60, 1.9066, None, None, None, None, None
1.429, 70, 1.4063, None, None, None, None, None
1.633, 80, 1.3479, None, None, None, None, None
1.837, 90, 1.1310, None, None, None, None, None
2.000, 98, None, 1.0348, 0.1762, 0.6467, 0.2769, 0.7026
2.041, 100, 1.2471, None, None, None, None, None
2.245, 110, 0.7140, None, None, None, None, None
2.449, 120, 0.6029, None, None, None, None, None
2.653, 130, 0.7136, None, None, None, None, None
2.857, 140, 0.6923, None, None, None, None, None
3.000, 147, None, 0.7057, 0.2705, 0.7622, 0.3993, 0.7450
3.061, 150, 0.4796, None, None, None, None, None
3.265, 160, 0.4124, None, None, None, None, None
3.469, 170, 0.3784, None, None, None, None, None
3.673, 180, 0.3343, None, None, None, None, None
3.878, 190, 0.2973, None, None, None, None, None
4.000, 196, None, 0.7380, 0.2220, 0.6356, 0.3291, 0.6987
4.082, 200, 0.3122, None, None, None, None, None
4.286, 210, 0.1596, None, None, None, None, None
4.490, 220, 0.2765, None, None, None, None, None
4.694, 230, 0.1612, None, None, None, None, None
4.898, 240, 0.2774, None, None, None, None, None
5.000, 245, None, 0.7096, 0.3235, 0.6800, 0.4384, 0.8215
5.102, 250, 0.1749, None, None, None, None, None
5.306, 260, 0.1033, None, None, None, None, None
5.510, 270, 0.1362, None, None, None, None, None
5.714, 280, 0.2866, None, None, None, None, None
5.918, 290, 0.0846, None, None, None, None, None
6.000, 294, None, 0.9163, 0.5321, 0.7378, 0.6182, 0.9142
6.122, 300, 0.0924, None, None, None, None, None
6.327, 310, 0.0604, None, None, None, None, None
6.531, 320, 0.1184, None, None, None, None, None
6.735, 330, 0.1138, None, None, None, None, None
6.939, 340, 0.0890, None, None, None, None, None
7.000, 343, None, 0.9100, 0.5474, 0.7578, 0.6356, 0.9131
7.143, 350, 0.0956, None, None, None, None, None
7.347, 360, 0.0809, None, None, None, None, None
7.551, 370, 0.0561, None, None, None, None, None
7.755, 380, 0.0679, None, None, None, None, None
7.959, 390, 0.0316, None, None, None, None, None
8.000, 392, None, 0.9952, 0.5939, 0.7733, 0.6718, 0.9272
8.163, 400, 0.0348, None, None, None, None, None
8.367, 410, 0.0414, None, None, None, None, None
8.571, 420, 0.0535, None, None, None, None, None
8.776, 430, 0.0848, None, None, None, None, None
8.980, 440, 0.0437, None, None, None, None, None
9.000, 441, None, 0.9976, 0.5973, 0.7778, 0.6757, 0.9259
9.184, 450, 0.0594, None, None, None, None, None
9.388, 460, 0.0476, None, None, None, None, None
9.592, 470, 0.0216, None, None, None, None, None
9.796, 480, 0.0315, None, None, None, None, None
10.000, 490, 0.0710, None, None, None, None, None
10.000, 490, None, 1.0048, 0.5945, 0.7756, 0.6731, 0.9273
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.0048, 0.5945, 0.7756, 0.6731, 0.9273

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.208, 10, 3.3576, None, None, None, None, None
0.417, 20, 3.1316, None, None, None, None, None
0.625, 30, 2.7201, None, None, None, None, None
0.833, 40, 2.7117, None, None, None, None, None
1.000, 48, None, 2.3678, 0.0410, 0.3713, 0.0738, 0.0972
1.042, 50, 2.2645, None, None, None, None, None
1.250, 60, 1.7316, None, None, None, None, None
1.458, 70, 1.5699, None, None, None, None, None
1.667, 80, 1.3887, None, None, None, None, None
1.875, 90, 1.0963, None, None, None, None, None
2.000, 96, None, 1.1785, 0.1686, 0.7034, 0.2720, 0.6341
2.083, 100, 1.0298, None, None, None, None, None
2.292, 110, 0.7662, None, None, None, None, None
2.500, 120, 0.6427, None, None, None, None, None
2.708, 130, 0.5182, None, None, None, None, None
2.917, 140, 0.4990, None, None, None, None, None
3.000, 144, None, 0.9403, 0.2770, 0.7183, 0.3998, 0.8030
3.125, 150, 0.4181, None, None, None, None, None
3.333, 160, 0.4854, None, None, None, None, None
3.542, 170, 0.3308, None, None, None, None, None
3.750, 180, 0.3028, None, None, None, None, None
3.958, 190, 0.4174, None, None, None, None, None
4.000, 192, None, 0.7813, 0.2565, 0.6604, 0.3695, 0.7638
4.167, 200, 0.2479, None, None, None, None, None
4.375, 210, 0.3204, None, None, None, None, None
4.583, 220, 0.1888, None, None, None, None, None
4.792, 230, 0.2079, None, None, None, None, None
5.000, 240, 0.2419, None, None, None, None, None
5.000, 240, None, 0.9760, 0.3369, 0.6381, 0.4410, 0.8636
5.208, 250, 0.1640, None, None, None, None, None
5.417, 260, 0.1393, None, None, None, None, None
5.625, 270, 0.1434, None, None, None, None, None
5.833, 280, 0.0924, None, None, None, None, None
6.000, 288, None, 1.2200, 0.5658, 0.6978, 0.6249, 0.9242
6.042, 290, 0.1126, None, None, None, None, None
6.250, 300, 0.0667, None, None, None, None, None
6.458, 310, 0.1237, None, None, None, None, None
6.667, 320, 0.1133, None, None, None, None, None
6.875, 330, 0.1112, None, None, None, None, None
7.000, 336, None, 1.1711, 0.4056, 0.5896, 0.4806, 0.8817
7.083, 340, 0.0762, None, None, None, None, None
7.292, 350, 0.1070, None, None, None, None, None
7.500, 360, 0.0679, None, None, None, None, None
7.708, 370, 0.0653, None, None, None, None, None
7.917, 380, 0.0413, None, None, None, None, None
8.000, 384, None, 1.1544, 0.4946, 0.6772, 0.5717, 0.9000
8.125, 390, 0.0504, None, None, None, None, None
8.333, 400, 0.0481, None, None, None, None, None
8.542, 410, 0.0439, None, None, None, None, None
8.750, 420, 0.0585, None, None, None, None, None
8.958, 430, 0.0521, None, None, None, None, None
9.000, 432, None, 1.2656, 0.5242, 0.6660, 0.5867, 0.9170
9.167, 440, 0.0304, None, None, None, None, None
9.375, 450, 0.0312, None, None, None, None, None
9.583, 460, 0.0571, None, None, None, None, None
9.792, 470, 0.0228, None, None, None, None, None
10.000, 480, 0.0420, None, None, None, None, None
10.000, 480, None, 1.3306, 0.5469, 0.6847, 0.6081, 0.9195
10.000, 480, None, None, None, None, None, None
10.000, 480, None, 1.3306, 0.5469, 0.6847, 0.6081, 0.9195

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2870, None, None, None, None, None
0.408, 20, 3.2308, None, None, None, None, None
0.612, 30, 2.7948, None, None, None, None, None
0.816, 40, 2.4718, None, None, None, None, None
1.000, 49, None, 2.1857, 0.0428, 0.4397, 0.0781, 0.1571
1.020, 50, 2.2006, None, None, None, None, None
1.224, 60, 1.7750, None, None, None, None, None
1.429, 70, 1.5446, None, None, None, None, None
1.633, 80, 1.4065, None, None, None, None, None
1.837, 90, 1.1293, None, None, None, None, None
2.000, 98, None, 1.2048, 0.1888, 0.6859, 0.2961, 0.7233
2.041, 100, 0.9958, None, None, None, None, None
2.245, 110, 0.6300, None, None, None, None, None
2.449, 120, 0.5721, None, None, None, None, None
2.653, 130, 0.6203, None, None, None, None, None
2.857, 140, 0.5803, None, None, None, None, None
3.000, 147, None, 1.1413, 0.1695, 0.6206, 0.2663, 0.5444
3.061, 150, 0.4417, None, None, None, None, None
3.265, 160, 0.3796, None, None, None, None, None
3.469, 170, 0.4091, None, None, None, None, None
3.673, 180, 0.3535, None, None, None, None, None
3.878, 190, 0.2784, None, None, None, None, None
4.000, 196, None, 1.0541, 0.2450, 0.7010, 0.3630, 0.6431
4.082, 200, 0.3366, None, None, None, None, None
4.286, 210, 0.1640, None, None, None, None, None
4.490, 220, 0.2539, None, None, None, None, None
4.694, 230, 0.1830, None, None, None, None, None
4.898, 240, 0.2534, None, None, None, None, None
5.000, 245, None, 1.0513, 0.2883, 0.5905, 0.3875, 0.7814
5.102, 250, 0.1897, None, None, None, None, None
5.306, 260, 0.1994, None, None, None, None, None
5.510, 270, 0.1251, None, None, None, None, None
5.714, 280, 0.1244, None, None, None, None, None
5.918, 290, 0.1497, None, None, None, None, None
6.000, 294, None, 1.1386, 0.3482, 0.6859, 0.4619, 0.8218
6.122, 300, 0.1733, None, None, None, None, None
6.327, 310, 0.0771, None, None, None, None, None
6.531, 320, 0.0936, None, None, None, None, None
6.735, 330, 0.1058, None, None, None, None, None
6.939, 340, 0.1461, None, None, None, None, None
7.000, 343, None, 1.3890, 0.4700, 0.6683, 0.5519, 0.8997
7.143, 350, 0.0763, None, None, None, None, None
7.347, 360, 0.0902, None, None, None, None, None
7.551, 370, 0.1069, None, None, None, None, None
7.755, 380, 0.1332, None, None, None, None, None
7.959, 390, 0.0198, None, None, None, None, None
8.000, 392, None, 1.5608, 0.5708, 0.6985, 0.6282, 0.9254
8.163, 400, 0.0453, None, None, None, None, None
8.367, 410, 0.0505, None, None, None, None, None
8.571, 420, 0.0804, None, None, None, None, None
8.776, 430, 0.0883, None, None, None, None, None
8.980, 440, 0.0593, None, None, None, None, None
9.000, 441, None, 1.5105, 0.5451, 0.6985, 0.6123, 0.9115
9.184, 450, 0.1016, None, None, None, None, None
9.388, 460, 0.0201, None, None, None, None, None
9.592, 470, 0.0227, None, None, None, None, None
9.796, 480, 0.0408, None, None, None, None, None
10.000, 490, 0.0626, None, None, None, None, None
10.000, 490, None, 1.5454, 0.5549, 0.6985, 0.6185, 0.9144
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.5454, 0.5549, 0.6985, 0.6185, 0.9144

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3242, None, None, None, None, None
0.408, 20, 3.1308, None, None, None, None, None
0.612, 30, 2.7688, None, None, None, None, None
0.816, 40, 2.7048, None, None, None, None, None
1.000, 49, None, 1.9305, 0.0705, 0.5234, 0.1243, 0.1478
1.020, 50, 2.3554, None, None, None, None, None
1.224, 60, 1.8398, None, None, None, None, None
1.429, 70, 1.5923, None, None, None, None, None
1.633, 80, 1.4272, None, None, None, None, None
1.837, 90, 1.0974, None, None, None, None, None
2.000, 98, None, 0.9941, 0.1341, 0.6393, 0.2217, 0.1470
2.041, 100, 1.3049, None, None, None, None, None
2.245, 110, 0.7791, None, None, None, None, None
2.449, 120, 0.7053, None, None, None, None, None
2.653, 130, 0.6724, None, None, None, None, None
2.857, 140, 0.7335, None, None, None, None, None
3.000, 147, None, 0.5450, 0.2348, 0.7215, 0.3543, 0.7026
3.061, 150, 0.4406, None, None, None, None, None
3.265, 160, 0.4422, None, None, None, None, None
3.469, 170, 0.3956, None, None, None, None, None
3.673, 180, 0.3874, None, None, None, None, None
3.878, 190, 0.3056, None, None, None, None, None
4.000, 196, None, 0.4198, 0.2263, 0.6636, 0.3375, 0.7053
4.082, 200, 0.3607, None, None, None, None, None
4.286, 210, 0.2243, None, None, None, None, None
4.490, 220, 0.2863, None, None, None, None, None
4.694, 230, 0.1882, None, None, None, None, None
4.898, 240, 0.3579, None, None, None, None, None
5.000, 245, None, 0.4437, 0.2643, 0.6636, 0.3781, 0.6481
5.102, 250, 0.3233, None, None, None, None, None
5.306, 260, 0.1727, None, None, None, None, None
5.510, 270, 0.2229, None, None, None, None, None
5.714, 280, 0.1965, None, None, None, None, None
5.918, 290, 0.1232, None, None, None, None, None
6.000, 294, None, 0.4336, 0.4517, 0.6991, 0.5488, 0.8801
6.122, 300, 0.1071, None, None, None, None, None
6.327, 310, 0.1315, None, None, None, None, None
6.531, 320, 0.1508, None, None, None, None, None
6.735, 330, 0.1215, None, None, None, None, None
6.939, 340, 0.0632, None, None, None, None, None
7.000, 343, None, 0.5083, 0.5458, 0.7682, 0.6382, 0.9022
7.143, 350, 0.1513, None, None, None, None, None
7.347, 360, 0.0798, None, None, None, None, None
7.551, 370, 0.0627, None, None, None, None, None
7.755, 380, 0.0966, None, None, None, None, None
7.959, 390, 0.0329, None, None, None, None, None
8.000, 392, None, 0.5063, 0.5340, 0.7477, 0.6231, 0.9025
8.163, 400, 0.0730, None, None, None, None, None
8.367, 410, 0.0669, None, None, None, None, None
8.571, 420, 0.0787, None, None, None, None, None
8.776, 430, 0.0991, None, None, None, None, None
8.980, 440, 0.0702, None, None, None, None, None
9.000, 441, None, 0.5426, 0.5443, 0.7346, 0.6253, 0.9096
9.184, 450, 0.0908, None, None, None, None, None
9.388, 460, 0.0329, None, None, None, None, None
9.592, 470, 0.0214, None, None, None, None, None
9.796, 480, 0.0337, None, None, None, None, None
10.000, 490, 0.1035, None, None, None, None, None
10.000, 490, None, 0.5984, 0.6235, 0.7832, 0.6943, 0.9262
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 0.5984, 0.6235, 0.7832, 0.6943, 0.9262

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.2728, None, None, None, None, None
0.408, 20, 3.0711, None, None, None, None, None
0.612, 30, 2.9176, None, None, None, None, None
0.816, 40, 2.5615, None, None, None, None, None
1.000, 49, None, 2.1548, 0.0480, 0.3543, 0.0845, 0.3961
1.020, 50, 2.2636, None, None, None, None, None
1.224, 60, 1.7303, None, None, None, None, None
1.429, 70, 1.6351, None, None, None, None, None
1.633, 80, 1.1655, None, None, None, None, None
1.837, 90, 1.4036, None, None, None, None, None
2.000, 98, None, 1.2006, 0.1502, 0.5761, 0.2383, 0.6403
2.041, 100, 0.8630, None, None, None, None, None
2.245, 110, 0.7073, None, None, None, None, None
2.449, 120, 0.5996, None, None, None, None, None
2.653, 130, 0.4291, None, None, None, None, None
2.857, 140, 0.5181, None, None, None, None, None
3.000, 147, None, 1.0637, 0.2541, 0.6130, 0.3592, 0.7075
3.061, 150, 0.4899, None, None, None, None, None
3.265, 160, 0.3280, None, None, None, None, None
3.469, 170, 0.2890, None, None, None, None, None
3.673, 180, 0.2284, None, None, None, None, None
3.878, 190, 0.3656, None, None, None, None, None
4.000, 196, None, 0.9352, 0.2992, 0.6543, 0.4106, 0.8499
4.082, 200, 0.3632, None, None, None, None, None
4.286, 210, 0.1422, None, None, None, None, None
4.490, 220, 0.2110, None, None, None, None, None
4.694, 230, 0.2202, None, None, None, None, None
4.898, 240, 0.1936, None, None, None, None, None
5.000, 245, None, 1.2129, 0.2990, 0.5674, 0.3916, 0.8291
5.102, 250, 0.1578, None, None, None, None, None
5.306, 260, 0.1220, None, None, None, None, None
5.510, 270, 0.1399, None, None, None, None, None
5.714, 280, 0.1862, None, None, None, None, None
5.918, 290, 0.1271, None, None, None, None, None
6.000, 294, None, 1.3874, 0.4296, 0.6565, 0.5193, 0.8791
6.122, 300, 0.1009, None, None, None, None, None
6.327, 310, 0.0509, None, None, None, None, None
6.531, 320, 0.0899, None, None, None, None, None
6.735, 330, 0.1336, None, None, None, None, None
6.939, 340, 0.1092, None, None, None, None, None
7.000, 343, None, 1.4087, 0.4040, 0.6217, 0.4897, 0.8788
7.143, 350, 0.0815, None, None, None, None, None
7.347, 360, 0.0884, None, None, None, None, None
7.551, 370, 0.0853, None, None, None, None, None
7.755, 380, 0.0815, None, None, None, None, None
7.959, 390, 0.0267, None, None, None, None, None
8.000, 392, None, 1.4590, 0.5017, 0.6609, 0.5704, 0.9050
8.163, 400, 0.0448, None, None, None, None, None
8.367, 410, 0.0694, None, None, None, None, None
8.571, 420, 0.0346, None, None, None, None, None
8.776, 430, 0.1824, None, None, None, None, None
8.980, 440, 0.0226, None, None, None, None, None
9.000, 441, None, 1.4324, 0.5340, 0.6826, 0.5992, 0.9314
9.184, 450, 0.0341, None, None, None, None, None
9.388, 460, 0.0258, None, None, None, None, None
9.592, 470, 0.0489, None, None, None, None, None
9.796, 480, 0.0370, None, None, None, None, None
10.000, 490, 0.0825, None, None, None, None, None
10.000, 490, None, 1.4927, 0.5445, 0.6783, 0.6041, 0.9382
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.4927, 0.5445, 0.6783, 0.6041, 0.9382

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 1,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.204, 10, 3.3035, None, None, None, None, None
0.408, 20, 3.0937, None, None, None, None, None
0.612, 30, 2.9349, None, None, None, None, None
0.816, 40, 2.6327, None, None, None, None, None
1.000, 49, None, 2.0129, 0.0558, 0.5178, 0.1008, 0.2249
1.020, 50, 2.4059, None, None, None, None, None
1.224, 60, 1.9075, None, None, None, None, None
1.429, 70, 1.4097, None, None, None, None, None
1.633, 80, 1.3475, None, None, None, None, None
1.837, 90, 1.1355, None, None, None, None, None
2.000, 98, None, 1.0143, 0.1716, 0.6511, 0.2717, 0.6888
2.041, 100, 1.2436, None, None, None, None, None
2.245, 110, 0.7077, None, None, None, None, None
2.449, 120, 0.6171, None, None, None, None, None
2.653, 130, 0.7205, None, None, None, None, None
2.857, 140, 0.7006, None, None, None, None, None
3.000, 147, None, 0.7003, 0.2558, 0.7644, 0.3833, 0.7228
3.061, 150, 0.4690, None, None, None, None, None
3.265, 160, 0.3926, None, None, None, None, None
3.469, 170, 0.3842, None, None, None, None, None
3.673, 180, 0.3488, None, None, None, None, None
3.878, 190, 0.3006, None, None, None, None, None
4.000, 196, None, 0.7271, 0.2489, 0.6533, 0.3605, 0.7499
4.082, 200, 0.3178, None, None, None, None, None
4.286, 210, 0.1523, None, None, None, None, None
4.490, 220, 0.2601, None, None, None, None, None
4.694, 230, 0.1776, None, None, None, None, None
4.898, 240, 0.3020, None, None, None, None, None
5.000, 245, None, 0.6942, 0.3348, 0.6933, 0.4515, 0.8244
5.102, 250, 0.1850, None, None, None, None, None
5.306, 260, 0.0994, None, None, None, None, None
5.510, 270, 0.1735, None, None, None, None, None
5.714, 280, 0.2773, None, None, None, None, None
5.918, 290, 0.0891, None, None, None, None, None
6.000, 294, None, 0.8785, 0.5638, 0.7556, 0.6458, 0.9234
6.122, 300, 0.0846, None, None, None, None, None
6.327, 310, 0.0653, None, None, None, None, None
6.531, 320, 0.1309, None, None, None, None, None
6.735, 330, 0.1082, None, None, None, None, None
6.939, 340, 0.0942, None, None, None, None, None
7.000, 343, None, 0.9048, 0.5346, 0.7556, 0.6262, 0.9117
7.143, 350, 0.1072, None, None, None, None, None
7.347, 360, 0.0835, None, None, None, None, None
7.551, 370, 0.0596, None, None, None, None, None
7.755, 380, 0.0676, None, None, None, None, None
7.959, 390, 0.0321, None, None, None, None, None
8.000, 392, None, 1.0545, 0.5990, 0.7800, 0.6776, 0.9320
8.163, 400, 0.0385, None, None, None, None, None
8.367, 410, 0.0369, None, None, None, None, None
8.571, 420, 0.0658, None, None, None, None, None
8.776, 430, 0.1048, None, None, None, None, None
8.980, 440, 0.0489, None, None, None, None, None
9.000, 441, None, 1.0400, 0.5908, 0.7667, 0.6673, 0.9280
9.184, 450, 0.0549, None, None, None, None, None
9.388, 460, 0.0394, None, None, None, None, None
9.592, 470, 0.0300, None, None, None, None, None
9.796, 480, 0.0360, None, None, None, None, None
10.000, 490, 0.0686, None, None, None, None, None
10.000, 490, None, 1.0843, 0.6147, 0.7800, 0.6876, 0.9326
10.000, 490, None, None, None, None, None, None
10.000, 490, None, 1.0843, 0.6147, 0.7800, 0.6876, 0.9326

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.417, 10, 3.2617, None, None, None, None, None
0.833, 20, 2.9183, None, None, None, None, None
1.000, 24, None, 2.5390, 0.0222, 0.2481, 0.0408, 0.0522
1.250, 30, 2.3139, None, None, None, None, None
1.667, 40, 1.9380, None, None, None, None, None
2.000, 48, None, 1.4719, 0.1319, 0.6493, 0.2192, 0.5985
2.083, 50, 1.4164, None, None, None, None, None
2.500, 60, 0.9763, None, None, None, None, None
2.917, 70, 0.7634, None, None, None, None, None
3.000, 72, None, 1.0523, 0.1451, 0.6847, 0.2394, 0.3504
3.333, 80, 0.5578, None, None, None, None, None
3.750, 90, 0.4833, None, None, None, None, None
4.000, 96, None, 0.9860, 0.1779, 0.6231, 0.2768, 0.6516
4.167, 100, 0.3928, None, None, None, None, None
4.583, 110, 0.3539, None, None, None, None, None
5.000, 120, 0.3135, None, None, None, None, None
5.000, 120, None, 0.8903, 0.2776, 0.6325, 0.3859, 0.7801
5.417, 130, 0.2218, None, None, None, None, None
5.833, 140, 0.1915, None, None, None, None, None
6.000, 144, None, 0.8403, 0.3020, 0.6474, 0.4119, 0.7879
6.250, 150, 0.1424, None, None, None, None, None
6.667, 160, 0.1451, None, None, None, None, None
7.000, 168, None, 1.0670, 0.3878, 0.6287, 0.4797, 0.8728
7.083, 170, 0.1299, None, None, None, None, None
7.500, 180, 0.0984, None, None, None, None, None
7.917, 190, 0.0911, None, None, None, None, None
8.000, 192, None, 1.0043, 0.3797, 0.6269, 0.4729, 0.8721
8.333, 200, 0.0797, None, None, None, None, None
8.750, 210, 0.0953, None, None, None, None, None
9.000, 216, None, 1.0176, 0.4194, 0.6455, 0.5084, 0.8845
9.167, 220, 0.0731, None, None, None, None, None
9.583, 230, 0.0843, None, None, None, None, None
10.000, 240, 0.0624, None, None, None, None, None
10.000, 240, None, 1.0432, 0.4295, 0.6474, 0.5164, 0.8881
10.000, 240, None, None, None, None, None, None
10.000, 240, None, 1.0432, 0.4295, 0.6474, 0.5164, 0.8881

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2865, None, None, None, None, None
0.800, 20, 2.8067, None, None, None, None, None
1.000, 25, None, 2.4963, 0.0218, 0.2613, 0.0402, 0.0464
1.200, 30, 2.4436, None, None, None, None, None
1.600, 40, 1.9336, None, None, None, None, None
2.000, 50, 1.5554, None, None, None, None, None
2.000, 50, None, 1.5598, 0.0917, 0.6030, 0.1592, 0.4289
2.400, 60, 1.0529, None, None, None, None, None
2.800, 70, 0.8284, None, None, None, None, None
3.000, 75, None, 1.3056, 0.1408, 0.5578, 0.2248, 0.5448
3.200, 80, 0.6523, None, None, None, None, None
3.600, 90, 0.5829, None, None, None, None, None
4.000, 100, 0.5250, None, None, None, None, None
4.000, 100, None, 1.0753, 0.2030, 0.6784, 0.3125, 0.6341
4.400, 110, 0.3072, None, None, None, None, None
4.800, 120, 0.3774, None, None, None, None, None
5.000, 125, None, 0.9909, 0.2336, 0.6156, 0.3386, 0.7531
5.200, 130, 0.2861, None, None, None, None, None
5.600, 140, 0.2216, None, None, None, None, None
6.000, 150, 0.2224, None, None, None, None, None
6.000, 150, None, 1.0189, 0.2649, 0.6482, 0.3761, 0.7723
6.400, 160, 0.1596, None, None, None, None, None
6.800, 170, 0.1595, None, None, None, None, None
7.000, 175, None, 1.0971, 0.3592, 0.6508, 0.4629, 0.8529
7.200, 180, 0.1494, None, None, None, None, None
7.600, 190, 0.1212, None, None, None, None, None
8.000, 200, 0.1090, None, None, None, None, None
8.000, 200, None, 1.1016, 0.3786, 0.6658, 0.4827, 0.8581
8.400, 210, 0.0778, None, None, None, None, None
8.800, 220, 0.1433, None, None, None, None, None
9.000, 225, None, 1.1704, 0.4228, 0.6608, 0.5157, 0.8730
9.200, 230, 0.0838, None, None, None, None, None
9.600, 240, 0.0691, None, None, None, None, None
10.000, 250, 0.0991, None, None, None, None, None
10.000, 250, None, 1.1645, 0.4224, 0.6633, 0.5161, 0.8714
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1645, 0.4224, 0.6633, 0.5161, 0.8714

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2397, None, None, None, None, None
0.800, 20, 2.8780, None, None, None, None, None
1.000, 25, None, 2.2395, 0.0377, 0.3981, 0.0688, 0.0677
1.200, 30, 2.4154, None, None, None, None, None
1.600, 40, 1.9332, None, None, None, None, None
2.000, 50, 1.4688, None, None, None, None, None
2.000, 50, None, 1.2154, 0.1159, 0.6056, 0.1946, 0.3204
2.400, 60, 1.0142, None, None, None, None, None
2.800, 70, 0.9468, None, None, None, None, None
3.000, 75, None, 0.6049, 0.1592, 0.7252, 0.2611, 0.5259
3.200, 80, 0.5847, None, None, None, None, None
3.600, 90, 0.4810, None, None, None, None, None
4.000, 100, 0.4524, None, None, None, None, None
4.000, 100, None, 0.4398, 0.3306, 0.7477, 0.4585, 0.7874
4.400, 110, 0.2948, None, None, None, None, None
4.800, 120, 0.2795, None, None, None, None, None
5.000, 125, None, 0.4531, 0.2456, 0.7570, 0.3709, 0.6045
5.200, 130, 0.3207, None, None, None, None, None
5.600, 140, 0.2367, None, None, None, None, None
6.000, 150, 0.1575, None, None, None, None, None
6.000, 150, None, 0.3753, 0.4078, 0.7402, 0.5259, 0.8477
6.400, 160, 0.1737, None, None, None, None, None
6.800, 170, 0.1422, None, None, None, None, None
7.000, 175, None, 0.3796, 0.3580, 0.6953, 0.4727, 0.8186
7.200, 180, 0.1054, None, None, None, None, None
7.600, 190, 0.0918, None, None, None, None, None
8.000, 200, 0.1068, None, None, None, None, None
8.000, 200, None, 0.3826, 0.4648, 0.7402, 0.5710, 0.8750
8.400, 210, 0.0906, None, None, None, None, None
8.800, 220, 0.0891, None, None, None, None, None
9.000, 225, None, 0.3878, 0.4668, 0.7364, 0.5714, 0.8712
9.200, 230, 0.0915, None, None, None, None, None
9.600, 240, 0.0641, None, None, None, None, None
10.000, 250, 0.1026, None, None, None, None, None
10.000, 250, None, 0.3880, 0.4794, 0.7383, 0.5813, 0.8801
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.3880, 0.4794, 0.7383, 0.5813, 0.8801

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2200, None, None, None, None, None
0.800, 20, 2.8992, None, None, None, None, None
1.000, 25, None, 2.4104, 0.0314, 0.3913, 0.0582, 0.0811
1.200, 30, 2.3200, None, None, None, None, None
1.600, 40, 1.8603, None, None, None, None, None
2.000, 50, 1.5057, None, None, None, None, None
2.000, 50, None, 1.4734, 0.1060, 0.5696, 0.1787, 0.4722
2.400, 60, 1.0043, None, None, None, None, None
2.800, 70, 0.7239, None, None, None, None, None
3.000, 75, None, 1.0193, 0.1516, 0.6478, 0.2457, 0.4795
3.200, 80, 0.5543, None, None, None, None, None
3.600, 90, 0.3977, None, None, None, None, None
4.000, 100, 0.5280, None, None, None, None, None
4.000, 100, None, 1.1294, 0.1952, 0.6196, 0.2969, 0.6895
4.400, 110, 0.2606, None, None, None, None, None
4.800, 120, 0.3671, None, None, None, None, None
5.000, 125, None, 0.9325, 0.2727, 0.6326, 0.3811, 0.8287
5.200, 130, 0.2346, None, None, None, None, None
5.600, 140, 0.1830, None, None, None, None, None
6.000, 150, 0.1813, None, None, None, None, None
6.000, 150, None, 0.9151, 0.3136, 0.6348, 0.4198, 0.8468
6.400, 160, 0.1478, None, None, None, None, None
6.800, 170, 0.1336, None, None, None, None, None
7.000, 175, None, 1.0920, 0.3420, 0.6304, 0.4434, 0.8400
7.200, 180, 0.1331, None, None, None, None, None
7.600, 190, 0.1077, None, None, None, None, None
8.000, 200, 0.0958, None, None, None, None, None
8.000, 200, None, 1.0424, 0.4072, 0.6630, 0.5045, 0.8783
8.400, 210, 0.0903, None, None, None, None, None
8.800, 220, 0.0917, None, None, None, None, None
9.000, 225, None, 1.0941, 0.4436, 0.6587, 0.5302, 0.9022
9.200, 230, 0.0656, None, None, None, None, None
9.600, 240, 0.0657, None, None, None, None, None
10.000, 250, 0.1048, None, None, None, None, None
10.000, 250, None, 1.0994, 0.4535, 0.6565, 0.5364, 0.9051
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.0994, 0.4535, 0.6565, 0.5364, 0.9051

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2209, None, None, None, None, None
0.800, 20, 2.9283, None, None, None, None, None
1.000, 25, None, 2.2131, 0.0362, 0.4578, 0.0671, 0.0731
1.200, 30, 2.4040, None, None, None, None, None
1.600, 40, 1.9089, None, None, None, None, None
2.000, 50, 1.4818, None, None, None, None, None
2.000, 50, None, 1.2142, 0.1228, 0.6711, 0.2076, 0.5124
2.400, 60, 1.0249, None, None, None, None, None
2.800, 70, 0.8384, None, None, None, None, None
3.000, 75, None, 0.7329, 0.1666, 0.7689, 0.2738, 0.6056
3.200, 80, 0.5856, None, None, None, None, None
3.600, 90, 0.4411, None, None, None, None, None
4.000, 100, 0.4466, None, None, None, None, None
4.000, 100, None, 0.6889, 0.2260, 0.6911, 0.3406, 0.7383
4.400, 110, 0.2661, None, None, None, None, None
4.800, 120, 0.3246, None, None, None, None, None
5.000, 125, None, 0.6604, 0.2648, 0.6867, 0.3822, 0.7209
5.200, 130, 0.2623, None, None, None, None, None
5.600, 140, 0.2168, None, None, None, None, None
6.000, 150, 0.1736, None, None, None, None, None
6.000, 150, None, 0.6909, 0.3781, 0.6822, 0.4865, 0.8625
6.400, 160, 0.1441, None, None, None, None, None
6.800, 170, 0.1375, None, None, None, None, None
7.000, 175, None, 0.7265, 0.4340, 0.7156, 0.5403, 0.8816
7.200, 180, 0.1435, None, None, None, None, None
7.600, 190, 0.0867, None, None, None, None, None
8.000, 200, 0.0742, None, None, None, None, None
8.000, 200, None, 0.7885, 0.5015, 0.7422, 0.5986, 0.9021
8.400, 210, 0.0646, None, None, None, None, None
8.800, 220, 0.0947, None, None, None, None, None
9.000, 225, None, 0.7987, 0.4970, 0.7356, 0.5932, 0.9000
9.200, 230, 0.0800, None, None, None, None, None
9.600, 240, 0.0653, None, None, None, None, None
10.000, 250, 0.0790, None, None, None, None, None
10.000, 250, None, 0.8083, 0.5068, 0.7400, 0.6016, 0.9035
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.8083, 0.5068, 0.7400, 0.6016, 0.9035

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.417, 10, 3.2617, None, None, None, None, None
0.833, 20, 2.9183, None, None, None, None, None
1.000, 24, None, 2.5390, 0.0222, 0.2481, 0.0408, 0.0522
1.250, 30, 2.3142, None, None, None, None, None
1.667, 40, 1.9430, None, None, None, None, None
2.000, 48, None, 1.5027, 0.1295, 0.6437, 0.2156, 0.5988
2.083, 50, 1.4333, None, None, None, None, None
2.500, 60, 1.0014, None, None, None, None, None
2.917, 70, 0.7923, None, None, None, None, None
3.000, 72, None, 1.0644, 0.1405, 0.6716, 0.2323, 0.3450
3.333, 80, 0.5865, None, None, None, None, None
3.750, 90, 0.4969, None, None, None, None, None
4.000, 96, None, 1.0006, 0.1732, 0.6306, 0.2718, 0.6472
4.167, 100, 0.4085, None, None, None, None, None
4.583, 110, 0.3772, None, None, None, None, None
5.000, 120, 0.3435, None, None, None, None, None
5.000, 120, None, 0.8591, 0.2589, 0.6119, 0.3638, 0.7787
5.417, 130, 0.2500, None, None, None, None, None
5.833, 140, 0.1905, None, None, None, None, None
6.000, 144, None, 0.8309, 0.2675, 0.6474, 0.3786, 0.7407
6.250, 150, 0.1634, None, None, None, None, None
6.667, 160, 0.1785, None, None, None, None, None
7.000, 168, None, 1.0294, 0.3808, 0.6138, 0.4700, 0.8760
7.083, 170, 0.1546, None, None, None, None, None
7.500, 180, 0.1117, None, None, None, None, None
7.917, 190, 0.0967, None, None, None, None, None
8.000, 192, None, 1.0551, 0.4208, 0.6493, 0.5106, 0.8874
8.333, 200, 0.0846, None, None, None, None, None
8.750, 210, 0.0974, None, None, None, None, None
9.000, 216, None, 1.1033, 0.4458, 0.6362, 0.5242, 0.9004
9.167, 220, 0.0742, None, None, None, None, None
9.583, 230, 0.0747, None, None, None, None, None
10.000, 240, 0.0642, None, None, None, None, None
10.000, 240, None, 1.1573, 0.4532, 0.6418, 0.5313, 0.9014
10.000, 240, None, None, None, None, None, None
10.000, 240, None, 1.1573, 0.4532, 0.6418, 0.5313, 0.9014

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2864, None, None, None, None, None
0.800, 20, 2.8068, None, None, None, None, None
1.000, 25, None, 2.4964, 0.0216, 0.2588, 0.0398, 0.0463
1.200, 30, 2.4437, None, None, None, None, None
1.600, 40, 1.9380, None, None, None, None, None
2.000, 50, 1.5726, None, None, None, None, None
2.000, 50, None, 1.5762, 0.0935, 0.6156, 0.1624, 0.4387
2.400, 60, 1.0831, None, None, None, None, None
2.800, 70, 0.8449, None, None, None, None, None
3.000, 75, None, 1.2980, 0.1376, 0.5704, 0.2217, 0.5386
3.200, 80, 0.6715, None, None, None, None, None
3.600, 90, 0.6187, None, None, None, None, None
4.000, 100, 0.5648, None, None, None, None, None
4.000, 100, None, 1.0944, 0.2109, 0.6683, 0.3207, 0.7016
4.400, 110, 0.3477, None, None, None, None, None
4.800, 120, 0.4020, None, None, None, None, None
5.000, 125, None, 0.9841, 0.2225, 0.6156, 0.3269, 0.7475
5.200, 130, 0.3076, None, None, None, None, None
5.600, 140, 0.2365, None, None, None, None, None
6.000, 150, 0.2488, None, None, None, None, None
6.000, 150, None, 0.9872, 0.2722, 0.6633, 0.3860, 0.7841
6.400, 160, 0.1791, None, None, None, None, None
6.800, 170, 0.1885, None, None, None, None, None
7.000, 175, None, 1.0630, 0.3428, 0.6658, 0.4526, 0.8298
7.200, 180, 0.1599, None, None, None, None, None
7.600, 190, 0.1300, None, None, None, None, None
8.000, 200, 0.1238, None, None, None, None, None
8.000, 200, None, 1.1377, 0.4161, 0.6608, 0.5107, 0.8688
8.400, 210, 0.0837, None, None, None, None, None
8.800, 220, 0.1504, None, None, None, None, None
9.000, 225, None, 1.1558, 0.4022, 0.6508, 0.4971, 0.8717
9.200, 230, 0.0801, None, None, None, None, None
9.600, 240, 0.0705, None, None, None, None, None
10.000, 250, 0.0955, None, None, None, None, None
10.000, 250, None, 1.1786, 0.4248, 0.6533, 0.5149, 0.8770
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1786, 0.4248, 0.6533, 0.5149, 0.8770

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2397, None, None, None, None, None
0.800, 20, 2.8780, None, None, None, None, None
1.000, 25, None, 2.2397, 0.0377, 0.3981, 0.0688, 0.0677
1.200, 30, 2.4155, None, None, None, None, None
1.600, 40, 1.9350, None, None, None, None, None
2.000, 50, 1.4805, None, None, None, None, None
2.000, 50, None, 1.2321, 0.1134, 0.6075, 0.1911, 0.3206
2.400, 60, 1.0346, None, None, None, None, None
2.800, 70, 0.9652, None, None, None, None, None
3.000, 75, None, 0.6268, 0.1551, 0.7252, 0.2555, 0.5165
3.200, 80, 0.6138, None, None, None, None, None
3.600, 90, 0.5097, None, None, None, None, None
4.000, 100, 0.4800, None, None, None, None, None
4.000, 100, None, 0.4695, 0.3586, 0.7607, 0.4874, 0.8391
4.400, 110, 0.3315, None, None, None, None, None
4.800, 120, 0.3179, None, None, None, None, None
5.000, 125, None, 0.4525, 0.2379, 0.7607, 0.3624, 0.6020
5.200, 130, 0.3473, None, None, None, None, None
5.600, 140, 0.2533, None, None, None, None, None
6.000, 150, 0.1757, None, None, None, None, None
6.000, 150, None, 0.3906, 0.4036, 0.7477, 0.5242, 0.8508
6.400, 160, 0.1919, None, None, None, None, None
6.800, 170, 0.1543, None, None, None, None, None
7.000, 175, None, 0.3879, 0.3691, 0.7271, 0.4896, 0.7971
7.200, 180, 0.1270, None, None, None, None, None
7.600, 190, 0.0976, None, None, None, None, None
8.000, 200, 0.1174, None, None, None, None, None
8.000, 200, None, 0.4118, 0.4653, 0.7383, 0.5708, 0.8732
8.400, 210, 0.0978, None, None, None, None, None
8.800, 220, 0.1015, None, None, None, None, None
9.000, 225, None, 0.3976, 0.4443, 0.7159, 0.5483, 0.8645
9.200, 230, 0.0895, None, None, None, None, None
9.600, 240, 0.0674, None, None, None, None, None
10.000, 250, 0.1080, None, None, None, None, None
10.000, 250, None, 0.4157, 0.5187, 0.7514, 0.6137, 0.9011
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.4157, 0.5187, 0.7514, 0.6137, 0.9011

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2200, None, None, None, None, None
0.800, 20, 2.8992, None, None, None, None, None
1.000, 25, None, 2.4104, 0.0312, 0.3891, 0.0578, 0.0808
1.200, 30, 2.3203, None, None, None, None, None
1.600, 40, 1.8651, None, None, None, None, None
2.000, 50, 1.5137, None, None, None, None, None
2.000, 50, None, 1.4877, 0.1034, 0.5652, 0.1748, 0.4549
2.400, 60, 1.0205, None, None, None, None, None
2.800, 70, 0.7393, None, None, None, None, None
3.000, 75, None, 1.0406, 0.1471, 0.6478, 0.2397, 0.4436
3.200, 80, 0.5736, None, None, None, None, None
3.600, 90, 0.4214, None, None, None, None, None
4.000, 100, 0.5049, None, None, None, None, None
4.000, 100, None, 1.0301, 0.2022, 0.6478, 0.3082, 0.7044
4.400, 110, 0.2586, None, None, None, None, None
4.800, 120, 0.3784, None, None, None, None, None
5.000, 125, None, 0.9141, 0.2645, 0.6348, 0.3734, 0.8181
5.200, 130, 0.2389, None, None, None, None, None
5.600, 140, 0.1979, None, None, None, None, None
6.000, 150, 0.2037, None, None, None, None, None
6.000, 150, None, 0.9890, 0.3128, 0.6500, 0.4223, 0.8273
6.400, 160, 0.1714, None, None, None, None, None
6.800, 170, 0.1436, None, None, None, None, None
7.000, 175, None, 1.1121, 0.3476, 0.6370, 0.4497, 0.8539
7.200, 180, 0.1458, None, None, None, None, None
7.600, 190, 0.1415, None, None, None, None, None
8.000, 200, 0.1013, None, None, None, None, None
8.000, 200, None, 1.0570, 0.3854, 0.6543, 0.4851, 0.8766
8.400, 210, 0.0961, None, None, None, None, None
8.800, 220, 0.1064, None, None, None, None, None
9.000, 225, None, 1.1762, 0.4600, 0.6630, 0.5432, 0.8977
9.200, 230, 0.0686, None, None, None, None, None
9.600, 240, 0.0588, None, None, None, None, None
10.000, 250, 0.1086, None, None, None, None, None
10.000, 250, None, 1.1692, 0.4784, 0.6739, 0.5596, 0.9082
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1692, 0.4784, 0.6739, 0.5596, 0.9082

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.05,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2209, None, None, None, None, None
0.800, 20, 2.9284, None, None, None, None, None
1.000, 25, None, 2.2132, 0.0364, 0.4600, 0.0675, 0.0734
1.200, 30, 2.4042, None, None, None, None, None
1.600, 40, 1.9144, None, None, None, None, None
2.000, 50, 1.4931, None, None, None, None, None
2.000, 50, None, 1.2339, 0.1208, 0.6644, 0.2044, 0.5054
2.400, 60, 1.0460, None, None, None, None, None
2.800, 70, 0.8532, None, None, None, None, None
3.000, 75, None, 0.7473, 0.1651, 0.7711, 0.2719, 0.6044
3.200, 80, 0.6131, None, None, None, None, None
3.600, 90, 0.4630, None, None, None, None, None
4.000, 100, 0.4532, None, None, None, None, None
4.000, 100, None, 0.6828, 0.2161, 0.7044, 0.3307, 0.7178
4.400, 110, 0.2671, None, None, None, None, None
4.800, 120, 0.3219, None, None, None, None, None
5.000, 125, None, 0.6324, 0.2453, 0.6733, 0.3596, 0.7106
5.200, 130, 0.2753, None, None, None, None, None
5.600, 140, 0.2459, None, None, None, None, None
6.000, 150, 0.2006, None, None, None, None, None
6.000, 150, None, 0.6782, 0.3648, 0.6867, 0.4765, 0.8520
6.400, 160, 0.1678, None, None, None, None, None
6.800, 170, 0.1498, None, None, None, None, None
7.000, 175, None, 0.7325, 0.4651, 0.7400, 0.5712, 0.8912
7.200, 180, 0.1532, None, None, None, None, None
7.600, 190, 0.1011, None, None, None, None, None
8.000, 200, 0.0936, None, None, None, None, None
8.000, 200, None, 0.8044, 0.5198, 0.7578, 0.6166, 0.9050
8.400, 210, 0.0647, None, None, None, None, None
8.800, 220, 0.0981, None, None, None, None, None
9.000, 225, None, 0.8014, 0.4926, 0.7444, 0.5929, 0.8966
9.200, 230, 0.0831, None, None, None, None, None
9.600, 240, 0.0588, None, None, None, None, None
10.000, 250, 0.0767, None, None, None, None, None
10.000, 250, None, 0.8746, 0.5525, 0.7600, 0.6399, 0.9167
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.8746, 0.5525, 0.7600, 0.6399, 0.9167

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.417, 10, 3.2617, None, None, None, None, None
0.833, 20, 2.9183, None, None, None, None, None
1.000, 24, None, 2.5390, 0.0222, 0.2481, 0.0408, 0.0522
1.250, 30, 2.3139, None, None, None, None, None
1.667, 40, 1.9381, None, None, None, None, None
2.000, 48, None, 1.4723, 0.1319, 0.6493, 0.2193, 0.5987
2.083, 50, 1.4168, None, None, None, None, None
2.500, 60, 0.9765, None, None, None, None, None
2.917, 70, 0.7634, None, None, None, None, None
3.000, 72, None, 1.0525, 0.1451, 0.6847, 0.2394, 0.3494
3.333, 80, 0.5580, None, None, None, None, None
3.750, 90, 0.4832, None, None, None, None, None
4.000, 96, None, 0.9870, 0.1778, 0.6231, 0.2766, 0.6520
4.167, 100, 0.3928, None, None, None, None, None
4.583, 110, 0.3540, None, None, None, None, None
5.000, 120, 0.3136, None, None, None, None, None
5.000, 120, None, 0.8897, 0.2774, 0.6325, 0.3857, 0.7800
5.417, 130, 0.2220, None, None, None, None, None
5.833, 140, 0.1924, None, None, None, None, None
6.000, 144, None, 0.8399, 0.3025, 0.6474, 0.4124, 0.7877
6.250, 150, 0.1425, None, None, None, None, None
6.667, 160, 0.1450, None, None, None, None, None
7.000, 168, None, 1.0641, 0.3878, 0.6287, 0.4797, 0.8723
7.083, 170, 0.1301, None, None, None, None, None
7.500, 180, 0.0987, None, None, None, None, None
7.917, 190, 0.0912, None, None, None, None, None
8.000, 192, None, 1.0025, 0.3797, 0.6269, 0.4729, 0.8723
8.333, 200, 0.0799, None, None, None, None, None
8.750, 210, 0.0956, None, None, None, None, None
9.000, 216, None, 1.0137, 0.4201, 0.6474, 0.5095, 0.8841
9.167, 220, 0.0731, None, None, None, None, None
9.583, 230, 0.0843, None, None, None, None, None
10.000, 240, 0.0626, None, None, None, None, None
10.000, 240, None, 1.0396, 0.4289, 0.6474, 0.5160, 0.8877
10.000, 240, None, None, None, None, None, None
10.000, 240, None, 1.0396, 0.4289, 0.6474, 0.5160, 0.8877

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2865, None, None, None, None, None
0.800, 20, 2.8068, None, None, None, None, None
1.000, 25, None, 2.4963, 0.0216, 0.2588, 0.0398, 0.0463
1.200, 30, 2.4435, None, None, None, None, None
1.600, 40, 1.9337, None, None, None, None, None
2.000, 50, 1.5553, None, None, None, None, None
2.000, 50, None, 1.5596, 0.0921, 0.6055, 0.1598, 0.4291
2.400, 60, 1.0528, None, None, None, None, None
2.800, 70, 0.8283, None, None, None, None, None
3.000, 75, None, 1.3055, 0.1407, 0.5578, 0.2247, 0.5448
3.200, 80, 0.6522, None, None, None, None, None
3.600, 90, 0.5829, None, None, None, None, None
4.000, 100, 0.5251, None, None, None, None, None
4.000, 100, None, 1.0750, 0.2038, 0.6809, 0.3137, 0.6346
4.400, 110, 0.3065, None, None, None, None, None
4.800, 120, 0.3774, None, None, None, None, None
5.000, 125, None, 0.9911, 0.2326, 0.6131, 0.3372, 0.7529
5.200, 130, 0.2861, None, None, None, None, None
5.600, 140, 0.2214, None, None, None, None, None
6.000, 150, 0.2224, None, None, None, None, None
6.000, 150, None, 1.0185, 0.2644, 0.6457, 0.3752, 0.7716
6.400, 160, 0.1595, None, None, None, None, None
6.800, 170, 0.1595, None, None, None, None, None
7.000, 175, None, 1.0971, 0.3611, 0.6533, 0.4651, 0.8532
7.200, 180, 0.1496, None, None, None, None, None
7.600, 190, 0.1212, None, None, None, None, None
8.000, 200, 0.1091, None, None, None, None, None
8.000, 200, None, 1.1010, 0.3786, 0.6658, 0.4827, 0.8579
8.400, 210, 0.0777, None, None, None, None, None
8.800, 220, 0.1432, None, None, None, None, None
9.000, 225, None, 1.1701, 0.4228, 0.6608, 0.5157, 0.8732
9.200, 230, 0.0838, None, None, None, None, None
9.600, 240, 0.0691, None, None, None, None, None
10.000, 250, 0.0991, None, None, None, None, None
10.000, 250, None, 1.1647, 0.4201, 0.6608, 0.5137, 0.8710
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1647, 0.4201, 0.6608, 0.5137, 0.8710

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2397, None, None, None, None, None
0.800, 20, 2.8780, None, None, None, None, None
1.000, 25, None, 2.2395, 0.0377, 0.3981, 0.0688, 0.0677
1.200, 30, 2.4154, None, None, None, None, None
1.600, 40, 1.9333, None, None, None, None, None
2.000, 50, 1.4688, None, None, None, None, None
2.000, 50, None, 1.2155, 0.1160, 0.6056, 0.1947, 0.3204
2.400, 60, 1.0142, None, None, None, None, None
2.800, 70, 0.9469, None, None, None, None, None
3.000, 75, None, 0.6052, 0.1596, 0.7271, 0.2617, 0.5246
3.200, 80, 0.5853, None, None, None, None, None
3.600, 90, 0.4812, None, None, None, None, None
4.000, 100, 0.4524, None, None, None, None, None
4.000, 100, None, 0.4396, 0.3311, 0.7477, 0.4590, 0.7875
4.400, 110, 0.2949, None, None, None, None, None
4.800, 120, 0.2797, None, None, None, None, None
5.000, 125, None, 0.4531, 0.2453, 0.7570, 0.3705, 0.6040
5.200, 130, 0.3211, None, None, None, None, None
5.600, 140, 0.2370, None, None, None, None, None
6.000, 150, 0.1576, None, None, None, None, None
6.000, 150, None, 0.3751, 0.4082, 0.7402, 0.5262, 0.8479
6.400, 160, 0.1736, None, None, None, None, None
6.800, 170, 0.1421, None, None, None, None, None
7.000, 175, None, 0.3789, 0.3580, 0.6953, 0.4727, 0.8187
7.200, 180, 0.1054, None, None, None, None, None
7.600, 190, 0.0915, None, None, None, None, None
8.000, 200, 0.1068, None, None, None, None, None
8.000, 200, None, 0.3834, 0.4665, 0.7421, 0.5729, 0.8759
8.400, 210, 0.0905, None, None, None, None, None
8.800, 220, 0.0889, None, None, None, None, None
9.000, 225, None, 0.3884, 0.4663, 0.7364, 0.5710, 0.8709
9.200, 230, 0.0916, None, None, None, None, None
9.600, 240, 0.0645, None, None, None, None, None
10.000, 250, 0.1026, None, None, None, None, None
10.000, 250, None, 0.3886, 0.4793, 0.7364, 0.5807, 0.8806
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.3886, 0.4793, 0.7364, 0.5807, 0.8806

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2200, None, None, None, None, None
0.800, 20, 2.8992, None, None, None, None, None
1.000, 25, None, 2.4105, 0.0314, 0.3913, 0.0582, 0.0809
1.200, 30, 2.3200, None, None, None, None, None
1.600, 40, 1.8603, None, None, None, None, None
2.000, 50, 1.5057, None, None, None, None, None
2.000, 50, None, 1.4733, 0.1055, 0.5674, 0.1779, 0.4721
2.400, 60, 1.0043, None, None, None, None, None
2.800, 70, 0.7241, None, None, None, None, None
3.000, 75, None, 1.0190, 0.1515, 0.6478, 0.2456, 0.4790
3.200, 80, 0.5545, None, None, None, None, None
3.600, 90, 0.3978, None, None, None, None, None
4.000, 100, 0.5282, None, None, None, None, None
4.000, 100, None, 1.1285, 0.1951, 0.6196, 0.2967, 0.6898
4.400, 110, 0.2608, None, None, None, None, None
4.800, 120, 0.3671, None, None, None, None, None
5.000, 125, None, 0.9330, 0.2730, 0.6326, 0.3814, 0.8280
5.200, 130, 0.2347, None, None, None, None, None
5.600, 140, 0.1827, None, None, None, None, None
6.000, 150, 0.1811, None, None, None, None, None
6.000, 150, None, 0.9156, 0.3140, 0.6348, 0.4201, 0.8471
6.400, 160, 0.1478, None, None, None, None, None
6.800, 170, 0.1337, None, None, None, None, None
7.000, 175, None, 1.0925, 0.3420, 0.6304, 0.4434, 0.8403
7.200, 180, 0.1332, None, None, None, None, None
7.600, 190, 0.1077, None, None, None, None, None
8.000, 200, 0.0961, None, None, None, None, None
8.000, 200, None, 1.0433, 0.4072, 0.6630, 0.5045, 0.8785
8.400, 210, 0.0905, None, None, None, None, None
8.800, 220, 0.0916, None, None, None, None, None
9.000, 225, None, 1.0945, 0.4443, 0.6587, 0.5306, 0.9022
9.200, 230, 0.0657, None, None, None, None, None
9.600, 240, 0.0657, None, None, None, None, None
10.000, 250, 0.1048, None, None, None, None, None
10.000, 250, None, 1.1000, 0.4535, 0.6565, 0.5364, 0.9051
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1000, 0.4535, 0.6565, 0.5364, 0.9051

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "cosine",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2209, None, None, None, None, None
0.800, 20, 2.9283, None, None, None, None, None
1.000, 25, None, 2.2132, 0.0364, 0.4600, 0.0675, 0.0734
1.200, 30, 2.4041, None, None, None, None, None
1.600, 40, 1.9090, None, None, None, None, None
2.000, 50, 1.4819, None, None, None, None, None
2.000, 50, None, 1.2144, 0.1228, 0.6711, 0.2076, 0.5127
2.400, 60, 1.0251, None, None, None, None, None
2.800, 70, 0.8383, None, None, None, None, None
3.000, 75, None, 0.7329, 0.1665, 0.7689, 0.2737, 0.6056
3.200, 80, 0.5856, None, None, None, None, None
3.600, 90, 0.4410, None, None, None, None, None
4.000, 100, 0.4468, None, None, None, None, None
4.000, 100, None, 0.6887, 0.2262, 0.6911, 0.3408, 0.7385
4.400, 110, 0.2656, None, None, None, None, None
4.800, 120, 0.3248, None, None, None, None, None
5.000, 125, None, 0.6575, 0.2637, 0.6844, 0.3807, 0.7204
5.200, 130, 0.2625, None, None, None, None, None
5.600, 140, 0.2162, None, None, None, None, None
6.000, 150, 0.1736, None, None, None, None, None
6.000, 150, None, 0.6899, 0.3800, 0.6822, 0.4881, 0.8636
6.400, 160, 0.1442, None, None, None, None, None
6.800, 170, 0.1380, None, None, None, None, None
7.000, 175, None, 0.7215, 0.4337, 0.7200, 0.5414, 0.8807
7.200, 180, 0.1435, None, None, None, None, None
7.600, 190, 0.0872, None, None, None, None, None
8.000, 200, 0.0744, None, None, None, None, None
8.000, 200, None, 0.7864, 0.4993, 0.7400, 0.5962, 0.9015
8.400, 210, 0.0647, None, None, None, None, None
8.800, 220, 0.0949, None, None, None, None, None
9.000, 225, None, 0.7989, 0.4947, 0.7311, 0.5901, 0.8997
9.200, 230, 0.0800, None, None, None, None, None
9.600, 240, 0.0653, None, None, None, None, None
10.000, 250, 0.0788, None, None, None, None, None
10.000, 250, None, 0.8082, 0.5084, 0.7400, 0.6027, 0.9035
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.8082, 0.5084, 0.7400, 0.6027, 0.9035

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 1
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.417, 10, 3.2617, None, None, None, None, None
0.833, 20, 2.9183, None, None, None, None, None
1.000, 24, None, 2.5390, 0.0222, 0.2481, 0.0408, 0.0522
1.250, 30, 2.3141, None, None, None, None, None
1.667, 40, 1.9430, None, None, None, None, None
2.000, 48, None, 1.5032, 0.1297, 0.6455, 0.2160, 0.5988
2.083, 50, 1.4337, None, None, None, None, None
2.500, 60, 1.0016, None, None, None, None, None
2.917, 70, 0.7923, None, None, None, None, None
3.000, 72, None, 1.0643, 0.1406, 0.6716, 0.2326, 0.3447
3.333, 80, 0.5864, None, None, None, None, None
3.750, 90, 0.4970, None, None, None, None, None
4.000, 96, None, 1.0002, 0.1735, 0.6306, 0.2721, 0.6479
4.167, 100, 0.4084, None, None, None, None, None
4.583, 110, 0.3769, None, None, None, None, None
5.000, 120, 0.3433, None, None, None, None, None
5.000, 120, None, 0.8598, 0.2591, 0.6138, 0.3643, 0.7783
5.417, 130, 0.2499, None, None, None, None, None
5.833, 140, 0.1908, None, None, None, None, None
6.000, 144, None, 0.8299, 0.2680, 0.6474, 0.3790, 0.7408
6.250, 150, 0.1632, None, None, None, None, None
6.667, 160, 0.1782, None, None, None, None, None
7.000, 168, None, 1.0294, 0.3788, 0.6119, 0.4679, 0.8754
7.083, 170, 0.1544, None, None, None, None, None
7.500, 180, 0.1116, None, None, None, None, None
7.917, 190, 0.0968, None, None, None, None, None
8.000, 192, None, 1.0531, 0.4188, 0.6493, 0.5091, 0.8870
8.333, 200, 0.0844, None, None, None, None, None
8.750, 210, 0.0974, None, None, None, None, None
9.000, 216, None, 1.1047, 0.4471, 0.6381, 0.5257, 0.9004
9.167, 220, 0.0748, None, None, None, None, None
9.583, 230, 0.0757, None, None, None, None, None
10.000, 240, 0.0647, None, None, None, None, None
10.000, 240, None, 1.1534, 0.4507, 0.6399, 0.5289, 0.9011
10.000, 240, None, None, None, None, None, None
10.000, 240, None, 1.1534, 0.4507, 0.6399, 0.5289, 0.9011

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 2
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2865, None, None, None, None, None
0.800, 20, 2.8068, None, None, None, None, None
1.000, 25, None, 2.4964, 0.0216, 0.2588, 0.0398, 0.0463
1.200, 30, 2.4438, None, None, None, None, None
1.600, 40, 1.9381, None, None, None, None, None
2.000, 50, 1.5726, None, None, None, None, None
2.000, 50, None, 1.5762, 0.0936, 0.6156, 0.1625, 0.4390
2.400, 60, 1.0831, None, None, None, None, None
2.800, 70, 0.8449, None, None, None, None, None
3.000, 75, None, 1.2978, 0.1375, 0.5704, 0.2216, 0.5376
3.200, 80, 0.6716, None, None, None, None, None
3.600, 90, 0.6185, None, None, None, None, None
4.000, 100, 0.5647, None, None, None, None, None
4.000, 100, None, 1.0943, 0.2114, 0.6683, 0.3213, 0.7023
4.400, 110, 0.3475, None, None, None, None, None
4.800, 120, 0.4022, None, None, None, None, None
5.000, 125, None, 0.9846, 0.2231, 0.6156, 0.3275, 0.7476
5.200, 130, 0.3079, None, None, None, None, None
5.600, 140, 0.2369, None, None, None, None, None
6.000, 150, 0.2486, None, None, None, None, None
6.000, 150, None, 0.9873, 0.2716, 0.6633, 0.3854, 0.7837
6.400, 160, 0.1792, None, None, None, None, None
6.800, 170, 0.1874, None, None, None, None, None
7.000, 175, None, 1.0615, 0.3411, 0.6658, 0.4511, 0.8291
7.200, 180, 0.1602, None, None, None, None, None
7.600, 190, 0.1302, None, None, None, None, None
8.000, 200, 0.1239, None, None, None, None, None
8.000, 200, None, 1.1374, 0.4148, 0.6608, 0.5097, 0.8687
8.400, 210, 0.0834, None, None, None, None, None
8.800, 220, 0.1512, None, None, None, None, None
9.000, 225, None, 1.1538, 0.4044, 0.6533, 0.4995, 0.8719
9.200, 230, 0.0804, None, None, None, None, None
9.600, 240, 0.0705, None, None, None, None, None
10.000, 250, 0.0948, None, None, None, None, None
10.000, 250, None, 1.1783, 0.4235, 0.6533, 0.5138, 0.8772
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1783, 0.4235, 0.6533, 0.5138, 0.8772

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 3
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2397, None, None, None, None, None
0.800, 20, 2.8779, None, None, None, None, None
1.000, 25, None, 2.2394, 0.0377, 0.3981, 0.0689, 0.0677
1.200, 30, 2.4155, None, None, None, None, None
1.600, 40, 1.9349, None, None, None, None, None
2.000, 50, 1.4803, None, None, None, None, None
2.000, 50, None, 1.2321, 0.1134, 0.6075, 0.1911, 0.3201
2.400, 60, 1.0348, None, None, None, None, None
2.800, 70, 0.9655, None, None, None, None, None
3.000, 75, None, 0.6270, 0.1554, 0.7271, 0.2561, 0.5168
3.200, 80, 0.6140, None, None, None, None, None
3.600, 90, 0.5103, None, None, None, None, None
4.000, 100, 0.4803, None, None, None, None, None
4.000, 100, None, 0.4694, 0.3592, 0.7607, 0.4880, 0.8389
4.400, 110, 0.3318, None, None, None, None, None
4.800, 120, 0.3180, None, None, None, None, None
5.000, 125, None, 0.4524, 0.2373, 0.7607, 0.3618, 0.6022
5.200, 130, 0.3475, None, None, None, None, None
5.600, 140, 0.2536, None, None, None, None, None
6.000, 150, 0.1756, None, None, None, None, None
6.000, 150, None, 0.3907, 0.4024, 0.7477, 0.5232, 0.8505
6.400, 160, 0.1918, None, None, None, None, None
6.800, 170, 0.1544, None, None, None, None, None
7.000, 175, None, 0.3877, 0.3677, 0.7271, 0.4884, 0.7965
7.200, 180, 0.1272, None, None, None, None, None
7.600, 190, 0.0977, None, None, None, None, None
8.000, 200, 0.1173, None, None, None, None, None
8.000, 200, None, 0.4119, 0.4660, 0.7421, 0.5725, 0.8731
8.400, 210, 0.0978, None, None, None, None, None
8.800, 220, 0.1016, None, None, None, None, None
9.000, 225, None, 0.3975, 0.4450, 0.7178, 0.5494, 0.8645
9.200, 230, 0.0896, None, None, None, None, None
9.600, 240, 0.0676, None, None, None, None, None
10.000, 250, 0.1082, None, None, None, None, None
10.000, 250, None, 0.4162, 0.5180, 0.7514, 0.6133, 0.9010
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.4162, 0.5180, 0.7514, 0.6133, 0.9010

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 4
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2200, None, None, None, None, None
0.800, 20, 2.8992, None, None, None, None, None
1.000, 25, None, 2.4104, 0.0314, 0.3913, 0.0582, 0.0811
1.200, 30, 2.3203, None, None, None, None, None
1.600, 40, 1.8652, None, None, None, None, None
2.000, 50, 1.5138, None, None, None, None, None
2.000, 50, None, 1.4879, 0.1029, 0.5630, 0.1740, 0.4546
2.400, 60, 1.0206, None, None, None, None, None
2.800, 70, 0.7394, None, None, None, None, None
3.000, 75, None, 1.0406, 0.1471, 0.6478, 0.2397, 0.4442
3.200, 80, 0.5734, None, None, None, None, None
3.600, 90, 0.4213, None, None, None, None, None
4.000, 100, 0.5048, None, None, None, None, None
4.000, 100, None, 1.0298, 0.2020, 0.6478, 0.3080, 0.7041
4.400, 110, 0.2587, None, None, None, None, None
4.800, 120, 0.3778, None, None, None, None, None
5.000, 125, None, 0.9131, 0.2639, 0.6304, 0.3720, 0.8169
5.200, 130, 0.2385, None, None, None, None, None
5.600, 140, 0.1964, None, None, None, None, None
6.000, 150, 0.2039, None, None, None, None, None
6.000, 150, None, 0.9904, 0.3148, 0.6522, 0.4246, 0.8277
6.400, 160, 0.1704, None, None, None, None, None
6.800, 170, 0.1437, None, None, None, None, None
7.000, 175, None, 1.1156, 0.3492, 0.6370, 0.4511, 0.8551
7.200, 180, 0.1475, None, None, None, None, None
7.600, 190, 0.1396, None, None, None, None, None
8.000, 200, 0.1022, None, None, None, None, None
8.000, 200, None, 1.0695, 0.3974, 0.6652, 0.4976, 0.8773
8.400, 210, 0.0922, None, None, None, None, None
8.800, 220, 0.1052, None, None, None, None, None
9.000, 225, None, 1.1477, 0.4639, 0.6696, 0.5480, 0.8983
9.200, 230, 0.0682, None, None, None, None, None
9.600, 240, 0.0585, None, None, None, None, None
10.000, 250, 0.1071, None, None, None, None, None
10.000, 250, None, 1.1506, 0.4747, 0.6717, 0.5563, 0.9067
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 1.1506, 0.4747, 0.6717, 0.5563, 0.9067

# Starting new run with hyperparams:
{
  "learning_rate": 5e-05,
  "batch_size": 2,
  "epochs": 10,
  "weight_decay": 0.1,
  "dropout_rate": 0.05,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.1,
  "lr_scheduler": "linear",
  "fold": 5
}
epoch,step,train_loss,eval_loss,eval_precision,eval_recall,eval_f1,eval_accuracy
0.400, 10, 3.2209, None, None, None, None, None
0.800, 20, 2.9283, None, None, None, None, None
1.000, 25, None, 2.2131, 0.0362, 0.4578, 0.0672, 0.0733
1.200, 30, 2.4042, None, None, None, None, None
1.600, 40, 1.9145, None, None, None, None, None
2.000, 50, 1.4932, None, None, None, None, None
2.000, 50, None, 1.2339, 0.1211, 0.6667, 0.2050, 0.5052
2.400, 60, 1.0460, None, None, None, None, None
2.800, 70, 0.8533, None, None, None, None, None
3.000, 75, None, 0.7472, 0.1650, 0.7711, 0.2718, 0.6042
3.200, 80, 0.6132, None, None, None, None, None
3.600, 90, 0.4631, None, None, None, None, None
4.000, 100, 0.4531, None, None, None, None, None
4.000, 100, None, 0.6826, 0.2161, 0.7044, 0.3307, 0.7164
4.400, 110, 0.2672, None, None, None, None, None
4.800, 120, 0.3222, None, None, None, None, None
5.000, 125, None, 0.6320, 0.2453, 0.6733, 0.3596, 0.7106
5.200, 130, 0.2753, None, None, None, None, None
5.600, 140, 0.2459, None, None, None, None, None
6.000, 150, 0.2009, None, None, None, None, None
6.000, 150, None, 0.6773, 0.3709, 0.6867, 0.4817, 0.8550
6.400, 160, 0.1690, None, None, None, None, None
6.800, 170, 0.1490, None, None, None, None, None
7.000, 175, None, 0.7388, 0.4631, 0.7400, 0.5697, 0.8908
7.200, 180, 0.1550, None, None, None, None, None
7.600, 190, 0.1017, None, None, None, None, None
8.000, 200, 0.0947, None, None, None, None, None
8.000, 200, None, 0.8061, 0.5184, 0.7511, 0.6134, 0.9063
8.400, 210, 0.0646, None, None, None, None, None
8.800, 220, 0.0997, None, None, None, None, None
9.000, 225, None, 0.7959, 0.4855, 0.7422, 0.5870, 0.8957
9.200, 230, 0.0812, None, None, None, None, None
9.600, 240, 0.0578, None, None, None, None, None
10.000, 250, 0.0780, None, None, None, None, None
10.000, 250, None, 0.8736, 0.5543, 0.7600, 0.6410, 0.9169
10.000, 250, None, None, None, None, None, None
10.000, 250, None, 0.8736, 0.5543, 0.7600, 0.6410, 0.9169

**Best Params across all folds: {'learning_rate': 5e-05, 'batch_size': 1, 'epochs': 10, 'weight_decay': 0.05, 'dropout_rate': 0.05, 'gradient_accumulation_steps': 1, 'warmup_ratio': 0.1, 'lr_scheduler': 'linear', 'fold': 5} with avg F1: 0.6449**
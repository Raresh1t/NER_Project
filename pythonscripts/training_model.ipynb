{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash-attn\n",
      "  Using cached flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\magnu\\\\AppData\\\\Local\\\\Temp\\\\pip-install-_h0lj359\\\\flash-attn_a64e364bab4b4bda827435c2541f476a\\\\csrc\\\\composable_kernel\\\\library\\\\include\\\\ck\\\\library\\\\tensor_operation_instance\\\\gpu\\\\grouped_conv_bwd_weight\\\\device_grouped_conv_bwd_weight_two_stage_xdl_instance.hpp'\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#! pip install seqeval\n",
    "#! pip install evaluate\n",
    "#! pip install pandas\n",
    "#! pip install datasets\n",
    "#! pip install torch\n",
    "#! pip install transformers\n",
    "#! pip install scikit-learn\n",
    "#! pip install ninja\n",
    "#! pip install flash-attn\n",
    "#! pip install packaging\n",
    "#! pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import evaluate\n",
    "import seqeval\n",
    "import accelerate\n",
    "import transformers\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from flash_attn.flash_attention import FlashAttention\n",
    "# Flash Attention for faster training\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True  # Enable TF32 for better performance\n",
    "torch.backends.cudnn.benchmark = True  # Enable CuDNN auto-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "DATA_PATH = \"tokenized_ner_data_6.json\"\n",
    "with open(DATA_PATH, \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_list(data)\n",
    "testing_dataset = Dataset.from_list(data)\n",
    "train_dataset, eval_dataset = dataset.train_test_split(test_size=0.2).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'labels', 'input_ids', 'attention_mask', 'word_ids'],\n",
      "        num_rows: 48\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'labels', 'input_ids', 'attention_mask', 'word_ids'],\n",
      "        num_rows: 13\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "#print(train_dataset)\n",
    "#print(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-CVE': 0, 'B-Event': 1, 'B-LOC': 2, 'B-MAL-ORG': 3, 'B-MISC': 4, 'B-Malware': 5, 'B-ORG': 6, 'B-PER': 7, 'B-Software': 8, 'I-CVE': 9, 'I-Event': 10, 'I-LOC': 11, 'I-MAL-ORG': 12, 'I-MISC': 13, 'I-Malware': 14, 'I-ORG': 15, 'I-PER': 16, 'I-Software': 17, 'O': 18}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = set(label for entry in dataset for label in entry[\"labels\"])\n",
    "label2id = {label: i for i, label in enumerate(sorted(unique_labels))}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "print(label2id)  # Mapping of labels to IDs\n",
    "\n",
    "# Convert text labels to integer IDs\n",
    "#data[\"labels\"] = [label2id[label] for label in data[\"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model\n",
    "MODEL_NAME = \"google-bert/bert-base-cased\"\n",
    "#\"answerdotai/ModernBERT-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Enable Flash Attention in the model (if applicable)\n",
    "#model.config.use_flash_attention = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3165df60e3b84a33be84b5fb1cdf12a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_tokens_and_labels(data):\n",
    "    \"\"\"Convert tokenized text into IDs and align labels.\"\"\"\n",
    "    data[\"input_ids\"] = tokenizer.convert_tokens_to_ids(data[\"tokens\"])\n",
    "    data[\"attention_mask\"] = [1] * len(data[\"input_ids\"])  # Mask for all tokens\n",
    "    \n",
    "    # Infer word_ids manually\n",
    "    word_ids = []\n",
    "    word_idx = -1 # Initialize\n",
    "    for token in data[\"tokens\"]:\n",
    "        if token in [\"[CLS]\", \"[SEP]\"]:\n",
    "            word_ids.append(None)\n",
    "        elif token.startswith(\"##\"):\n",
    "            word_ids.append(word_idx)\n",
    "        else:\n",
    "            word_idx += 1\n",
    "            word_ids.append(word_idx)\n",
    "\n",
    "    data[\"word_ids\"] = word_ids\n",
    "    \n",
    "    # Convert text labels to integer IDs\n",
    "    data[\"labels\"] = [label2id[label] for label in data[\"labels\"]]\n",
    "\n",
    "    return data\n",
    "\n",
    "# Apply transformation to dataset\n",
    "dataset = dataset.map(process_tokens_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['[CLS]', 'A', 'new', 'ransom', '##ware', '-', 'as', '-', 'a', '-', 'service', '(', 'Ra', '##a', '##S', ')', 'operation', 'named', 'C', '##ica', '##da', '##33', '##01', 'has', 'already', 'listed', '19', 'victims', 'on', 'its', 'ex', '##tor', '##tion', 'portal', ',', 'as', 'it', 'quickly', 'attacked', 'companies', 'worldwide', '.', 'The', 'new', 'c', '##y', '##ber', '##c', '##rim', '##e', 'operation', 'is', 'named', 'after', 'the', 'mysterious', '2012', '-', '2014', 'online', '/', 'real', '-', 'world', 'game', 'that', 'involved', 'elaborate', 'cry', '##pt', '##ographic', 'puzzles', 'and', 'used', 'the', 'same', 'logo', 'for', 'promotion', 'on', 'c', '##y', '##ber', '##c', '##rim', '##e', 'forums', '.', 'However', ',', 'there', \"'\", 's', 'no', 'connection', 'between', 'the', 'two', ',', 'and', 'the', 'legitimate', 'project', 'has', 'issued', 'a', 'statement', 'to', 're', '##nounce', 'any', 'association', 'and', 'con', '##de', '##m', '##n', 'the', 'ransom', '##ware', 'operators', \"'\", 'actions', '.', 'The', 'C', '##ica', '##da', '##33', '##01', 'Ra', '##a', '##S', 'first', 'began', 'promoting', 'the', 'operation', 'and', 'recruiting', 'affiliates', 'on', 'June', '29', ',', '202', '##4', ',', 'in', 'a', 'forum', 'post', 'to', 'the', 'ransom', '##ware', 'and', 'c', '##y', '##ber', '##c', '##rim', '##e', 'forum', 'known', 'as', 'RAM', '##P', '.', 'However', ',', 'B', '##lee', '##ping', '##C', '##om', '##pute', '##r', 'is', 'aware', 'of', 'C', '##ica', '##da', 'attacks', 'as', 'early', 'as', 'June', '6', ',', 'indicating', 'that', 'the', 'gang', 'was', 'operating', 'independently', 'before', 'attempting', 'to', 'recruit', 'affiliates', '.', 'Like', 'other', 'ransom', '##ware', 'operations', ',', 'C', '##ica', '##da', '##33', '##01', 'conducts', 'double', '-', 'ex', '##tor', '##tion', 'tactics', 'where', 'they', 'breach', 'corporate', 'networks', ',', 'steal', 'data', ',', 'and', 'then', 'en', '##c', '##ry', '##pt', 'devices', '.', 'The', 'encryption', 'key', 'and', 'threats', 'to', 'leak', 'stolen', 'data', 'are', 'then', 'used', 'as', 'leverage', 'to', 'scare', 'victims', 'into', 'paying', 'a', 'ransom', '.', 'The', 'threat', 'actors', 'operate', 'a', 'data', 'leak', 'site', 'that', 'is', 'used', 'as', 'part', 'of', 'their', 'double', '-', 'ex', '##tor', '##tion', 'scheme', '.', 'An', 'analysis', 'of', 'the', 'new', 'ma', '##l', '##ware', 'by', 'True', '##se', '##c', 'revealed', 'significant', 'overlap', '##s', 'between', 'C', '##ica', '##da', '##33', '##01', 'and', 'AL', '##P', '##H', '##V', '/', 'Black', '##C', '##at', ',', 'indicating', 'a', 'possible', 're', '##brand', 'or', 'a', 'fork', 'created', 'by', 'former', 'AL', '##P', '##H', '##V', \"'\", 's', 'core', 'team', 'members', '.', 'This', 'is', 'based', 'on', 'the', 'fact', 'that', ':', 'For', 'context', ',', 'AL', '##P', '##H', '##V', 'performed', 'an', 'exit', 's', '##cam', 'in', 'early', 'March', '202', '##4', 'involving', 'fake', 'claims', 'about', 'an', 'FBI', 'take', '##down', 'operation', 'after', 'they', 'stole', 'a', 'massive', '$', '22', 'million', 'payment', 'from', 'Change', 'Healthcare', 'from', 'one', 'of', 'their', 'affiliates', '.', 'True', '##se', '##c', 'has', 'also', 'found', 'indication', '##s', 'that', 'the', 'C', '##ica', '##da', '##33', '##01', 'ransom', '##ware', 'operation', 'may', 'partner', 'with', 'or', 'utilize', 'the', 'B', '##ru', '##tus', 'b', '##ot', '##net', 'for', 'initial', 'access', 'to', 'corporate', 'networks', '.', 'That', 'b', '##ot', '##net', 'was', 'previously', 'associated', 'with', 'global', '-', 'scale', 'VP', '##N', 'br', '##ute', '-', 'forcing', 'activities', 'targeting', 'C', '##isco', ',', 'Fort', '##inet', ',', 'Pa', '##lo', 'Alto', ',', 'and', 'Sonic', '##W', '##all', 'appliances', '.', 'It', \"'\", 's', 'worth', 'noting', 'that', 'the', 'B', '##ru', '##tus', 'activity', 'was', 'first', 'spotted', 'two', 'weeks', 'after', 'AL', '##P', '##H', '##V', 'shut', 'down', 'operations', ',', 'so', 'the', 'link', 'between', 'the', 'two', 'groups', 'still', 'stands', 'in', 'terms', 'of', 'timeline', '##s', '.', 'C', '##ica', '##da', '##33', '##01', 'is', 'a', 'R', '##ust', '-', 'based', '[SEP]'], 'labels': [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 3, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 3, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 6, 15, 15, 15, 15, 15, 15, 18, 18, 18, 3, 12, 12, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 3, 12, 12, 12, 12, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 6, 15, 15, 18, 18, 18, 18, 18, 3, 12, 12, 12, 12, 18, 3, 12, 12, 12, 18, 3, 12, 12, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 3, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 3, 12, 12, 12, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 6, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 6, 15, 18, 18, 18, 18, 18, 18, 6, 15, 15, 18, 18, 18, 18, 18, 18, 18, 3, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18, 18, 18, 18, 5, 14, 14, 14, 14, 14, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 6, 15, 18, 6, 15, 18, 6, 15, 15, 18, 18, 6, 15, 15, 18, 18, 18, 18, 18, 18, 18, 18, 18, 3, 12, 12, 18, 18, 18, 18, 18, 18, 18, 6, 15, 15, 15, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 3, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18, 18], 'input_ids': [101, 138, 1207, 25057, 7109, 118, 1112, 118, 170, 118, 1555, 113, 16890, 1161, 1708, 114, 2805, 1417, 140, 4578, 1810, 23493, 24400, 1144, 1640, 2345, 1627, 5256, 1113, 1157, 4252, 2772, 2116, 10823, 117, 1112, 1122, 1976, 3623, 2557, 4529, 119, 1109, 1207, 172, 1183, 3169, 1665, 10205, 1162, 2805, 1110, 1417, 1170, 1103, 8198, 1368, 118, 1387, 3294, 120, 1842, 118, 1362, 1342, 1115, 2017, 9427, 5354, 6451, 9597, 22747, 1105, 1215, 1103, 1269, 7998, 1111, 4166, 1113, 172, 1183, 3169, 1665, 10205, 1162, 25438, 119, 1438, 117, 1175, 112, 188, 1185, 3797, 1206, 1103, 1160, 117, 1105, 1103, 11582, 1933, 1144, 3010, 170, 4195, 1106, 1231, 25196, 1251, 3852, 1105, 14255, 2007, 1306, 1179, 1103, 25057, 7109, 9298, 112, 3721, 119, 1109, 140, 4578, 1810, 23493, 24400, 16890, 1161, 1708, 1148, 1310, 7495, 1103, 2805, 1105, 16226, 20795, 1113, 1340, 1853, 117, 17881, 1527, 117, 1107, 170, 13912, 2112, 1106, 1103, 25057, 7109, 1105, 172, 1183, 3169, 1665, 10205, 1162, 13912, 1227, 1112, 20898, 2101, 119, 1438, 117, 139, 6894, 2624, 1658, 4165, 22662, 1197, 1110, 4484, 1104, 140, 4578, 1810, 3690, 1112, 1346, 1112, 1340, 127, 117, 7713, 1115, 1103, 6939, 1108, 3389, 8942, 1196, 6713, 1106, 14240, 20795, 119, 2409, 1168, 25057, 7109, 2500, 117, 140, 4578, 1810, 23493, 24400, 19706, 2702, 118, 4252, 2772, 2116, 10524, 1187, 1152, 13275, 6214, 6379, 117, 8991, 2233, 117, 1105, 1173, 4035, 1665, 1616, 6451, 5197, 119, 1109, 26463, 2501, 1105, 8657, 1106, 19299, 7251, 2233, 1132, 1173, 1215, 1112, 24228, 1106, 13671, 5256, 1154, 6573, 170, 25057, 119, 1109, 4433, 5681, 4732, 170, 2233, 19299, 1751, 1115, 1110, 1215, 1112, 1226, 1104, 1147, 2702, 118, 4252, 2772, 2116, 5471, 119, 1760, 3622, 1104, 1103, 1207, 12477, 1233, 7109, 1118, 7817, 2217, 1665, 3090, 2418, 19235, 1116, 1206, 140, 4578, 1810, 23493, 24400, 1105, 18589, 2101, 3048, 2559, 120, 2117, 1658, 2980, 117, 7713, 170, 1936, 1231, 25123, 1137, 170, 13097, 1687, 1118, 1393, 18589, 2101, 3048, 2559, 112, 188, 4160, 1264, 1484, 119, 1188, 1110, 1359, 1113, 1103, 1864, 1115, 131, 1370, 5618, 117, 18589, 2101, 3048, 2559, 1982, 1126, 6300, 188, 24282, 1107, 1346, 1345, 17881, 1527, 5336, 8406, 3711, 1164, 1126, 8099, 1321, 5455, 2805, 1170, 1152, 10566, 170, 4672, 109, 1659, 1550, 7727, 1121, 9091, 22993, 1121, 1141, 1104, 1147, 20795, 119, 7817, 2217, 1665, 1144, 1145, 1276, 12754, 1116, 1115, 1103, 140, 4578, 1810, 23493, 24400, 25057, 7109, 2805, 1336, 3547, 1114, 1137, 17573, 1103, 139, 5082, 4814, 171, 3329, 6097, 1111, 3288, 2469, 1106, 6214, 6379, 119, 1337, 171, 3329, 6097, 1108, 2331, 2628, 1114, 4265, 118, 3418, 23659, 2249, 9304, 6140, 118, 6524, 2619, 15141, 140, 21097, 117, 3144, 27411, 117, 19585, 2858, 17762, 117, 1105, 16202, 2924, 5727, 26498, 119, 1135, 112, 188, 3869, 9095, 1115, 1103, 139, 5082, 4814, 3246, 1108, 1148, 6910, 1160, 2277, 1170, 18589, 2101, 3048, 2559, 3210, 1205, 2500, 117, 1177, 1103, 5088, 1206, 1103, 1160, 2114, 1253, 4061, 1107, 2538, 1104, 21169, 1116, 119, 140, 4578, 1810, 23493, 24400, 1110, 170, 155, 8954, 118, 1359, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'word_ids': [None, 0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 11, 12, 13, 14, 14, 14, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 34, 34, 34, 34, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 53, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 63, 63, 63, 63, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 86, 87, 88, 89, 90, 90, 90, 90, 91, 92, 92, 93, 94, 95, 96, 97, 98, 98, 98, 98, 98, 99, 99, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 112, 113, 114, 115, 116, 117, 118, 119, 120, 120, 121, 122, 122, 122, 122, 122, 122, 123, 124, 125, 126, 126, 127, 128, 129, 130, 130, 130, 130, 130, 130, 130, 131, 132, 133, 134, 134, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 157, 158, 159, 160, 160, 160, 160, 160, 161, 162, 163, 164, 164, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 177, 177, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 219, 219, 220, 221, 222, 223, 224, 225, 226, 227, 227, 227, 228, 229, 229, 229, 230, 231, 232, 232, 233, 234, 234, 234, 234, 234, 235, 236, 236, 236, 236, 237, 238, 238, 238, 239, 240, 241, 242, 243, 243, 244, 245, 246, 247, 248, 249, 250, 250, 250, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 268, 268, 268, 269, 270, 271, 272, 272, 273, 274, 275, 276, 276, 277, 278, 279, 280, 281, 282, 283, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 303, 303, 304, 305, 306, 307, 307, 308, 309, 310, 310, 310, 310, 310, 311, 311, 312, 313, 314, 315, 316, 317, 318, 319, 319, 319, 320, 320, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 329, 329, 330, 331, 332, 333, 334, 335, 336, 337, 337, 338, 338, 339, 340, 341, 342, 343, 343, 344, 345, 345, 346, 347, 347, 348, 349, 350, 351, 351, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 361, 361, 362, 363, 364, 365, 366, 367, 368, 369, 369, 369, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 386, 387, 388, 388, 388, 388, 388, 389, 390, 391, 391, 392, 393, None]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: Label 18, Word ID None\n",
      "Index 1: Label 18, Word ID 0\n",
      "Index 2: Label 18, Word ID 1\n",
      "Index 3: Label 18, Word ID 2\n",
      "Index 4: Label 18, Word ID 2\n",
      "Index 5: Label 18, Word ID 3\n",
      "Index 6: Label 18, Word ID 4\n",
      "Index 7: Label 18, Word ID 5\n",
      "Index 8: Label 18, Word ID 6\n",
      "Index 9: Label 18, Word ID 7\n",
      "Index 10: Label 18, Word ID 8\n",
      "Index 11: Label 18, Word ID 9\n",
      "Index 12: Label 18, Word ID 10\n",
      "Index 13: Label 18, Word ID 10\n",
      "Index 14: Label 18, Word ID 10\n",
      "Index 15: Label 18, Word ID 11\n",
      "Index 16: Label 18, Word ID 12\n",
      "Index 17: Label 18, Word ID 13\n",
      "Index 18: Label 3, Word ID 14\n",
      "Index 19: Label 12, Word ID 14\n",
      "Index 20: Label 12, Word ID 14\n",
      "Index 21: Label 12, Word ID 14\n",
      "Index 22: Label 12, Word ID 14\n",
      "Index 23: Label 18, Word ID 15\n",
      "Index 24: Label 18, Word ID 16\n",
      "Index 25: Label 18, Word ID 17\n",
      "Index 26: Label 18, Word ID 18\n",
      "Index 27: Label 18, Word ID 19\n",
      "Index 28: Label 18, Word ID 20\n",
      "Index 29: Label 18, Word ID 21\n",
      "Index 30: Label 18, Word ID 22\n",
      "Index 31: Label 18, Word ID 22\n",
      "Index 32: Label 18, Word ID 22\n",
      "Index 33: Label 18, Word ID 23\n",
      "Index 34: Label 18, Word ID 24\n",
      "Index 35: Label 18, Word ID 25\n",
      "Index 36: Label 18, Word ID 26\n",
      "Index 37: Label 18, Word ID 27\n",
      "Index 38: Label 18, Word ID 28\n",
      "Index 39: Label 18, Word ID 29\n",
      "Index 40: Label 18, Word ID 30\n",
      "Index 41: Label 18, Word ID 31\n",
      "Index 42: Label 18, Word ID 32\n",
      "Index 43: Label 18, Word ID 33\n",
      "Index 44: Label 18, Word ID 34\n",
      "Index 45: Label 18, Word ID 34\n",
      "Index 46: Label 18, Word ID 34\n",
      "Index 47: Label 18, Word ID 34\n",
      "Index 48: Label 18, Word ID 34\n",
      "Index 49: Label 18, Word ID 34\n",
      "Index 50: Label 18, Word ID 35\n",
      "Index 51: Label 18, Word ID 36\n",
      "Index 52: Label 18, Word ID 37\n",
      "Index 53: Label 18, Word ID 38\n",
      "Index 54: Label 18, Word ID 39\n",
      "Index 55: Label 18, Word ID 40\n",
      "Index 56: Label 18, Word ID 41\n",
      "Index 57: Label 18, Word ID 42\n",
      "Index 58: Label 18, Word ID 43\n",
      "Index 59: Label 18, Word ID 44\n",
      "Index 60: Label 18, Word ID 45\n",
      "Index 61: Label 18, Word ID 46\n",
      "Index 62: Label 18, Word ID 47\n",
      "Index 63: Label 18, Word ID 48\n",
      "Index 64: Label 18, Word ID 49\n",
      "Index 65: Label 18, Word ID 50\n",
      "Index 66: Label 18, Word ID 51\n",
      "Index 67: Label 18, Word ID 52\n",
      "Index 68: Label 18, Word ID 53\n",
      "Index 69: Label 18, Word ID 53\n",
      "Index 70: Label 18, Word ID 53\n",
      "Index 71: Label 18, Word ID 54\n",
      "Index 72: Label 18, Word ID 55\n",
      "Index 73: Label 18, Word ID 56\n",
      "Index 74: Label 18, Word ID 57\n",
      "Index 75: Label 18, Word ID 58\n",
      "Index 76: Label 18, Word ID 59\n",
      "Index 77: Label 18, Word ID 60\n",
      "Index 78: Label 18, Word ID 61\n",
      "Index 79: Label 18, Word ID 62\n",
      "Index 80: Label 18, Word ID 63\n",
      "Index 81: Label 18, Word ID 63\n",
      "Index 82: Label 18, Word ID 63\n",
      "Index 83: Label 18, Word ID 63\n",
      "Index 84: Label 18, Word ID 63\n",
      "Index 85: Label 18, Word ID 63\n",
      "Index 86: Label 18, Word ID 64\n",
      "Index 87: Label 18, Word ID 65\n",
      "Index 88: Label 18, Word ID 66\n",
      "Index 89: Label 18, Word ID 67\n",
      "Index 90: Label 18, Word ID 68\n",
      "Index 91: Label 18, Word ID 69\n",
      "Index 92: Label 18, Word ID 70\n",
      "Index 93: Label 18, Word ID 71\n",
      "Index 94: Label 18, Word ID 72\n",
      "Index 95: Label 18, Word ID 73\n",
      "Index 96: Label 18, Word ID 74\n",
      "Index 97: Label 18, Word ID 75\n",
      "Index 98: Label 18, Word ID 76\n",
      "Index 99: Label 18, Word ID 77\n",
      "Index 100: Label 18, Word ID 78\n",
      "Index 101: Label 18, Word ID 79\n",
      "Index 102: Label 18, Word ID 80\n",
      "Index 103: Label 18, Word ID 81\n",
      "Index 104: Label 18, Word ID 82\n",
      "Index 105: Label 18, Word ID 83\n",
      "Index 106: Label 18, Word ID 84\n",
      "Index 107: Label 18, Word ID 85\n",
      "Index 108: Label 18, Word ID 86\n",
      "Index 109: Label 18, Word ID 86\n",
      "Index 110: Label 18, Word ID 87\n",
      "Index 111: Label 18, Word ID 88\n",
      "Index 112: Label 18, Word ID 89\n",
      "Index 113: Label 18, Word ID 90\n",
      "Index 114: Label 18, Word ID 90\n",
      "Index 115: Label 18, Word ID 90\n",
      "Index 116: Label 18, Word ID 90\n",
      "Index 117: Label 18, Word ID 91\n",
      "Index 118: Label 18, Word ID 92\n",
      "Index 119: Label 18, Word ID 92\n",
      "Index 120: Label 18, Word ID 93\n",
      "Index 121: Label 18, Word ID 94\n",
      "Index 122: Label 18, Word ID 95\n",
      "Index 123: Label 18, Word ID 96\n",
      "Index 124: Label 18, Word ID 97\n",
      "Index 125: Label 3, Word ID 98\n",
      "Index 126: Label 12, Word ID 98\n",
      "Index 127: Label 12, Word ID 98\n",
      "Index 128: Label 12, Word ID 98\n",
      "Index 129: Label 12, Word ID 98\n",
      "Index 130: Label 18, Word ID 99\n",
      "Index 131: Label 18, Word ID 99\n",
      "Index 132: Label 18, Word ID 99\n",
      "Index 133: Label 18, Word ID 100\n",
      "Index 134: Label 18, Word ID 101\n",
      "Index 135: Label 18, Word ID 102\n",
      "Index 136: Label 18, Word ID 103\n",
      "Index 137: Label 18, Word ID 104\n",
      "Index 138: Label 18, Word ID 105\n",
      "Index 139: Label 18, Word ID 106\n",
      "Index 140: Label 18, Word ID 107\n",
      "Index 141: Label 18, Word ID 108\n",
      "Index 142: Label 18, Word ID 109\n",
      "Index 143: Label 18, Word ID 110\n",
      "Index 144: Label 18, Word ID 111\n",
      "Index 145: Label 18, Word ID 112\n",
      "Index 146: Label 18, Word ID 112\n",
      "Index 147: Label 18, Word ID 113\n",
      "Index 148: Label 18, Word ID 114\n",
      "Index 149: Label 18, Word ID 115\n",
      "Index 150: Label 18, Word ID 116\n",
      "Index 151: Label 18, Word ID 117\n",
      "Index 152: Label 18, Word ID 118\n",
      "Index 153: Label 18, Word ID 119\n",
      "Index 154: Label 18, Word ID 120\n",
      "Index 155: Label 18, Word ID 120\n",
      "Index 156: Label 18, Word ID 121\n",
      "Index 157: Label 18, Word ID 122\n",
      "Index 158: Label 18, Word ID 122\n",
      "Index 159: Label 18, Word ID 122\n",
      "Index 160: Label 18, Word ID 122\n",
      "Index 161: Label 18, Word ID 122\n",
      "Index 162: Label 18, Word ID 122\n",
      "Index 163: Label 18, Word ID 123\n",
      "Index 164: Label 18, Word ID 124\n",
      "Index 165: Label 18, Word ID 125\n",
      "Index 166: Label 18, Word ID 126\n",
      "Index 167: Label 18, Word ID 126\n",
      "Index 168: Label 18, Word ID 127\n",
      "Index 169: Label 18, Word ID 128\n",
      "Index 170: Label 18, Word ID 129\n",
      "Index 171: Label 6, Word ID 130\n",
      "Index 172: Label 15, Word ID 130\n",
      "Index 173: Label 15, Word ID 130\n",
      "Index 174: Label 15, Word ID 130\n",
      "Index 175: Label 15, Word ID 130\n",
      "Index 176: Label 15, Word ID 130\n",
      "Index 177: Label 15, Word ID 130\n",
      "Index 178: Label 18, Word ID 131\n",
      "Index 179: Label 18, Word ID 132\n",
      "Index 180: Label 18, Word ID 133\n",
      "Index 181: Label 3, Word ID 134\n",
      "Index 182: Label 12, Word ID 134\n",
      "Index 183: Label 12, Word ID 134\n",
      "Index 184: Label 18, Word ID 135\n",
      "Index 185: Label 18, Word ID 136\n",
      "Index 186: Label 18, Word ID 137\n",
      "Index 187: Label 18, Word ID 138\n",
      "Index 188: Label 18, Word ID 139\n",
      "Index 189: Label 18, Word ID 140\n",
      "Index 190: Label 18, Word ID 141\n",
      "Index 191: Label 18, Word ID 142\n",
      "Index 192: Label 18, Word ID 143\n",
      "Index 193: Label 18, Word ID 144\n",
      "Index 194: Label 18, Word ID 145\n",
      "Index 195: Label 18, Word ID 146\n",
      "Index 196: Label 18, Word ID 147\n",
      "Index 197: Label 18, Word ID 148\n",
      "Index 198: Label 18, Word ID 149\n",
      "Index 199: Label 18, Word ID 150\n",
      "Index 200: Label 18, Word ID 151\n",
      "Index 201: Label 18, Word ID 152\n",
      "Index 202: Label 18, Word ID 153\n",
      "Index 203: Label 18, Word ID 154\n",
      "Index 204: Label 18, Word ID 155\n",
      "Index 205: Label 18, Word ID 156\n",
      "Index 206: Label 18, Word ID 157\n",
      "Index 207: Label 18, Word ID 157\n",
      "Index 208: Label 18, Word ID 158\n",
      "Index 209: Label 18, Word ID 159\n",
      "Index 210: Label 3, Word ID 160\n",
      "Index 211: Label 12, Word ID 160\n",
      "Index 212: Label 12, Word ID 160\n",
      "Index 213: Label 12, Word ID 160\n",
      "Index 214: Label 12, Word ID 160\n",
      "Index 215: Label 1, Word ID 161\n",
      "Index 216: Label 10, Word ID 162\n",
      "Index 217: Label 10, Word ID 163\n",
      "Index 218: Label 10, Word ID 164\n",
      "Index 219: Label 10, Word ID 164\n",
      "Index 220: Label 10, Word ID 164\n",
      "Index 221: Label 10, Word ID 165\n",
      "Index 222: Label 10, Word ID 166\n",
      "Index 223: Label 10, Word ID 167\n",
      "Index 224: Label 10, Word ID 168\n",
      "Index 225: Label 10, Word ID 169\n",
      "Index 226: Label 10, Word ID 170\n",
      "Index 227: Label 10, Word ID 171\n",
      "Index 228: Label 10, Word ID 172\n",
      "Index 229: Label 10, Word ID 173\n",
      "Index 230: Label 10, Word ID 174\n",
      "Index 231: Label 10, Word ID 175\n",
      "Index 232: Label 10, Word ID 176\n",
      "Index 233: Label 10, Word ID 177\n",
      "Index 234: Label 10, Word ID 177\n",
      "Index 235: Label 10, Word ID 177\n",
      "Index 236: Label 10, Word ID 177\n",
      "Index 237: Label 10, Word ID 178\n",
      "Index 238: Label 18, Word ID 179\n",
      "Index 239: Label 18, Word ID 180\n",
      "Index 240: Label 18, Word ID 181\n",
      "Index 241: Label 18, Word ID 182\n",
      "Index 242: Label 18, Word ID 183\n",
      "Index 243: Label 18, Word ID 184\n",
      "Index 244: Label 18, Word ID 185\n",
      "Index 245: Label 18, Word ID 186\n",
      "Index 246: Label 18, Word ID 187\n",
      "Index 247: Label 18, Word ID 188\n",
      "Index 248: Label 18, Word ID 189\n",
      "Index 249: Label 18, Word ID 190\n",
      "Index 250: Label 18, Word ID 191\n",
      "Index 251: Label 18, Word ID 192\n",
      "Index 252: Label 18, Word ID 193\n",
      "Index 253: Label 18, Word ID 194\n",
      "Index 254: Label 18, Word ID 195\n",
      "Index 255: Label 18, Word ID 196\n",
      "Index 256: Label 18, Word ID 197\n",
      "Index 257: Label 18, Word ID 198\n",
      "Index 258: Label 18, Word ID 199\n",
      "Index 259: Label 18, Word ID 200\n",
      "Index 260: Label 18, Word ID 201\n",
      "Index 261: Label 18, Word ID 202\n",
      "Index 262: Label 18, Word ID 203\n",
      "Index 263: Label 18, Word ID 204\n",
      "Index 264: Label 18, Word ID 205\n",
      "Index 265: Label 18, Word ID 206\n",
      "Index 266: Label 18, Word ID 207\n",
      "Index 267: Label 18, Word ID 208\n",
      "Index 268: Label 18, Word ID 209\n",
      "Index 269: Label 18, Word ID 210\n",
      "Index 270: Label 18, Word ID 211\n",
      "Index 271: Label 18, Word ID 212\n",
      "Index 272: Label 18, Word ID 213\n",
      "Index 273: Label 18, Word ID 214\n",
      "Index 274: Label 18, Word ID 215\n",
      "Index 275: Label 18, Word ID 216\n",
      "Index 276: Label 18, Word ID 217\n",
      "Index 277: Label 18, Word ID 218\n",
      "Index 278: Label 18, Word ID 219\n",
      "Index 279: Label 18, Word ID 219\n",
      "Index 280: Label 18, Word ID 219\n",
      "Index 281: Label 18, Word ID 220\n",
      "Index 282: Label 18, Word ID 221\n",
      "Index 283: Label 18, Word ID 222\n",
      "Index 284: Label 18, Word ID 223\n",
      "Index 285: Label 18, Word ID 224\n",
      "Index 286: Label 18, Word ID 225\n",
      "Index 287: Label 18, Word ID 226\n",
      "Index 288: Label 18, Word ID 227\n",
      "Index 289: Label 18, Word ID 227\n",
      "Index 290: Label 18, Word ID 227\n",
      "Index 291: Label 18, Word ID 228\n",
      "Index 292: Label 6, Word ID 229\n",
      "Index 293: Label 15, Word ID 229\n",
      "Index 294: Label 15, Word ID 229\n",
      "Index 295: Label 18, Word ID 230\n",
      "Index 296: Label 18, Word ID 231\n",
      "Index 297: Label 18, Word ID 232\n",
      "Index 298: Label 18, Word ID 232\n",
      "Index 299: Label 18, Word ID 233\n",
      "Index 300: Label 3, Word ID 234\n",
      "Index 301: Label 12, Word ID 234\n",
      "Index 302: Label 12, Word ID 234\n",
      "Index 303: Label 12, Word ID 234\n",
      "Index 304: Label 12, Word ID 234\n",
      "Index 305: Label 18, Word ID 235\n",
      "Index 306: Label 3, Word ID 236\n",
      "Index 307: Label 12, Word ID 236\n",
      "Index 308: Label 12, Word ID 236\n",
      "Index 309: Label 12, Word ID 236\n",
      "Index 310: Label 18, Word ID 237\n",
      "Index 311: Label 3, Word ID 238\n",
      "Index 312: Label 12, Word ID 238\n",
      "Index 313: Label 12, Word ID 238\n",
      "Index 314: Label 18, Word ID 239\n",
      "Index 315: Label 18, Word ID 240\n",
      "Index 316: Label 18, Word ID 241\n",
      "Index 317: Label 18, Word ID 242\n",
      "Index 318: Label 18, Word ID 243\n",
      "Index 319: Label 18, Word ID 243\n",
      "Index 320: Label 18, Word ID 244\n",
      "Index 321: Label 18, Word ID 245\n",
      "Index 322: Label 18, Word ID 246\n",
      "Index 323: Label 18, Word ID 247\n",
      "Index 324: Label 18, Word ID 248\n",
      "Index 325: Label 18, Word ID 249\n",
      "Index 326: Label 3, Word ID 250\n",
      "Index 327: Label 12, Word ID 250\n",
      "Index 328: Label 12, Word ID 250\n",
      "Index 329: Label 12, Word ID 250\n",
      "Index 330: Label 12, Word ID 251\n",
      "Index 331: Label 12, Word ID 252\n",
      "Index 332: Label 18, Word ID 253\n",
      "Index 333: Label 18, Word ID 254\n",
      "Index 334: Label 18, Word ID 255\n",
      "Index 335: Label 18, Word ID 256\n",
      "Index 336: Label 18, Word ID 257\n",
      "Index 337: Label 18, Word ID 258\n",
      "Index 338: Label 18, Word ID 259\n",
      "Index 339: Label 18, Word ID 260\n",
      "Index 340: Label 18, Word ID 261\n",
      "Index 341: Label 18, Word ID 262\n",
      "Index 342: Label 18, Word ID 263\n",
      "Index 343: Label 18, Word ID 264\n",
      "Index 344: Label 18, Word ID 265\n",
      "Index 345: Label 18, Word ID 266\n",
      "Index 346: Label 18, Word ID 267\n",
      "Index 347: Label 3, Word ID 268\n",
      "Index 348: Label 12, Word ID 268\n",
      "Index 349: Label 12, Word ID 268\n",
      "Index 350: Label 12, Word ID 268\n",
      "Index 351: Label 18, Word ID 269\n",
      "Index 352: Label 18, Word ID 270\n",
      "Index 353: Label 18, Word ID 271\n",
      "Index 354: Label 18, Word ID 272\n",
      "Index 355: Label 18, Word ID 272\n",
      "Index 356: Label 18, Word ID 273\n",
      "Index 357: Label 18, Word ID 274\n",
      "Index 358: Label 18, Word ID 275\n",
      "Index 359: Label 18, Word ID 276\n",
      "Index 360: Label 18, Word ID 276\n",
      "Index 361: Label 18, Word ID 277\n",
      "Index 362: Label 18, Word ID 278\n",
      "Index 363: Label 18, Word ID 279\n",
      "Index 364: Label 18, Word ID 280\n",
      "Index 365: Label 18, Word ID 281\n",
      "Index 366: Label 6, Word ID 282\n",
      "Index 367: Label 18, Word ID 283\n",
      "Index 368: Label 18, Word ID 283\n",
      "Index 369: Label 18, Word ID 284\n",
      "Index 370: Label 18, Word ID 285\n",
      "Index 371: Label 18, Word ID 286\n",
      "Index 372: Label 18, Word ID 287\n",
      "Index 373: Label 18, Word ID 288\n",
      "Index 374: Label 18, Word ID 289\n",
      "Index 375: Label 18, Word ID 290\n",
      "Index 376: Label 18, Word ID 291\n",
      "Index 377: Label 18, Word ID 292\n",
      "Index 378: Label 18, Word ID 293\n",
      "Index 379: Label 18, Word ID 294\n",
      "Index 380: Label 6, Word ID 295\n",
      "Index 381: Label 15, Word ID 296\n",
      "Index 382: Label 18, Word ID 297\n",
      "Index 383: Label 18, Word ID 298\n",
      "Index 384: Label 18, Word ID 299\n",
      "Index 385: Label 18, Word ID 300\n",
      "Index 386: Label 18, Word ID 301\n",
      "Index 387: Label 18, Word ID 302\n",
      "Index 388: Label 6, Word ID 303\n",
      "Index 389: Label 15, Word ID 303\n",
      "Index 390: Label 15, Word ID 303\n",
      "Index 391: Label 18, Word ID 304\n",
      "Index 392: Label 18, Word ID 305\n",
      "Index 393: Label 18, Word ID 306\n",
      "Index 394: Label 18, Word ID 307\n",
      "Index 395: Label 18, Word ID 307\n",
      "Index 396: Label 18, Word ID 308\n",
      "Index 397: Label 18, Word ID 309\n",
      "Index 398: Label 3, Word ID 310\n",
      "Index 399: Label 12, Word ID 310\n",
      "Index 400: Label 12, Word ID 310\n",
      "Index 401: Label 12, Word ID 310\n",
      "Index 402: Label 12, Word ID 310\n",
      "Index 403: Label 18, Word ID 311\n",
      "Index 404: Label 18, Word ID 311\n",
      "Index 405: Label 18, Word ID 312\n",
      "Index 406: Label 18, Word ID 313\n",
      "Index 407: Label 18, Word ID 314\n",
      "Index 408: Label 18, Word ID 315\n",
      "Index 409: Label 18, Word ID 316\n",
      "Index 410: Label 18, Word ID 317\n",
      "Index 411: Label 18, Word ID 318\n",
      "Index 412: Label 5, Word ID 319\n",
      "Index 413: Label 14, Word ID 319\n",
      "Index 414: Label 14, Word ID 319\n",
      "Index 415: Label 14, Word ID 320\n",
      "Index 416: Label 14, Word ID 320\n",
      "Index 417: Label 14, Word ID 320\n",
      "Index 418: Label 18, Word ID 321\n",
      "Index 419: Label 18, Word ID 322\n",
      "Index 420: Label 18, Word ID 323\n",
      "Index 421: Label 18, Word ID 324\n",
      "Index 422: Label 18, Word ID 325\n",
      "Index 423: Label 18, Word ID 326\n",
      "Index 424: Label 18, Word ID 327\n",
      "Index 425: Label 18, Word ID 328\n",
      "Index 426: Label 18, Word ID 329\n",
      "Index 427: Label 18, Word ID 329\n",
      "Index 428: Label 18, Word ID 329\n",
      "Index 429: Label 18, Word ID 330\n",
      "Index 430: Label 18, Word ID 331\n",
      "Index 431: Label 18, Word ID 332\n",
      "Index 432: Label 18, Word ID 333\n",
      "Index 433: Label 18, Word ID 334\n",
      "Index 434: Label 18, Word ID 335\n",
      "Index 435: Label 18, Word ID 336\n",
      "Index 436: Label 18, Word ID 337\n",
      "Index 437: Label 18, Word ID 337\n",
      "Index 438: Label 18, Word ID 338\n",
      "Index 439: Label 18, Word ID 338\n",
      "Index 440: Label 18, Word ID 339\n",
      "Index 441: Label 18, Word ID 340\n",
      "Index 442: Label 18, Word ID 341\n",
      "Index 443: Label 18, Word ID 342\n",
      "Index 444: Label 6, Word ID 343\n",
      "Index 445: Label 15, Word ID 343\n",
      "Index 446: Label 18, Word ID 344\n",
      "Index 447: Label 6, Word ID 345\n",
      "Index 448: Label 15, Word ID 345\n",
      "Index 449: Label 18, Word ID 346\n",
      "Index 450: Label 6, Word ID 347\n",
      "Index 451: Label 15, Word ID 347\n",
      "Index 452: Label 15, Word ID 348\n",
      "Index 453: Label 18, Word ID 349\n",
      "Index 454: Label 18, Word ID 350\n",
      "Index 455: Label 6, Word ID 351\n",
      "Index 456: Label 15, Word ID 351\n",
      "Index 457: Label 15, Word ID 351\n",
      "Index 458: Label 18, Word ID 352\n",
      "Index 459: Label 18, Word ID 353\n",
      "Index 460: Label 18, Word ID 354\n",
      "Index 461: Label 18, Word ID 355\n",
      "Index 462: Label 18, Word ID 356\n",
      "Index 463: Label 18, Word ID 357\n",
      "Index 464: Label 18, Word ID 358\n",
      "Index 465: Label 18, Word ID 359\n",
      "Index 466: Label 18, Word ID 360\n",
      "Index 467: Label 3, Word ID 361\n",
      "Index 468: Label 12, Word ID 361\n",
      "Index 469: Label 12, Word ID 361\n",
      "Index 470: Label 18, Word ID 362\n",
      "Index 471: Label 18, Word ID 363\n",
      "Index 472: Label 18, Word ID 364\n",
      "Index 473: Label 18, Word ID 365\n",
      "Index 474: Label 18, Word ID 366\n",
      "Index 475: Label 18, Word ID 367\n",
      "Index 476: Label 18, Word ID 368\n",
      "Index 477: Label 6, Word ID 369\n",
      "Index 478: Label 15, Word ID 369\n",
      "Index 479: Label 15, Word ID 369\n",
      "Index 480: Label 15, Word ID 369\n",
      "Index 481: Label 18, Word ID 370\n",
      "Index 482: Label 18, Word ID 371\n",
      "Index 483: Label 18, Word ID 372\n",
      "Index 484: Label 18, Word ID 373\n",
      "Index 485: Label 18, Word ID 374\n",
      "Index 486: Label 18, Word ID 375\n",
      "Index 487: Label 18, Word ID 376\n",
      "Index 488: Label 18, Word ID 377\n",
      "Index 489: Label 18, Word ID 378\n",
      "Index 490: Label 18, Word ID 379\n",
      "Index 491: Label 18, Word ID 380\n",
      "Index 492: Label 18, Word ID 381\n",
      "Index 493: Label 18, Word ID 382\n",
      "Index 494: Label 18, Word ID 383\n",
      "Index 495: Label 18, Word ID 384\n",
      "Index 496: Label 18, Word ID 385\n",
      "Index 497: Label 18, Word ID 386\n",
      "Index 498: Label 18, Word ID 386\n",
      "Index 499: Label 18, Word ID 387\n",
      "Index 500: Label 3, Word ID 388\n",
      "Index 501: Label 12, Word ID 388\n",
      "Index 502: Label 12, Word ID 388\n",
      "Index 503: Label 12, Word ID 388\n",
      "Index 504: Label 12, Word ID 388\n",
      "Index 505: Label 18, Word ID 389\n",
      "Index 506: Label 18, Word ID 390\n",
      "Index 507: Label 18, Word ID 391\n",
      "Index 508: Label 18, Word ID 391\n",
      "Index 509: Label 18, Word ID 392\n",
      "Index 510: Label 18, Word ID 393\n",
      "Index 511: Label 18, Word ID None\n"
     ]
    }
   ],
   "source": [
    "for i, (label, word_id) in enumerate(zip(dataset[0]['labels'], dataset[0]['word_ids'])):\n",
    "    print(f\"Index {i}: Label {label}, Word ID {word_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:  [CLS]\n",
      "Label:  18\n",
      "Word_ids:  None\n",
      "Input_ids:  101\n",
      "---------------------------\n",
      "Token:  A\n",
      "Label:  18\n",
      "Word_ids:  0\n",
      "Input_ids:  138\n",
      "---------------------------\n",
      "Token:  new\n",
      "Label:  18\n",
      "Word_ids:  1\n",
      "Input_ids:  1207\n",
      "---------------------------\n",
      "Token:  ransom\n",
      "Label:  18\n",
      "Word_ids:  2\n",
      "Input_ids:  25057\n",
      "---------------------------\n",
      "Token:  ##ware\n",
      "Label:  18\n",
      "Word_ids:  2\n",
      "Input_ids:  7109\n",
      "---------------------------\n",
      "Token:  -\n",
      "Label:  18\n",
      "Word_ids:  3\n",
      "Input_ids:  118\n",
      "---------------------------\n",
      "Token:  as\n",
      "Label:  18\n",
      "Word_ids:  4\n",
      "Input_ids:  1112\n",
      "---------------------------\n",
      "Token:  -\n",
      "Label:  18\n",
      "Word_ids:  5\n",
      "Input_ids:  118\n",
      "---------------------------\n",
      "Token:  a\n",
      "Label:  18\n",
      "Word_ids:  6\n",
      "Input_ids:  170\n",
      "---------------------------\n",
      "Token:  -\n",
      "Label:  18\n",
      "Word_ids:  7\n",
      "Input_ids:  118\n",
      "---------------------------\n",
      "Token:  service\n",
      "Label:  18\n",
      "Word_ids:  8\n",
      "Input_ids:  1555\n",
      "---------------------------\n",
      "Token:  (\n",
      "Label:  18\n",
      "Word_ids:  9\n",
      "Input_ids:  113\n",
      "---------------------------\n",
      "Token:  Ra\n",
      "Label:  18\n",
      "Word_ids:  10\n",
      "Input_ids:  16890\n",
      "---------------------------\n",
      "Token:  ##a\n",
      "Label:  18\n",
      "Word_ids:  10\n",
      "Input_ids:  1161\n",
      "---------------------------\n",
      "Token:  ##S\n",
      "Label:  18\n",
      "Word_ids:  10\n",
      "Input_ids:  1708\n",
      "---------------------------\n",
      "Token:  )\n",
      "Label:  18\n",
      "Word_ids:  11\n",
      "Input_ids:  114\n",
      "---------------------------\n",
      "Token:  operation\n",
      "Label:  18\n",
      "Word_ids:  12\n",
      "Input_ids:  2805\n",
      "---------------------------\n",
      "Token:  named\n",
      "Label:  18\n",
      "Word_ids:  13\n",
      "Input_ids:  1417\n",
      "---------------------------\n",
      "Token:  C\n",
      "Label:  3\n",
      "Word_ids:  14\n",
      "Input_ids:  140\n",
      "---------------------------\n",
      "Token:  ##ica\n",
      "Label:  12\n",
      "Word_ids:  14\n",
      "Input_ids:  4578\n",
      "---------------------------\n",
      "Token:  ##da\n",
      "Label:  12\n",
      "Word_ids:  14\n",
      "Input_ids:  1810\n",
      "---------------------------\n",
      "Token:  ##33\n",
      "Label:  12\n",
      "Word_ids:  14\n",
      "Input_ids:  23493\n",
      "---------------------------\n",
      "Token:  ##01\n",
      "Label:  12\n",
      "Word_ids:  14\n",
      "Input_ids:  24400\n",
      "---------------------------\n",
      "Token:  has\n",
      "Label:  18\n",
      "Word_ids:  15\n",
      "Input_ids:  1144\n",
      "---------------------------\n",
      "Token:  already\n",
      "Label:  18\n",
      "Word_ids:  16\n",
      "Input_ids:  1640\n",
      "---------------------------\n",
      "Token:  listed\n",
      "Label:  18\n",
      "Word_ids:  17\n",
      "Input_ids:  2345\n",
      "---------------------------\n",
      "Token:  19\n",
      "Label:  18\n",
      "Word_ids:  18\n",
      "Input_ids:  1627\n",
      "---------------------------\n",
      "Token:  victims\n",
      "Label:  18\n",
      "Word_ids:  19\n",
      "Input_ids:  5256\n",
      "---------------------------\n",
      "Token:  on\n",
      "Label:  18\n",
      "Word_ids:  20\n",
      "Input_ids:  1113\n",
      "---------------------------\n",
      "Token:  its\n",
      "Label:  18\n",
      "Word_ids:  21\n",
      "Input_ids:  1157\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(\"Token: \", dataset[0]['tokens'][i])\n",
    "    print(\"Label: \", dataset[0]['labels'][i])\n",
    "    print(\"Word_ids: \", dataset[0]['word_ids'][i])\n",
    "    print(\"Input_ids: \", dataset[0]['input_ids'][i])\n",
    "    print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_2(data):\n",
    "    word_ids = data[\"word_ids\"]\n",
    "    original_labels = data[\"labels\"]\n",
    "    new_labels = []\n",
    "\n",
    "    previous_word_idx = None\n",
    "    \n",
    "    for idx, (word_id, label) in enumerate(zip(word_ids, original_labels)):\n",
    "        if word_id is None:\n",
    "            new_labels.append(-100) # Special tokens\n",
    "        elif word_id != previous_word_idx:\n",
    "            new_labels.append(label)\n",
    "        else:\n",
    "            new_labels.append(-100)\n",
    "        previous_word_idx = word_id\n",
    "\n",
    "    data[\"labels\"] = new_labels\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30c0e0c4d104299a9800cf1627ca28c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_and_aligned_dataset = dataset.map(align_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['[CLS]', 'A', 'new', 'ransom', '##ware', '-', 'as', '-', 'a', '-', 'service', '(', 'Ra', '##a', '##S', ')', 'operation', 'named', 'C', '##ica', '##da', '##33', '##01', 'has', 'already', 'listed', '19', 'victims', 'on', 'its', 'ex', '##tor', '##tion', 'portal', ',', 'as', 'it', 'quickly', 'attacked', 'companies', 'worldwide', '.', 'The', 'new', 'c', '##y', '##ber', '##c', '##rim', '##e', 'operation', 'is', 'named', 'after', 'the', 'mysterious', '2012', '-', '2014', 'online', '/', 'real', '-', 'world', 'game', 'that', 'involved', 'elaborate', 'cry', '##pt', '##ographic', 'puzzles', 'and', 'used', 'the', 'same', 'logo', 'for', 'promotion', 'on', 'c', '##y', '##ber', '##c', '##rim', '##e', 'forums', '.', 'However', ',', 'there', \"'\", 's', 'no', 'connection', 'between', 'the', 'two', ',', 'and', 'the', 'legitimate', 'project', 'has', 'issued', 'a', 'statement', 'to', 're', '##nounce', 'any', 'association', 'and', 'con', '##de', '##m', '##n', 'the', 'ransom', '##ware', 'operators', \"'\", 'actions', '.', 'The', 'C', '##ica', '##da', '##33', '##01', 'Ra', '##a', '##S', 'first', 'began', 'promoting', 'the', 'operation', 'and', 'recruiting', 'affiliates', 'on', 'June', '29', ',', '202', '##4', ',', 'in', 'a', 'forum', 'post', 'to', 'the', 'ransom', '##ware', 'and', 'c', '##y', '##ber', '##c', '##rim', '##e', 'forum', 'known', 'as', 'RAM', '##P', '.', 'However', ',', 'B', '##lee', '##ping', '##C', '##om', '##pute', '##r', 'is', 'aware', 'of', 'C', '##ica', '##da', 'attacks', 'as', 'early', 'as', 'June', '6', ',', 'indicating', 'that', 'the', 'gang', 'was', 'operating', 'independently', 'before', 'attempting', 'to', 'recruit', 'affiliates', '.', 'Like', 'other', 'ransom', '##ware', 'operations', ',', 'C', '##ica', '##da', '##33', '##01', 'conducts', 'double', '-', 'ex', '##tor', '##tion', 'tactics', 'where', 'they', 'breach', 'corporate', 'networks', ',', 'steal', 'data', ',', 'and', 'then', 'en', '##c', '##ry', '##pt', 'devices', '.', 'The', 'encryption', 'key', 'and', 'threats', 'to', 'leak', 'stolen', 'data', 'are', 'then', 'used', 'as', 'leverage', 'to', 'scare', 'victims', 'into', 'paying', 'a', 'ransom', '.', 'The', 'threat', 'actors', 'operate', 'a', 'data', 'leak', 'site', 'that', 'is', 'used', 'as', 'part', 'of', 'their', 'double', '-', 'ex', '##tor', '##tion', 'scheme', '.', 'An', 'analysis', 'of', 'the', 'new', 'ma', '##l', '##ware', 'by', 'True', '##se', '##c', 'revealed', 'significant', 'overlap', '##s', 'between', 'C', '##ica', '##da', '##33', '##01', 'and', 'AL', '##P', '##H', '##V', '/', 'Black', '##C', '##at', ',', 'indicating', 'a', 'possible', 're', '##brand', 'or', 'a', 'fork', 'created', 'by', 'former', 'AL', '##P', '##H', '##V', \"'\", 's', 'core', 'team', 'members', '.', 'This', 'is', 'based', 'on', 'the', 'fact', 'that', ':', 'For', 'context', ',', 'AL', '##P', '##H', '##V', 'performed', 'an', 'exit', 's', '##cam', 'in', 'early', 'March', '202', '##4', 'involving', 'fake', 'claims', 'about', 'an', 'FBI', 'take', '##down', 'operation', 'after', 'they', 'stole', 'a', 'massive', '$', '22', 'million', 'payment', 'from', 'Change', 'Healthcare', 'from', 'one', 'of', 'their', 'affiliates', '.', 'True', '##se', '##c', 'has', 'also', 'found', 'indication', '##s', 'that', 'the', 'C', '##ica', '##da', '##33', '##01', 'ransom', '##ware', 'operation', 'may', 'partner', 'with', 'or', 'utilize', 'the', 'B', '##ru', '##tus', 'b', '##ot', '##net', 'for', 'initial', 'access', 'to', 'corporate', 'networks', '.', 'That', 'b', '##ot', '##net', 'was', 'previously', 'associated', 'with', 'global', '-', 'scale', 'VP', '##N', 'br', '##ute', '-', 'forcing', 'activities', 'targeting', 'C', '##isco', ',', 'Fort', '##inet', ',', 'Pa', '##lo', 'Alto', ',', 'and', 'Sonic', '##W', '##all', 'appliances', '.', 'It', \"'\", 's', 'worth', 'noting', 'that', 'the', 'B', '##ru', '##tus', 'activity', 'was', 'first', 'spotted', 'two', 'weeks', 'after', 'AL', '##P', '##H', '##V', 'shut', 'down', 'operations', ',', 'so', 'the', 'link', 'between', 'the', 'two', 'groups', 'still', 'stands', 'in', 'terms', 'of', 'timeline', '##s', '.', 'C', '##ica', '##da', '##33', '##01', 'is', 'a', 'R', '##ust', '-', 'based', '[SEP]'], 'labels': [-100, 18, 18, 18, -100, 18, 18, 18, 18, 18, 18, 18, 18, -100, -100, 18, 18, 18, 3, -100, -100, -100, -100, 18, 18, 18, 18, 18, 18, 18, 18, -100, -100, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, -100, -100, -100, -100, -100, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, -100, -100, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, -100, -100, -100, -100, -100, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, -100, 18, 18, 18, 18, -100, -100, -100, 18, 18, -100, 18, 18, 18, 18, 18, 3, -100, -100, -100, -100, 18, -100, -100, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, -100, 18, 18, 18, 18, 18, 18, 18, 18, -100, 18, 18, -100, -100, -100, -100, -100, 18, 18, 18, 18, -100, 18, 18, 18, 6, -100, -100, -100, -100, -100, -100, 18, 18, 18, 3, -100, -100, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, -100, 18, 18, 3, -100, -100, -100, -100, 1, 10, 10, 10, -100, -100, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, -100, -100, -100, 10, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, -100, -100, 18, 18, 18, 18, 18, 18, 18, 18, -100, -100, 18, 6, -100, -100, 18, 18, 18, -100, 18, 3, -100, -100, -100, -100, 18, 3, -100, -100, -100, 18, 3, -100, -100, 18, 18, 18, 18, 18, -100, 18, 18, 18, 18, 18, 18, 3, -100, -100, -100, 12, 12, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 3, -100, -100, -100, 18, 18, 18, 18, -100, 18, 18, 18, 18, -100, 18, 18, 18, 18, 18, 6, 18, -100, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 6, 15, 18, 18, 18, 18, 18, 18, 6, -100, -100, 18, 18, 18, 18, -100, 18, 18, 3, -100, -100, -100, -100, 18, -100, 18, 18, 18, 18, 18, 18, 18, 5, -100, -100, 14, -100, -100, 18, 18, 18, 18, 18, 18, 18, 18, 18, -100, -100, 18, 18, 18, 18, 18, 18, 18, 18, -100, 18, -100, 18, 18, 18, 18, 6, -100, 18, 6, -100, 18, 6, -100, 15, 18, 18, 6, -100, -100, 18, 18, 18, 18, 18, 18, 18, 18, 18, 3, -100, -100, 18, 18, 18, 18, 18, 18, 18, 6, -100, -100, -100, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, -100, 18, 3, -100, -100, -100, -100, 18, 18, 18, -100, 18, 18, -100], 'input_ids': [101, 138, 1207, 25057, 7109, 118, 1112, 118, 170, 118, 1555, 113, 16890, 1161, 1708, 114, 2805, 1417, 140, 4578, 1810, 23493, 24400, 1144, 1640, 2345, 1627, 5256, 1113, 1157, 4252, 2772, 2116, 10823, 117, 1112, 1122, 1976, 3623, 2557, 4529, 119, 1109, 1207, 172, 1183, 3169, 1665, 10205, 1162, 2805, 1110, 1417, 1170, 1103, 8198, 1368, 118, 1387, 3294, 120, 1842, 118, 1362, 1342, 1115, 2017, 9427, 5354, 6451, 9597, 22747, 1105, 1215, 1103, 1269, 7998, 1111, 4166, 1113, 172, 1183, 3169, 1665, 10205, 1162, 25438, 119, 1438, 117, 1175, 112, 188, 1185, 3797, 1206, 1103, 1160, 117, 1105, 1103, 11582, 1933, 1144, 3010, 170, 4195, 1106, 1231, 25196, 1251, 3852, 1105, 14255, 2007, 1306, 1179, 1103, 25057, 7109, 9298, 112, 3721, 119, 1109, 140, 4578, 1810, 23493, 24400, 16890, 1161, 1708, 1148, 1310, 7495, 1103, 2805, 1105, 16226, 20795, 1113, 1340, 1853, 117, 17881, 1527, 117, 1107, 170, 13912, 2112, 1106, 1103, 25057, 7109, 1105, 172, 1183, 3169, 1665, 10205, 1162, 13912, 1227, 1112, 20898, 2101, 119, 1438, 117, 139, 6894, 2624, 1658, 4165, 22662, 1197, 1110, 4484, 1104, 140, 4578, 1810, 3690, 1112, 1346, 1112, 1340, 127, 117, 7713, 1115, 1103, 6939, 1108, 3389, 8942, 1196, 6713, 1106, 14240, 20795, 119, 2409, 1168, 25057, 7109, 2500, 117, 140, 4578, 1810, 23493, 24400, 19706, 2702, 118, 4252, 2772, 2116, 10524, 1187, 1152, 13275, 6214, 6379, 117, 8991, 2233, 117, 1105, 1173, 4035, 1665, 1616, 6451, 5197, 119, 1109, 26463, 2501, 1105, 8657, 1106, 19299, 7251, 2233, 1132, 1173, 1215, 1112, 24228, 1106, 13671, 5256, 1154, 6573, 170, 25057, 119, 1109, 4433, 5681, 4732, 170, 2233, 19299, 1751, 1115, 1110, 1215, 1112, 1226, 1104, 1147, 2702, 118, 4252, 2772, 2116, 5471, 119, 1760, 3622, 1104, 1103, 1207, 12477, 1233, 7109, 1118, 7817, 2217, 1665, 3090, 2418, 19235, 1116, 1206, 140, 4578, 1810, 23493, 24400, 1105, 18589, 2101, 3048, 2559, 120, 2117, 1658, 2980, 117, 7713, 170, 1936, 1231, 25123, 1137, 170, 13097, 1687, 1118, 1393, 18589, 2101, 3048, 2559, 112, 188, 4160, 1264, 1484, 119, 1188, 1110, 1359, 1113, 1103, 1864, 1115, 131, 1370, 5618, 117, 18589, 2101, 3048, 2559, 1982, 1126, 6300, 188, 24282, 1107, 1346, 1345, 17881, 1527, 5336, 8406, 3711, 1164, 1126, 8099, 1321, 5455, 2805, 1170, 1152, 10566, 170, 4672, 109, 1659, 1550, 7727, 1121, 9091, 22993, 1121, 1141, 1104, 1147, 20795, 119, 7817, 2217, 1665, 1144, 1145, 1276, 12754, 1116, 1115, 1103, 140, 4578, 1810, 23493, 24400, 25057, 7109, 2805, 1336, 3547, 1114, 1137, 17573, 1103, 139, 5082, 4814, 171, 3329, 6097, 1111, 3288, 2469, 1106, 6214, 6379, 119, 1337, 171, 3329, 6097, 1108, 2331, 2628, 1114, 4265, 118, 3418, 23659, 2249, 9304, 6140, 118, 6524, 2619, 15141, 140, 21097, 117, 3144, 27411, 117, 19585, 2858, 17762, 117, 1105, 16202, 2924, 5727, 26498, 119, 1135, 112, 188, 3869, 9095, 1115, 1103, 139, 5082, 4814, 3246, 1108, 1148, 6910, 1160, 2277, 1170, 18589, 2101, 3048, 2559, 3210, 1205, 2500, 117, 1177, 1103, 5088, 1206, 1103, 1160, 2114, 1253, 4061, 1107, 2538, 1104, 21169, 1116, 119, 140, 4578, 1810, 23493, 24400, 1110, 170, 155, 8954, 118, 1359, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'word_ids': [None, 0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 11, 12, 13, 14, 14, 14, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 34, 34, 34, 34, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 53, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 63, 63, 63, 63, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 86, 87, 88, 89, 90, 90, 90, 90, 91, 92, 92, 93, 94, 95, 96, 97, 98, 98, 98, 98, 98, 99, 99, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 112, 113, 114, 115, 116, 117, 118, 119, 120, 120, 121, 122, 122, 122, 122, 122, 122, 123, 124, 125, 126, 126, 127, 128, 129, 130, 130, 130, 130, 130, 130, 130, 131, 132, 133, 134, 134, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 157, 158, 159, 160, 160, 160, 160, 160, 161, 162, 163, 164, 164, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 177, 177, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 219, 219, 220, 221, 222, 223, 224, 225, 226, 227, 227, 227, 228, 229, 229, 229, 230, 231, 232, 232, 233, 234, 234, 234, 234, 234, 235, 236, 236, 236, 236, 237, 238, 238, 238, 239, 240, 241, 242, 243, 243, 244, 245, 246, 247, 248, 249, 250, 250, 250, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 268, 268, 268, 269, 270, 271, 272, 272, 273, 274, 275, 276, 276, 277, 278, 279, 280, 281, 282, 283, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 303, 303, 304, 305, 306, 307, 307, 308, 309, 310, 310, 310, 310, 310, 311, 311, 312, 313, 314, 315, 316, 317, 318, 319, 319, 319, 320, 320, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 329, 329, 330, 331, 332, 333, 334, 335, 336, 337, 337, 338, 338, 339, 340, 341, 342, 343, 343, 344, 345, 345, 346, 347, 347, 348, 349, 350, 351, 351, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 361, 361, 362, 363, 364, 365, 366, 367, 368, 369, 369, 369, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 386, 387, 388, 388, 388, 388, 388, 389, 390, 391, 391, 392, 393, None]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_and_aligned_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:  [CLS]\n",
      "Label:  -100\n",
      "Word_ids:  None\n",
      "Input_ids:  101\n",
      "---------------------------\n",
      "Token:  A\n",
      "Label:  18\n",
      "Word_ids:  0\n",
      "Input_ids:  138\n",
      "---------------------------\n",
      "Token:  new\n",
      "Label:  18\n",
      "Word_ids:  1\n",
      "Input_ids:  1207\n",
      "---------------------------\n",
      "Token:  ransom\n",
      "Label:  18\n",
      "Word_ids:  2\n",
      "Input_ids:  25057\n",
      "---------------------------\n",
      "Token:  ##ware\n",
      "Label:  -100\n",
      "Word_ids:  2\n",
      "Input_ids:  7109\n",
      "---------------------------\n",
      "Token:  -\n",
      "Label:  18\n",
      "Word_ids:  3\n",
      "Input_ids:  118\n",
      "---------------------------\n",
      "Token:  as\n",
      "Label:  18\n",
      "Word_ids:  4\n",
      "Input_ids:  1112\n",
      "---------------------------\n",
      "Token:  -\n",
      "Label:  18\n",
      "Word_ids:  5\n",
      "Input_ids:  118\n",
      "---------------------------\n",
      "Token:  a\n",
      "Label:  18\n",
      "Word_ids:  6\n",
      "Input_ids:  170\n",
      "---------------------------\n",
      "Token:  -\n",
      "Label:  18\n",
      "Word_ids:  7\n",
      "Input_ids:  118\n",
      "---------------------------\n",
      "Token:  service\n",
      "Label:  18\n",
      "Word_ids:  8\n",
      "Input_ids:  1555\n",
      "---------------------------\n",
      "Token:  (\n",
      "Label:  18\n",
      "Word_ids:  9\n",
      "Input_ids:  113\n",
      "---------------------------\n",
      "Token:  Ra\n",
      "Label:  18\n",
      "Word_ids:  10\n",
      "Input_ids:  16890\n",
      "---------------------------\n",
      "Token:  ##a\n",
      "Label:  -100\n",
      "Word_ids:  10\n",
      "Input_ids:  1161\n",
      "---------------------------\n",
      "Token:  ##S\n",
      "Label:  -100\n",
      "Word_ids:  10\n",
      "Input_ids:  1708\n",
      "---------------------------\n",
      "Token:  )\n",
      "Label:  18\n",
      "Word_ids:  11\n",
      "Input_ids:  114\n",
      "---------------------------\n",
      "Token:  operation\n",
      "Label:  18\n",
      "Word_ids:  12\n",
      "Input_ids:  2805\n",
      "---------------------------\n",
      "Token:  named\n",
      "Label:  18\n",
      "Word_ids:  13\n",
      "Input_ids:  1417\n",
      "---------------------------\n",
      "Token:  C\n",
      "Label:  3\n",
      "Word_ids:  14\n",
      "Input_ids:  140\n",
      "---------------------------\n",
      "Token:  ##ica\n",
      "Label:  -100\n",
      "Word_ids:  14\n",
      "Input_ids:  4578\n",
      "---------------------------\n",
      "Token:  ##da\n",
      "Label:  -100\n",
      "Word_ids:  14\n",
      "Input_ids:  1810\n",
      "---------------------------\n",
      "Token:  ##33\n",
      "Label:  -100\n",
      "Word_ids:  14\n",
      "Input_ids:  23493\n",
      "---------------------------\n",
      "Token:  ##01\n",
      "Label:  -100\n",
      "Word_ids:  14\n",
      "Input_ids:  24400\n",
      "---------------------------\n",
      "Token:  has\n",
      "Label:  18\n",
      "Word_ids:  15\n",
      "Input_ids:  1144\n",
      "---------------------------\n",
      "Token:  already\n",
      "Label:  18\n",
      "Word_ids:  16\n",
      "Input_ids:  1640\n",
      "---------------------------\n",
      "Token:  listed\n",
      "Label:  18\n",
      "Word_ids:  17\n",
      "Input_ids:  2345\n",
      "---------------------------\n",
      "Token:  19\n",
      "Label:  18\n",
      "Word_ids:  18\n",
      "Input_ids:  1627\n",
      "---------------------------\n",
      "Token:  victims\n",
      "Label:  18\n",
      "Word_ids:  19\n",
      "Input_ids:  5256\n",
      "---------------------------\n",
      "Token:  on\n",
      "Label:  18\n",
      "Word_ids:  20\n",
      "Input_ids:  1113\n",
      "---------------------------\n",
      "Token:  its\n",
      "Label:  18\n",
      "Word_ids:  21\n",
      "Input_ids:  1157\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(\"Token: \", tokenized_and_aligned_dataset[0]['tokens'][i])\n",
    "    print(\"Label: \", tokenized_and_aligned_dataset[0]['labels'][i])\n",
    "    print(\"Word_ids: \", tokenized_and_aligned_dataset[0]['word_ids'][i])\n",
    "    print(\"Input_ids: \", tokenized_and_aligned_dataset[0]['input_ids'][i])\n",
    "    print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0384ce5936d14725b5b3294c4c0271e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(align_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:  [CLS]\n",
      "Label:  -100\n",
      "Word_ids:  None\n",
      "Input_ids:  101\n",
      "---------------------------\n",
      "Token:  A\n",
      "Label:  18\n",
      "Word_ids:  0\n",
      "Input_ids:  138\n",
      "---------------------------\n",
      "Token:  new\n",
      "Label:  18\n",
      "Word_ids:  1\n",
      "Input_ids:  1207\n",
      "---------------------------\n",
      "Token:  ransom\n",
      "Label:  18\n",
      "Word_ids:  2\n",
      "Input_ids:  25057\n",
      "---------------------------\n",
      "Token:  ##ware\n",
      "Label:  -100\n",
      "Word_ids:  2\n",
      "Input_ids:  7109\n",
      "---------------------------\n",
      "Token:  -\n",
      "Label:  18\n",
      "Word_ids:  3\n",
      "Input_ids:  118\n",
      "---------------------------\n",
      "Token:  as\n",
      "Label:  18\n",
      "Word_ids:  4\n",
      "Input_ids:  1112\n",
      "---------------------------\n",
      "Token:  -\n",
      "Label:  18\n",
      "Word_ids:  5\n",
      "Input_ids:  118\n",
      "---------------------------\n",
      "Token:  a\n",
      "Label:  18\n",
      "Word_ids:  6\n",
      "Input_ids:  170\n",
      "---------------------------\n",
      "Token:  -\n",
      "Label:  18\n",
      "Word_ids:  7\n",
      "Input_ids:  118\n",
      "---------------------------\n",
      "Token:  service\n",
      "Label:  18\n",
      "Word_ids:  8\n",
      "Input_ids:  1555\n",
      "---------------------------\n",
      "Token:  (\n",
      "Label:  18\n",
      "Word_ids:  9\n",
      "Input_ids:  113\n",
      "---------------------------\n",
      "Token:  Ra\n",
      "Label:  18\n",
      "Word_ids:  10\n",
      "Input_ids:  16890\n",
      "---------------------------\n",
      "Token:  ##a\n",
      "Label:  -100\n",
      "Word_ids:  10\n",
      "Input_ids:  1161\n",
      "---------------------------\n",
      "Token:  ##S\n",
      "Label:  -100\n",
      "Word_ids:  10\n",
      "Input_ids:  1708\n",
      "---------------------------\n",
      "Token:  )\n",
      "Label:  18\n",
      "Word_ids:  11\n",
      "Input_ids:  114\n",
      "---------------------------\n",
      "Token:  operation\n",
      "Label:  18\n",
      "Word_ids:  12\n",
      "Input_ids:  2805\n",
      "---------------------------\n",
      "Token:  named\n",
      "Label:  18\n",
      "Word_ids:  13\n",
      "Input_ids:  1417\n",
      "---------------------------\n",
      "Token:  C\n",
      "Label:  3\n",
      "Word_ids:  14\n",
      "Input_ids:  140\n",
      "---------------------------\n",
      "Token:  ##ica\n",
      "Label:  -100\n",
      "Word_ids:  14\n",
      "Input_ids:  4578\n",
      "---------------------------\n",
      "Token:  ##da\n",
      "Label:  -100\n",
      "Word_ids:  14\n",
      "Input_ids:  1810\n",
      "---------------------------\n",
      "Token:  ##33\n",
      "Label:  -100\n",
      "Word_ids:  14\n",
      "Input_ids:  23493\n",
      "---------------------------\n",
      "Token:  ##01\n",
      "Label:  -100\n",
      "Word_ids:  14\n",
      "Input_ids:  24400\n",
      "---------------------------\n",
      "Token:  has\n",
      "Label:  18\n",
      "Word_ids:  15\n",
      "Input_ids:  1144\n",
      "---------------------------\n",
      "Token:  already\n",
      "Label:  18\n",
      "Word_ids:  16\n",
      "Input_ids:  1640\n",
      "---------------------------\n",
      "Token:  listed\n",
      "Label:  18\n",
      "Word_ids:  17\n",
      "Input_ids:  2345\n",
      "---------------------------\n",
      "Token:  19\n",
      "Label:  18\n",
      "Word_ids:  18\n",
      "Input_ids:  1627\n",
      "---------------------------\n",
      "Token:  victims\n",
      "Label:  18\n",
      "Word_ids:  19\n",
      "Input_ids:  5256\n",
      "---------------------------\n",
      "Token:  on\n",
      "Label:  18\n",
      "Word_ids:  20\n",
      "Input_ids:  1113\n",
      "---------------------------\n",
      "Token:  its\n",
      "Label:  18\n",
      "Word_ids:  21\n",
      "Input_ids:  1157\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(\"Token: \", dataset[0]['tokens'][i])\n",
    "    print(\"Label: \", dataset[0]['labels'][i])\n",
    "    print(\"Word_ids: \", dataset[0]['word_ids'][i])\n",
    "    print(\"Input_ids: \", dataset[0]['input_ids'][i])\n",
    "    print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'labels', 'input_ids', 'attention_mask', 'word_ids'],\n",
      "        num_rows: 48\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'labels', 'input_ids', 'attention_mask', 'word_ids'],\n",
      "        num_rows: 13\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Verify split\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b55daf6bb5b4280b7136d5fd2dcb1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magnu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\magnu\\.cache\\huggingface\\hub\\models--google-bert--bert-base-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metric\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    true_labels = [[label for label in label_seq if label != -100] for label_seq in labels]\n",
    "    true_predictions = [[pred for pred, lab in zip(pred_seq, label_seq) if lab != -100] for pred_seq, label_seq in zip(predictions, labels)]\n",
    "    return seqeval.compute(predictions=true_predictions, references=true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magnu\\AppData\\Local\\Temp\\ipykernel_27368\\3993666119.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 03:05, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.807386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.254900</td>\n",
       "      <td>0.696961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.254900</td>\n",
       "      <td>0.587973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.549310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.492200</td>\n",
       "      <td>0.527802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./ner_model\\\\tokenizer_config.json',\n",
       " './ner_model\\\\special_tokens_map.json',\n",
       " './ner_model\\\\vocab.txt',\n",
       " './ner_model\\\\added_tokens.json',\n",
       " './ner_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model(\"./ner_model\")\n",
    "tokenizer.save_pretrained(\"./ner_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
